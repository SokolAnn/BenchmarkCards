# Comparison of BBQ and RealToxicityPrompts Benchmarks üìö

| **Field**                  | **BBQ** | **RealToxicityPrompts** |
|----------------------------|---------|-------------------------|
| **Name**                   | Bias Benchmark for Question Answering | RealToxicityPrompts |
| **Overview**               | Assessing social biases in QA systems | Evaluating toxicity in language generation |
| **Data Type**              | Text (QA pairs and contexts) | Text (prompts and continuations) |
| **Domains**                | Social Bias, Fairness, QA | Toxicity Detection, Language Modeling, Controllable Generation |
| **Languages**              | English | English |
| **Similar Benchmarks**     | WINO-Bias, StereoSet, CrowS-Pairs | ToxiGen, Ethos, HateCheck |
| **Resources**              | [BBQ GitHub](https://github.com/nyu-mll/BBQ) | [RealToxicityPrompts](http://toxicdegeneration.allenai.org/) |

---

## Purpose and Intended Users üéØ

| **Field**            | **BBQ** | **RealToxicityPrompts** |
|----------------------|---------|-------------------------|
| **Goal**             | Measure social biases in QA models | Measure and mitigate toxic degeneration in language models |
| **Audience**         | NLP researchers, developers, ethics experts | NLP researchers, developers, AI safety experts |
| **Tasks**            | QA with ambiguous and disambiguated contexts | Conditional text generation |
| **Limitations**      | Focuses on US English, limited social bias categories | Reliance on automated toxicity detection which may exhibit biases |
| **Out-of-Scope Uses** | Deploying models without addressing biases | Using generated text without review/filtering |

---

## Data üìÅ

| **Field**            | **BBQ** | **RealToxicityPrompts** |
|----------------------|---------|-------------------------|
| **Source**           | Hand-crafted templates based on social biases | OpenWebText Corpus, Reddit |
| **Size**             | 58,492 unique examples | 100K sentence-level prompts |
| **Format**           | Textual QA pairs with contexts | Textual prompts with toxicity scores |
| **Annotation**       | Crowdsourced validation | Toxicity scores generated by Perspective API |

---

## Methodology ‚öôÔ∏è

| **Field**            | **BBQ** | **RealToxicityPrompts** |
|----------------------|---------|-------------------------|
| **Methods**          | Evaluating responses in ambiguous and disambiguated contexts | Nucleus sampling for text generation. Detoxification through pretraining, attribute conditioning, and word filtering |
| **Pipeline Stage**   | Inference, potential deployment if used for training | Inference, deployment in downstream applications |
| **Metrics**          | Accuracy, Bias Score (sDIS, sAMB) | Expected maximum toxicity, toxicity probability |
| **Calculation**      | Accuracy = % of correct answers. Bias Score = % of non-UNKNOWN answers that align with a social bias | Expected maximum toxicity estimated via bootstrap sampling. Toxicity probability = chance of generating toxic text at least once |
| **Interpretation**   | Higher accuracy = better performance. Higher bias score = stronger reliance on social biases | Higher scores = greater tendency to generate toxic text |
| **Results**          | Results for UnifiedQA, RoBERTa, DeBERTaV3 | Results for GPT-1, GPT-2, GPT-3, CTRL, CTRL-WIKI |
| **Validation**       | Human evaluation on MTurk | Toxicity evaluation via Perspective API |

---

## Risks ‚ö†Ô∏è

| **Field**                  | **BBQ** | **RealToxicityPrompts** |
|----------------------------|---------|-------------------------|
| **Risk Categories**        | Biases related to age, gender, race, religion, and other protected groups in question answering | Risk of generating toxic or harmful language |
| **Limitations**            | Limited to certain social bias categories and US English | Heavily reliant on automated toxicity detection, potential for misclassification |
| **Demographic Analysis**   | Assesses bias across demographic groups | Evaluates toxicity risk across various demographic groups |
| **Harm**                   | Risk of perpetuating harmful stereotypes or biased predictions | Risk of generating offensive or harmful content |

---

## Ethical and Legal Considerations üõ°Ô∏è

| **Field**                | **BBQ** | **RealToxicityPrompts** |
|--------------------------|---------|-------------------------|
| **Privacy and Anonymity** | Synthetic data, no personal information | Data from OpenWebText/Reddit; anonymization efforts made |
| **Data Licensing**        | MIT License | Open Data Commons Attribution (ODC-By) License |
| **Consent Procedures**    | Not applicable | Data from public sources |

---


