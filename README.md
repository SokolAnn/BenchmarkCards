# 📊 BenchmarkCards: Large Language Model and Risk Reporting 📊

Welcome to the **BenchmarkCards** repository! This is where we introduce a structured framework for documenting benchmarks used in large language models (LLMs). Our goal? To make benchmarking LLMs easier, transparent, and more informative by focusing on risks and key metrics.  🚀

---

## 🛠️ How to Use this Repository

### 🔗 Key Contents

- **BenchmarkCard_Template.md**: 📋 A handy template for creating your very own BenchmarkCard for LLM documentation. Keep it consistent and organized!
- **ComparisonBenchmarks.md**: ⚖️ Curious how different benchmarks stack up? This file compares various benchmarks used for LLM risk evaluation.
- **Benchmarks_and_Risk_Table.md**: 🗂 A detailed table with benchmarks found in literature, including key references.
- **Benchmark_Network.md**: 🌐 A visual network that shows how benchmarks connect and relate, especially when it comes to evaluating LLM risks.



