# ğŸ“Š BenchmarkCards: Large Language Model and Risk Reporting ğŸ“Š

Welcome to the **BenchmarkCards** repository! This is where we introduce a structured framework for documenting benchmarks used in large language models (LLMs). Our goal? To make benchmarking LLMs easier, transparent, and more informative by focusing on risks and key metrics.  ğŸš€

---

## ğŸ› ï¸ How to Use this Repository

### ğŸ”— Key Contents

- **BenchmarkCard_Template.md**: ğŸ“‹ A handy template for creating your very own BenchmarkCard for LLM documentation. Keep it consistent and organized!
- **ComparisonBenchmarks.md**: âš–ï¸ Curious how different benchmarks stack up? This file compares various benchmarks used for LLM risk evaluation.
- **Benchmarks_and_Risk_Table.md**: ğŸ—‚ A detailed table with benchmarks found in literature, including key references.
- **Benchmark_Network.md**: ğŸŒ A visual network that shows how benchmarks connect and relate, especially when it comes to evaluating LLM risks.



