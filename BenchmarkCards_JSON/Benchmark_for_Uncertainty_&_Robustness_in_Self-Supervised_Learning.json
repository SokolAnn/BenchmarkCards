{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Benchmark for Uncertainty & Robustness in Self-Supervised Learning",
    "abbreviation": "N/A",
    "overview": "We explore variants of SSL methods for vision and language, train SSL as an auxiliary task for vision and pre-training/fine-tuning for language, then evaluate generalization (in-out classification accuracy) and uncertainty (expected calibration error) across covariate shift datasets (MNIST-C, CIFAR-10-C, CIFAR-10.1, MNLI). Our goal is to create a benchmark with outputs from experiments, providing a starting point for new SSL methods in Reliable Machine Learning.",
    "data_type": "image (classification images, corrupted/shifted images), text (sentence-pair natural language inference)",
    "domains": [
      "Computer Vision",
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "Uncertainty Baselines",
      "lebenchmark",
      "DABS",
      "Scaling and benchmarking self-supervised visual representation learning"
    ],
    "resources": [
      "https://github.com/hamanhbui/reliable_ssl_baselines"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Create a benchmark for a fair comparison between SSL methods in reliable machine learning, including source code, model checkpoints, experiment outputs, and comparing generalization (in-out classification accuracy) and uncertainty (expected calibration error) across covariate shift datasets.",
    "audience": [
      "ML Researchers",
      "Research community"
    ],
    "tasks": [
      "Image Classification",
      "Natural Language Inference",
      "Uncertainty Estimation (Calibration)"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "MNIST-C, CIFAR-10-C, CIFAR-10.1, MultiNLI (as described in paper)",
    "size": "MNIST-C: 10,000 samples; CIFAR-10-C: 10,000 images; CIFAR-10.1: v4 2,021 images, v6 2,000 images; MultiNLI: 433,000 sentence pairs",
    "format": "Raw image tensors with dimensions provided (MNIST-C: (1,28,28); CIFAR-10 variants: (3,32,32)); text sentence-pair files for MultiNLI",
    "annotation": "Original dataset classification labels (MNIST/CIFAR: 10 classes; MultiNLI: 3 classes: entailment, contradiction, neutral)"
  },
  "methodology": {
    "methods": [
      "Automated metrics evaluation (NLL, Accuracy, ECE)",
      "Cross-validation model selection with 10 runs/seeds",
      "Model evaluation across in-distribution and out-of-distribution test sets"
    ],
    "metrics": [
      "Negative Log Likelihood (NLL)",
      "Accuracy",
      "Expected Calibration Error (ECE)"
    ],
    "calculation": "ECE computed using the deterministic method with the max of predictive softmax as referenced (section 2.1). Metrics are averaged over 10 runs (mean and standard deviation). cNLL/cAccuracy/cECE denote metrics averaged over corruption types for corrupted datasets.",
    "interpretation": "Robust generalization measured by in-out classification accuracy (a reliable model is expected to achieve high accuracy in both in- and out-of-distribution). Uncertainty measured by low Expected Calibration Error (ECE); a model is considered reliable if it achieves low ECE in both in-data and out-of-data distributions.",
    "baseline_results": "ERM baselines from Table 1: MNIST & MNIST-C ERM NLL 0.0365, Accuracy 98.87%, ECE 0.0107, cNLL 1.5439, cAccuracy 77.64%, cECE 0.1759. CIFAR-10 & CIFAR-10-C ERM NLL 0.9988, Accuracy 86.85%, ECE 0.1115, cNLL 3.4181, cAccuracy 66.22%, cECE 0.2858. MultiNLI (Table 2) BERT NLL 0.5309, Accuracy 0.8242, ECE 0.1546; GPT2 NLL 0.9205, Accuracy 0.5332, ECE 0.04625 (OOD values also reported in Table 2).",
    "validation": "For vision tasks, merged raw training and validation then ran tests 10 times with 10 different seeds; for each seed randomly split training and validation (80%/20%), selected model maximizing validation accuracy, and reported mean and standard deviation over 10 runs."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Accuracy",
      "Calibration"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Value Alignment",
          "subcategory": [
            "Over- or under-reliance"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}