{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Institutional Books 1.0",
    "abbreviation": "N/A",
    "overview": "This technical report introduces Institutional Books 1.0, a large collection of public domain books originally digitized through Harvard Library’s participation in the Google Books project, processed into an extensive dataset of historic texts, enabling easier access for research and machine learning applications.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing",
      "Education",
      "Historical Research"
    ],
    "languages": [
      "English",
      "German",
      "French",
      "Italian",
      "Spanish",
      "Latin",
      "Russian",
      "Dutch",
      "Portuguese",
      "Hebrew",
      "Chinese",
      "Swedish",
      "Greek",
      "Japanese",
      "Arabic"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://huggingface.co/datasets/instdin/institutional-books-1.0",
      "https://github.com/instdin/institutional-books-1-pipeline",
      "https://huggingface.co/instdin/institutional-books-topic-classifier-bert"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a large, well-documented dataset of public domain texts to improve accessibility and usability for both humans and machines.",
    "audience": [
      "ML Researchers",
      "Academic Researchers",
      "Library Scientists",
      "Data Scientists"
    ],
    "tasks": [
      "Text Classification",
      "Information Retrieval",
      "Language Modeling"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Digitized books from Harvard Library’s collections via the Google Books project.",
    "size": "983,004 volumes, 242B tokens",
    "format": "JSONL, CSV",
    "annotation": "Processed through OCR extraction and additional data cleaning methods."
  },
  "methodology": {
    "methods": [
      "Text classification",
      "Data extraction",
      "OCR processing",
      "Statistical analysis"
    ],
    "metrics": [
      "Token count",
      "Word count",
      "Unique word count",
      "Lexical diversity",
      "OCR quality scores"
    ],
    "calculation": "Metrics are calculated based on the total number of characters, words and other textual elements extracted from the dataset.",
    "interpretation": "High token counts and lexical diversity scores are indicative of rich text content suitable for training language models.",
    "baseline_results": "N/A",
    "validation": "Manual review and automated statistical analysis were conducted to ensure quality and accuracy."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "The dataset includes texts in over 250 different languages, which may have varying representation across topics.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Public domain with restrictions on the use of copyrighted material.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "All datasets are released in compliance with applicable laws regarding public domain works."
  }
}