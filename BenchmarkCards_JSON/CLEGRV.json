{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CLEGRV (Visual Graph Question Answering Dataset)",
    "abbreviation": "CLEGRV",
    "overview": "CLEGRV is a new dataset for benchmarking Visual Question Answering (VQA) systems that focus on images of graphs, particularly inspired by transit networks. The dataset enhances the existing CLEGR dataset by providing images and related questions that can be answered using the visual information provided.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "CLEGR"
    ],
    "resources": [
      "https://github.com/pudumagico/NSGRAPH"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a benchmark for evaluating VQA systems on images of graphs, specifically for questions related to transit networks.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Visual Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated images and questions derived from the existing CLEGR dataset.",
    "size": "3,000 question-answer pairs",
    "format": "JSON",
    "annotation": "Questions are derived from naturally occurring queries related to the graph images."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is calculated based on the correct answers provided for the questions in the VQA task.",
    "interpretation": "An accuracy of 73% indicates the proportion of correctly answered questions by the VQA system.",
    "baseline_results": "An average accuracy of 73% on the CLEGRV dataset.",
    "validation": "Validation of the benchmark was done through evaluation against existing systems and methods."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}