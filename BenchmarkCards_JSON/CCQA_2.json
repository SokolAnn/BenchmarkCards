{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CCQA (Cycle-Consistency in Question Answering)",
    "abbreviation": "CCQA",
    "overview": "CCQA is a novel inference-time reasoning method designed to enhance the reasoning capabilities of small language models (SLMs) by generating questions from candidate solutions and selecting the most consistent response based on similarity to the original question.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "GSM8K",
      "CommonSenseQA",
      "StrategyQA",
      "ARC-Challenge",
      "Multi-Arith",
      "SV AMP"
    ],
    "resources": [
      "https://github.com/scai-research/ccqa_official"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To improve inference-time reasoning in small language models through cycle consistency in question answering.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Mathematical Reasoning",
      "Commonsense Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Evaluated on reasoning benchmarks like GSM8K, SV AMP, CSQA, StrategyQA, and ARC-Challenge.",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is calculated based on how well CCQA performs on various reasoning tasks compared to state-of-the-art methods.",
    "interpretation": "Higher accuracy indicates improved reasoning capability.",
    "baseline_results": "CCQA achieved 69.60% accuracy on GSM8K, outperforming USC at 53.83%; and 38.74% accuracy on CommonSenseQA compared to USC's 33.99%.",
    "validation": "Validated through extensive experiments across multiple reasoning benchmarks."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}