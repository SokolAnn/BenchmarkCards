{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "TRUCE (TRusted UnContaminated Evaluation)",
    "abbreviation": "TRUCE",
    "overview": "TRUCE introduces the concept of Private Benchmarking, ensuring that benchmark datasets are kept private from the model to prevent contamination, while allowing for effective evaluation of LLMs. It builds solutions based on various trust models and demonstrates practical feasibility with experimental evaluation.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/microsoft/private-benchmarking"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of TRUCE is to provide a solution for private benchmarking of LLMs to prevent data contamination during model evaluation.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "N/A",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Trusted model owner evaluation",
      "Trusted dataset owner evaluation",
      "Trusted third party evaluation",
      "Confidential computation",
      "Secure multi-party computation"
    ],
    "metrics": [],
    "calculation": "The evaluation computes metrics based on the outputs of the LLM against the private benchmark data.",
    "interpretation": "N/A",
    "baseline_results": "N/A",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Data privacy rights alignment"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "MIT",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}