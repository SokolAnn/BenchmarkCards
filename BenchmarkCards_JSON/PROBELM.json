{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "PROBELM (Plausibility Ranking Evaluation for Language Models)",
    "abbreviation": "PROBELM",
    "overview": "PROBELM is a benchmark designed to assess language models’ ability to discern more plausible from less plausible scenarios through their parametric knowledge. It evaluates models' capabilities to prioritize plausible scenarios that leverage world knowledge over less plausible alternatives.",
    "data_type": "scenario ranking",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "TruthfulQA",
      "COPA"
    ],
    "resources": [
      "https://huggingface.co/datasets/MoyYuan/PRobELM"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate language models’ ability to discern plausible scenarios and fill a gap left by benchmarks focused on factual accuracy.",
    "audience": [
      "ML Researchers",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Plausibility Ranking",
      "Scenario Evaluation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Wikidata edit histories",
    "size": "126,000 scenarios",
    "format": "JSON",
    "annotation": "Automatically generated less plausible scenarios based on statistical techniques."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "Mean Reciprocal Rank (MRR)",
      "Normalized Discounted Cumulative Gain (NDCG)"
    ],
    "calculation": "Metrics are calculated based on the ranking of scenarios assessed by model outputs.",
    "interpretation": "Higher scores indicate better ability to discern the most plausible scenario among alternatives.",
    "baseline_results": null,
    "validation": "Evaluated models were assessed against four distinct timeframes."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}