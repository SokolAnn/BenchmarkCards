{
  "benchmark_details": {
    "name": "THRONE",
    "overview": "THRONE is a novel object-based automatic framework for quantitatively evaluating Type I hallucinations in large vision-language models (LVLMs) when generating free-form image descriptions.",
    "data_type": "Images and text responses",
    "domains": [
      "Vision-Language",
      "Image Description"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "POPE",
      "CHAIR"
    ],
    "resources": [
      "COCO dataset",
      "Objects365 dataset",
      "Open-source FLAN-T5 models"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate and mitigate hallucinations in large vision-language models.",
    "audience": [
      "Researchers in AI and machine learning",
      "Developers of vision-language models"
    ],
    "tasks": [
      "Evaluate hallucinations in image descriptions generated by LVLMs",
      "Benchmark different LVLMs on Type I hallucinations"
    ],
    "limitations": "THRONE focuses solely on measuring Type I hallucinations and does not consider other types of hallucinations.",
    "out_of_scope_uses": null
  },
  "data": {
    "source": "COCO and Objects365 datasets",
    "size": "COCO validation set: 5000 images; Objects365 validation subset: 5110 images",
    "format": "Images and human annotations",
    "annotation": "Annotations of objects present in images provided by COCO and Objects365 datasets."
  },
  "methodology": {
    "methods": [
      "Quantitative evaluation of hallucinations using Type I and Type II classifications",
      "Leveraging public language models for evaluation"
    ],
    "metrics": [
      "Overall Precision (PALL)",
      "Overall Recall (RALL)",
      "Class-wise Precision (PCLS)",
      "Class-wise Recall (RCLS)",
      "F0.5-score"
    ],
    "calculation": "Metrics are calculated based on the comparison of predicted object labels from LVLM responses against ground truth data.",
    "interpretation": "Higher precision indicates fewer Type I hallucinations in responses.",
    "baseline_results": "The paper compares THRONE results with existing benchmarks, showing considerable improvement in precision.",
    "validation": "Validated using human oracle evaluations alongside automated methods."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias",
            "Output bias"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data",
            "Data privacy rights alignment"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": "Potential for hallucinations leading to misinformation or incorrect conclusions drawn from visual data."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "THRONE utilizes publicly available datasets ensuring no sensitive personal data is mixed.",
    "data_licensing": "Uses publicly available datasets (COCO and Objects365) under their respective licenses.",
    "consent_procedures": "Not applicable as the dataset does not involve personal data.",
    "compliance_with_regulations": "Adheres to ethical standards in AI research and data usage."
  }
}