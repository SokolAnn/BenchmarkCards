{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "PeanoBench",
    "abbreviation": "N/A",
    "overview": "PeanoBench is a human-written dataset derived from the Natural Numbers Game, consisting of 371 Peano Arithmetic proofs, where each natural language proof step is paired with the corresponding logically equivalent tactic in Lean.",
    "data_type": "proof pairs",
    "domains": [
      "Education"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2506.08321"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the LeanTutor system designed to assist students in writing mathematical proofs through formal verification and feedback.",
    "audience": [
      "Educators",
      "Students",
      "Educational Researchers"
    ],
    "tasks": [
      "Mathematical Proof Verification",
      "Educational Feedback Generation"
    ],
    "limitations": "The dataset includes assumptions such as one-to-one correspondence between natural language proof steps and formal language tactics, which may not scale to more complicated proofs.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Derived from the Natural Numbers Game, specifically annotated by authors.",
    "size": "371 proofs",
    "format": "JSON",
    "annotation": "Annotated by authors to create a one-to-one correspondence between natural language proof steps and Lean tactics."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "Relevance"
    ],
    "calculation": "Metrics are assessed based on the performance of LeanTutor's system compared to baselines concerning correctness and relevance of feedback provided.",
    "interpretation": "Higher scores indicate better performance in feedback accuracy and relevance.",
    "baseline_results": "LeanTutor outperformed baseline models with significant improvements in the accuracy and relevance of generated feedback.",
    "validation": "Results were validated through human evaluator assessments across multiple proof categories."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "The system aims to reduce the potential harm of misguidance by providing feedback that helps students identify specific errors in their reasoning."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Apache-2.0 license for the original dataset used.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}