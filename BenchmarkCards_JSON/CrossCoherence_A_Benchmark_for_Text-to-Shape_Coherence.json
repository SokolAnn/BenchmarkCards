{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CrossCoherence: A Benchmark for Text-to-Shape Coherence",
    "abbreviation": "N/A",
    "overview": "We propose the first benchmark for text-to-shape generation and manipulation that addresses the lack of high-quality paired text-3D datasets and effective metrics to evaluate coherence between generated 3D shapes and input textual descriptions, including a refined dataset, a new quantitative metric called CrossCoherence, and a human-validated dataset.",
    "data_type": "shape-text pairs",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "Text2Shape"
    ],
    "resources": [
      "https://cvlab-unibo.github.io/CrossCoherence-Web/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a comprehensive benchmark for evaluating the coherence between textual descriptions and 3D shapes generated from those descriptions.",
    "audience": [
      "ML Researchers",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Text-to-Shape Generation",
      "Shape Recognition"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "GPT2Shape, a refined dataset generated using improved text descriptions for existing shapes from Text2Shape based on human evaluation.",
    "size": "15,032 shapes, with a total of 75,358 shape-text pairs",
    "format": "N/A",
    "annotation": "Automatically refined descriptions generated by a large language model (GPT-3) and validated through user studies."
  },
  "methodology": {
    "methods": [
      "User evaluation",
      "Quantitative comparison of coherence metrics"
    ],
    "metrics": [
      "CrossCoherence",
      "CLIP-Similarity",
      "ShapeGlot"
    ],
    "calculation": "Metrics are calculated based on the coherence scores derived from shape-text relations evaluated via cross-attention mechanisms.",
    "interpretation": "Higher scores indicate stronger coherence between the generated shape and the corresponding text description.",
    "baseline_results": "CrossCoherence achieved 81.04% accuracy on chairs, outperforming other existing metrics.",
    "validation": "Validated through human evaluation, using a user study comparing the quality of text descriptions."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}