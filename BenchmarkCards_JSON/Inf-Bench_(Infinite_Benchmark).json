{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Inf-Bench (Infinite Benchmark)",
    "abbreviation": "N/A",
    "overview": "Inf-Bench is a newly proposed benchmark designed to evaluate the performance of Vision-Language Models (VLMs) in spatial deformation reasoning tasks. It encompasses forward and inverse reasoning tasks across 2D, 2.5D, and 3D spaces, highlighting the limitations of current models in handling complex spatial transformations.",
    "data_type": "question-answering pairs",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "VSI-Bench",
      "SPGym",
      "iVISPAR"
    ],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To systematically evaluate the spatial deformation reasoning abilities of Vision-Language Models, identifying their capabilities and limitations in layered shape manipulations.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Spatial Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated by a fully automated data engine ensuring diversity and non-overlapping evaluation problem pairs.",
    "size": "Unlimited evaluation pairs",
    "format": "Structured question formats",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Ladder competition format for evaluation",
      "Automated metrics based on the highest difficulty level achieved"
    ],
    "metrics": [
      "Reasoning depth"
    ],
    "calculation": "The reasoning depth is determined by the highest level (number of deformation steps) successfully completed by the models.",
    "interpretation": "Higher scores indicate better spatial deformation reasoning capabilities in models.",
    "baseline_results": null,
    "validation": "Models must answer a series of progressively difficult tasks; failure to succeed at a level results in demotion or termination of the evaluation."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Hallucination"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}