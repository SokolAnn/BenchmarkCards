{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "FFR Dataset",
    "abbreviation": "FFR",
    "overview": "The FFR Dataset is a corpus of Fon-to-French parallel sentences created to compile a large, growing corpus of carefully cleaned Fon-French parallel sentences for machine translation and other NLP research-related projects; the dataset and model are made publicly available to promote collaboration and reproducibility.",
    "data_type": "text (parallel Fon-French sentence pairs)",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Fon",
      "French"
    ],
    "similar_benchmarks": [
      "JW300",
      "BeninLangues"
    ],
    "resources": [
      "https://github.com/bonaventuredossou/ffr-v1",
      "https://github.com/bonaventuredossou/ffr-v1/blob/master/FFR-Dataset/Data_Statement_FFR_Dataset.pdf",
      "https://github.com/bonaventuredossou/ffr-v1/blob/master/model_train_test/fon_fr.py",
      "http://creativecommons.org/licenses/by/4.0/",
      "https://beninlangues.com/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Compile a large, growing corpus of carefully cleaned Fon-French parallel sentences for machine translation, and other NLP research-related projects.",
    "audience": [
      "Researchers",
      "Public"
    ],
    "tasks": [
      "Machine Translation"
    ],
    "limitations": "Project is at the pilot stage and therefore there is headroom to be explored with tuning of different architectures, learning schemes, transfer learning, tokenization methods, data augmentation, and training on state-of-the-art Transformer models.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Compiled from JW300 and BeninLangues. FFR1 initial sources: JW300 (27,980 aligned sentences) and BeninLangues (89,049 aligned sentences) giving a total of 117,029 parallel sentences. FFR2 re-evaluated and reduced JW and BeninLangues original samples to 26,510 and 27,465 Fon-French parallel sentences respectively.",
    "size": "FFR1: 117,029 parallel sentences; FFR2: (derived counts) training 43,719, validation 4,858, testing 5,398",
    "format": "N/A",
    "annotation": "Initial cleaning using rule-based preprocessing (Python regex, NLTK). FFR2 obtained after re-evaluation of translations in FFR1 by FFR native speakers."
  },
  "methodology": {
    "methods": [
      "Automated metrics (BLEU, GLEU)",
      "Human evaluation using the Context-Meaning-Similarity (CMS) metric with native speakers"
    ],
    "metrics": [
      "BLEU",
      "GLEU",
      "Context-Meaning-Similarity (CMS)"
    ],
    "calculation": "BLEU and GLEU computed on test data as standard automatic metrics. CMS: a subset of 100 specially selected source, target and predicted sentences was rated by five FFR natives. For each source and prediction, natives gave a score t in [0,1] for contextual similarity without reference; then gave a score tr when shown source, prediction and reference. Total score t_total = alpha * t + (1 - alpha) * tr. For the experiment alpha = 0.7. The average of these scores is the CMS score.",
    "interpretation": "Higher BLEU and GLEU indicate better automatic translation quality; the paper reports that training with diacritical encoding (DE) improved BLEU and GLEU. CMS yields an average score in [0,1] representing contextual similarity as judged by native speakers; the parameter alpha controls the tradeoff between judgment of the prediction alone and judgment with the reference. The authors note CMS is especially useful for languages with many dialects and multiple valid expressions.",
    "baseline_results": "Evaluation scores on test data (Table 2): FFR1 Without DE: BLEU 24.53, GLEU 13.0. FFR1 With DE: BLEU 30.55, GLEU 18.18. FFR2 Without DE: BLEU 27.80, GLEU 17.05. FFR2 With DE: BLEU 37.15, GLEU 20.85. Sample CMS/BLEU scores (Table 3): examples show BLEU/CMS: 1.0; 1.0; 0.0; 0.0; 0.0/0.95; 0.25/0.9 (as presented in the paper).",
    "validation": "FFR2 was produced after re-evaluation of FFR1 translations by FFR native speakers. CMS validation used five FFR natives to rate a 100-sentence subset; the authors also produced a data statement for FFR2."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}