{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "IndoToxic2024 (A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language)",
    "abbreviation": "IndoToxic2024",
    "overview": "IndoToxic2024 is a comprehensive Indonesian hate speech and toxicity classification dataset comprising 43,692 entries annotated by 19 diverse individuals. It focuses on texts targeting vulnerable groups in Indonesia, particularly during the 2024 presidential election.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Indonesian"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/izzako/IndoToxic2024/tree/main"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To enable the creation of better hate speech detection systems specifically for the Indonesian language.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Hate Speech Detection",
      "Toxicity Classification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Collected from social media platforms including Facebook, Instagram, and Twitter, as well as articles from CekFakta.",
    "size": "43,692 examples",
    "format": "N/A",
    "annotation": "Annotated by 19 diverse individuals with ten-dimensional demographic information."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "F1 Score",
      "Accuracy"
    ],
    "calculation": "Macro F1 score calculated across various classification tasks.",
    "interpretation": "A macro F1 score above 0.7 indicates good performance in hate speech detection tasks.",
    "baseline_results": "Achieved a macro F1 score of 0.78 with IndoBERTweet fine-tuned for hate speech classification.",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "The dataset and the annotation process incorporates demographic information to assess the biases in hate speech detection.",
    "harm": "The creation of the dataset could inadvertently lead to models generating or amplifying hate speech."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Annotators were warned and asked for consent. They had the option to quit if they felt unable to continue.",
    "data_licensing": "N/A",
    "consent_procedures": "Annotators were compensated and warned of potential harm.",
    "compliance_with_regulations": "N/A"
  }
}