{
  "benchmark_details": {
    "name": "HypoTermQA",
    "overview": "HypoTermQA is a benchmarking dataset introduced for evaluating the hallucination tendency of Large Language Models (LLMs). It focuses on generating challenging questions related to hypothetical phenomena to assess how models handle non-existent terms.",
    "data_type": "Benchmarking Dataset",
    "domains": [
      "General",
      "Law",
      "Health",
      "Finance"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "HaluEval",
      "PHD",
      "AutoHall"
    ],
    "resources": [
      "https://github.com/cemuluoglakci/HypoTermQA"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To create a framework for benchmarking hallucination tendencies in LLMs and evaluate their performance in handling hypothetical terms.",
    "audience": [
      "Researchers",
      "Developers",
      "Academics"
    ],
    "tasks": [
      "Evaluating hallucination tendencies of LLMs",
      "Generating benchmarking datasets for specific domains"
    ],
    "limitations": "The dataset is focused exclusively on hypothetical terms and may not cover all aspects of LLM performance or other types of hallucinations.",
    "out_of_scope_uses": [
      "Training language models",
      "General natural language processing tasks"
    ]
  },
  "data": {
    "source": "OpenAI's GPT-3.5 model output",
    "size": "19,508 questions",
    "format": "Text",
    "annotation": "Each question is categorized as hypothetical or valid based on the terms used."
  },
  "methodology": {
    "methods": [
      "Automated question generation",
      "LLM performance evaluation",
      "Hypothetical and valid term creation"
    ],
    "metrics": [
      "HypoTermQA Score",
      "Error rate"
    ],
    "calculation": "HypoTermQA Score is calculated as the percentage of valid answers to hypothetical questions.",
    "interpretation": "A higher score indicates better performance in resisting hallucination.",
    "baseline_results": "Both GPT-3.5 and Llama2-70B models scored around 5.7% for hypothetical questions.",
    "validation": "Evaluated using a combination of programmatic checks and LLM responses."
  },
  "targeted_risks": {
    "risk_categories": [
      "Hallucination tendencies",
      "Evaluation biases",
      "Improper generalization"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Prompt injection attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Misleading information generation",
      "Increased reliance on factual inaccuracies"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "The dataset is publicly available under specified usage policies.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}