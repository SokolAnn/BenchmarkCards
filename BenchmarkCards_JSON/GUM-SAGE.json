{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "GUM-SAGE (GUM-based Summary Aligned Graded Entities)",
    "abbreviation": "GUM-SAGE",
    "overview": "GUM-SAGE is a novel dataset for graded entity salience prediction, combining human summaries and aligning them to document entities to derive salience scores. It spans multiple genres and provides graded salience scores for named and non-named entities.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/jl908069/gum_sum_salience1"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To improve graded salient entity extraction and support further research on entity salience prediction and summarization.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Entity Salience Prediction",
      "Summarization"
    ],
    "limitations": "The dataset is limited to English, and relies on multiple high-quality summaries which can introduce scalability challenges.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "GUM corpus (Zeldes, 2017), enriched with human and model-generated summaries.",
    "size": "213 documents, over 200K tokens",
    "format": "N/A",
    "annotation": "Data was annotated using crowdsourcing methods for summaries and alignment with expert-written quality control."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "F1 Score",
      "Spearman correlation"
    ],
    "calculation": "F1 Score is calculated based on the model's ability to classify entities into graded salience scores (1-5), and Spearman's ρ measures the correlation between predicted and human-aggregated scores.",
    "interpretation": "Higher F1 scores indicate better agreement with human judgments on entity salience. Spearman's ρ close to 1 indicates strong correlation.",
    "baseline_results": "Position baseline model indicated lower performance in salience ranking with Spearman's ρ of 0.153.",
    "validation": "Validation conducted using separate test and development sets from the GUM corpus."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "The dataset spans multiple genres but is limited to English.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "All summaries were collected with explicit consent.",
    "data_licensing": "Released under a CC0 license.",
    "consent_procedures": "Annotators consented to data sharing for research purposes.",
    "compliance_with_regulations": "N/A"
  }
}