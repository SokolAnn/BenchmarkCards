{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "TrajVL",
    "abbreviation": "N/A",
    "overview": "TrajVL is the first benchmark dataset specifically designed for the Text-to-TrajVis domain, containing 18,140 (question, TVL) pairs aimed at transforming natural language questions into trajectory data visualizations.",
    "data_type": "question-Trajectory Visualization Language (TVL) pairs",
    "domains": [
      "Natural Language Processing",
      "Data Visualization"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "nvBench",
      "Dial-NVBench"
    ],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a dataset for benchmarking the Text-to-TrajVis task, facilitating the translation of natural language queries into trajectory visualizations.",
    "audience": [
      "ML Researchers",
      "Data Visualization Practitioners"
    ],
    "tasks": [
      "Text-to-Visualization"
    ],
    "limitations": "The dataset is limited to trajectory data from a single source (GeoLife project dataset), which may not cover all real-world spatio-temporal scenarios exhaustively.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "GeoLife project dataset",
    "size": "18,140 question-TVL pairs",
    "format": "N/A",
    "annotation": "Generated using Large Language Models with manual verification"
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Manual evaluation"
    ],
    "metrics": [
      "Visual Accuracy",
      "Axis Accuracy",
      "Data Accuracy",
      "Area Accuracy",
      "Time Accuracy",
      "SQL Accuracy",
      "TVL Accuracy"
    ],
    "calculation": "Metrics are calculated based on the model's ability to accurately generate specified visual types, recognize geographic areas, and handle temporal information within generated TVLs.",
    "interpretation": "Higher accuracy rates indicate better model performance in generating accurate and contextually appropriate trajectory visualizations from natural language inputs.",
    "baseline_results": "Baseline performance established by multiple LLMs, with the highest achieving 74.61% TVL accuracy under normal conditions.",
    "validation": "The model's evaluations involved multiple experiments with diverse LLMs under varying configurations to assess performance."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Privacy",
      "Robustness",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}