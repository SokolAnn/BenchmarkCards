{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "OptiSeq: Ordering Examples On-The-Fly for In-Context Learning",
    "abbreviation": "OptiSeq",
    "overview": "OptiSeq is a novel method that orders in-context examples dynamically at inference time to enhance the performance of large language models on various tasks. It improves accuracy by optimizing the sequence of examples presented to the model, as shown through extensive empirical evaluation across multiple datasets and tasks.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "ToolBench",
      "RestGPT",
      "AG News",
      "SST-5",
      "TREC"
    ],
    "resources": [
      "https://arxiv.org/abs/2501.15030"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To optimize the ordering of in-context examples for large language models at inference time to improve task performance.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "API Sequence Generation",
      "Text Classification"
    ],
    "limitations": "OptiSeq requires evaluating k=|E|! permutations, which introduces computational challenges as the number of in-context examples grows.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "The datasets used include ToolBench, RestGPT, AG News, SST-5, and TREC, each containing various instances for evaluation.",
    "size": "Multiple datasets with various numbers of instances (e.g., 100 classes in ToolBench, 75 in RestGPT, etc.)",
    "format": "N/A",
    "annotation": "Data is pre-existing datasets that do not require additional annotation."
  },
  "methodology": {
    "methods": [
      "Empirical evaluation across datasets",
      "Performance comparison against random and Top-K selections"
    ],
    "metrics": [
      "Accuracy",
      "Precision",
      "Recall"
    ],
    "calculation": "Accuracy is based on exact matching of generated API sequences with ground truth; Precision and Recall represent relevancy in predictions.",
    "interpretation": "Higher values in Accuracy, Precision, and Recall indicate better performance of the model with respect to the correct API selection.",
    "baseline_results": "OptiSeq improves accuracy by 10.5 percentage points over random selection, and 6.5 percentage points over Top-K selection across various tasks.",
    "validation": "The benchmarks were validated through empirical evaluation comparing outputs with different ordering strategies."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}