{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CORE-Bench (Computational Reproducibility Agent Benchmark)",
    "abbreviation": "CORE-Bench",
    "overview": "CORE-Bench consists of 270 tasks derived from 90 papers across computer science, social science, and medicine, designed to evaluate agents on their ability to reproduce the results of scientific studies using provided code and data.",
    "data_type": "language-only and vision-language tasks",
    "domains": [
      "Natural Language Processing",
      "Computer Science",
      "Medicine",
      "Social Science"
    ],
    "languages": [
      "Python",
      "R"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/siegelz/core-bench"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the ability of AI agents to reproduce scientific results, improving computational reproducibility in research.",
    "audience": [
      "AI Researchers",
      "Domain Experts",
      "Model Developers"
    ],
    "tasks": [
      "Computational Reproducibility"
    ],
    "limitations": "Limited accuracy of baseline agents demonstrated the need for further development.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "CodeOcean repositories with verified reproducibility.",
    "size": "270 tasks",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Agent-based evaluation"
    ],
    "metrics": [
      "Task accuracy"
    ],
    "calculation": "Accuracy calculated as the proportion of tasks for which all task questions have been answered correctly.",
    "interpretation": "Higher accuracy indicates better agent performance in reproducing scientific results.",
    "baseline_results": "CORE-Agent achieved 60% accuracy on the easiest tasks.",
    "validation": "Tasks validated through multiple evaluations of agents and manual reproduction."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}