{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "AttentionSpan",
    "abbreviation": "N/A",
    "overview": "AttentionSpan is an algorithmic benchmark comprising five tasks of infinite input domains aimed at assessing the reliability and robustness of transformer models in algorithmic reasoning, specifically their ability to extrapolate to unseen types of inputs and to analyze attention mechanisms.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "CRLS-Text",
      "BIG-Bench"
    ],
    "resources": [
      "https://github.com/michalspiegel/AttentionSpan"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the reasoning robustness of transformers and trace the attention mechanisms in algorithmic tasks.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Algorithmic Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic generation of tasks including string reversal, long addition, long multiplication, flip-flop language modeling, and value assignment.",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Evaluation of attention patterns",
      "Intervention experiments"
    ],
    "metrics": [
      "Accuracy",
      "Partial Accuracy"
    ],
    "calculation": "Exact-match accuracy of output sequences and calculation of partial accuracy based on correct token predictions.",
    "interpretation": "An evaluation of model accuracy on in-distribution and out-of-distribution tasks reveals the reliability of attention mechanisms.",
    "baseline_results": "N/A",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}