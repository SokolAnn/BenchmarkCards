{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MANITWEET",
    "abbreviation": "MANITWEET",
    "overview": "Introduces the task \"identifying manipulation of news on social media\" and presents MANITWEET, a curated dataset of 3.6K tweets paired with corresponding news articles to detect whether and how social media posts manipulate information presented in associated news articles.",
    "data_type": "text (tweet-article pairs)",
    "domains": [
      "Natural Language Processing",
      "Social Media"
    ],
    "languages": null,
    "similar_benchmarks": [
      "FakeNewsNet",
      "FEVER",
      "SCIFACT",
      "LIAR",
      "X-Fact",
      "NEWS-DISCOURSE"
    ],
    "resources": [
      "https://huggingface.co/allenai/led-base-16384",
      "https://sharegpt.com/",
      "https://github.com/tatsu-lab/stanford_alpaca"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Determine whether and how a social media post (tweet) manipulates the associated news article, and localize the manipulating span and the pristine span.",
    "audience": [
      "Researchers"
    ],
    "tasks": [
      "Text Classification (Tweet manipulation detection)",
      "Span Extraction (Manipulating span localization)",
      "Span Extraction (Pristine span localization)"
    ],
    "limitations": "Training set is largely machine-generated while the test set is human-written, introducing distributional discrepancies. The dataset and annotation pipeline focus on three entity types (LOCATION, PEOPLE, EVENT) and may fail for complex manipulations beyond entity-level perturbations. Data creation uses LLMs (ChatGPT), which may introduce biases and artifacts. Prompting strategies for LLM baselines were limited to ICL and CoT as described.",
    "out_of_scope_uses": [
      "The fake news and manipulating tweets in MANITWEET cannot be used to train text generators for malicious purposes.",
      "Use the manipulation prompts discussed in this paper to generate tweets and spread false information.",
      "The fake news in MANITWEET should not be used as evidence for fact-checking claims."
    ]
  },
  "data": {
    "source": "Repurposed news articles and associated tweets from the FakeNewsNet dataset (Shu et al., 2020). Machine-generated tweets were produced using ChatGPT for training/dev data; human-written tweets from FakeNewsNet were annotated for the test set.",
    "size": "3,636 tweets associated with 2,688 news articles (dataset total: 3,636 examples)",
    "format": "N/A",
    "annotation": "Two-stage annotation: (1) ChatGPT-generated tweets validated by Amazon Mechanical Turk (AMT) workers with graduate student re-validation (first round) to collect machine-generated, human-validated samples; (2) a seq2seq model trained on round-1 data used to identify candidate human-written MANI/NOMANI tweets which were then annotated/validated by AMT (second round). Annotator qualification: U.S.-based, >10,000 HITs, 99% acceptance. Inter-annotator agreement: Fleiss' κ = 62.4% during qualification; graduate student vs. MTurk validation Cohen's κ = 93.1% (first round) and 73.0% (second round)."
  },
  "methodology": {
    "methods": [
      "Automated metrics (Exact Match, ROUGE-L, Overlap F1, Macro F1)",
      "Model-based evaluation (fine-tuned seq2seq LED-FT and LLM prompting: ChatGPT, Vicuna, GPT-4)",
      "Human evaluation (graduate student annotation as an approximate human performance estimate)"
    ],
    "metrics": [
      "Macro F1",
      "Exact Match",
      "Macro Overlap F1",
      "ROUGE-L"
    ],
    "calculation": "Subtask 1 (binary classification): Macro F1. Subtasks 2 and 3 (span localization): Exact Match, Macro Overlap F1, and ROUGE-L to allow partial credit for partially-correct spans.",
    "interpretation": "Higher Macro F1 indicates better manipulation detection. For span localization, higher Exact Match, Overlap F1, and ROUGE-L indicate better identification of manipulating/pristine spans; partial credit is allowed via overlap and ROUGE-L. Human performance (graduate student) is reported as a reference upper bound; LLM prompting (zero-/few-shot) generally underperforms compared to fine-tuned models on this dataset.",
    "baseline_results": "Key results on the MANITWEET test set: Human (approximate) Subtask1 Macro F1 = 89.92%. Vicuna Zero-shot Subtask1 Macro F1 = 47.09%. ChatGPT Zero-shot Subtask1 Macro F1 = 52.49%; ChatGPT Two-shot ICL Subtask1 Macro F1 = 65.28%. LED-FT (Ours, fine-tuned) Subtask1 Macro F1 = 72.62%. LLM + LED-FT (Ours) Subtask1 Macro F1 = 73.46%. (See Table 2 and Table 4 in the paper for full per-subtask and per-metric results, including GPT-4 evaluations.)",
    "validation": "Test set consists of human-written tweets annotated in the second round. Validation included annotator qualification, inter-annotator agreement measurements (Fleiss' κ and Cohen's κ), and graduate student re-validation; samples where graduate student disagreed with MTurk annotation were discarded in round 1. The 3K machine-validated samples were split (2,316:800) for training and validation of the seq2seq model used to select human-written candidates for round 2."
  },
  "targeted_risks": {
    "risk_categories": [
      "Misuse",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Misuse",
          "subcategory": [
            "Spreading disinformation"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": [
      "Malicious users could utilize the manipulating tweets or fake news articles to train a text generator for creating deceptive content.",
      "Using the manipulation prompts or generated tweets to spread false information.",
      "Fake news in MANITWEET should not be used as evidence for fact-checking claims."
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "The dataset's human-written tweets are anonymized; all associated news articles were already publicly available. The authors state the dataset does not pose significant privacy concerns.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}