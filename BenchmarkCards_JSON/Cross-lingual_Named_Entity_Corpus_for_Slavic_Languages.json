{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Cross-lingual Named Entity Corpus for Slavic Languages",
    "abbreviation": "N/A",
    "overview": "This paper presents a corpus manually annotated with named entities for six Slavic languages, consisting of 5017 documents annotated with five classes of named entities. It aims to foster research in named entity recognition and linking across multiple Slavic languages.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Bulgarian",
      "Czech",
      "Polish",
      "Slovenian",
      "Russian",
      "Ukrainian"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/SlavicNLP/SlavicNER",
      "https://bsnlp.cs.helsinki.fi/SlavicNER"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a high-quality dataset for named entity recognition, linking, and lemmatization across Slavic languages.",
    "audience": [
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Named Entity Recognition",
      "Named Entity Linking",
      "Lemmatization"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Manually annotated corpus derived from online news articles in six Slavic languages.",
    "size": "5017 documents, 152,888 named-entity mentions",
    "format": "Annotated text files",
    "annotation": "Manual annotation by native speakers with multiple consistency checks."
  },
  "methodology": {
    "methods": [
      "Baseline evaluation using transformer-based models"
    ],
    "metrics": [
      "F1 Score"
    ],
    "calculation": "The F1 Score is calculated over the various categories of named entities, using standard evaluation procedures.",
    "interpretation": "Higher F1 Scores indicate better performance in correctly identifying and categorizing named entities.",
    "baseline_results": "Micro-averaged F-score of 0.8503 (single topic out), 0.9222 (cross topics).",
    "validation": "Cross-validation techniques were utilized to ensure the reliability of the benchmark."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}