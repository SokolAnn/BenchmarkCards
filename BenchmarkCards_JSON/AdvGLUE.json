{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Adversarial GLUE (AdvGLUE)",
    "abbreviation": "AdvGLUE",
    "overview": "Adversarial GLUE (AdvGLUE) is a new multi-task benchmark to quantitatively and thoroughly explore and evaluate the vulnerabilities of modern large-scale language models under various types of adversarial attacks, constructed by applying 14 textual adversarial attack methods to GLUE tasks.",
    "data_type": "adversarial examples for language understanding tasks",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "GLUE",
      "SuperGLUE"
    ],
    "resources": [
      "https://adversarialglue.github.io"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a cohesive and principled benchmark for evaluating the robustness of language models against adversarial attacks.",
    "audience": [
      "Research community",
      "ML Researchers",
      "Corporations developing NLP applications",
      "Model Developers"
    ],
    "tasks": [
      "Sentiment Analysis",
      "Question Answering",
      "Natural Language Inference"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated adversarial examples based on GLUE benchmark tasks using multiple adversarial attack methods and human-annotated samples.",
    "size": "5,563 adversarial examples",
    "format": "N/A",
    "annotation": "Crowdsourced evaluations for verification of adversarial perturbations."
  },
  "methodology": {
    "methods": [
      "Manual evaluation",
      "Adversarial attack simulation"
    ],
    "metrics": [
      "Attack Success Rate (ASR)",
      "Curated Attack Success Rate (Curated ASR)"
    ],
    "calculation": "ASR measures the effectiveness of adversarial attacks by assessing how many perturbed examples mislead the models.",
    "interpretation": "A lower score indicates a model's robustness against adversarial examples; higher ASR indicates vulnerability.",
    "baseline_results": "Models were evaluated against the standard GLUE accuracy and compared to their performance on AdvGLUE.",
    "validation": "Human evaluation and automatic filtering process were applied to ensure the quality of adversarial examples."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "CC BY-SA 4.0",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}