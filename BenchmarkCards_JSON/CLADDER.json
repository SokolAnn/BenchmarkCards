{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CLADDER",
    "abbreviation": "N/A",
    "overview": "CLADDER is a dataset designed to evaluate the ability of large language models to perform causal reasoning by presenting them with causal inference questions based on structured causal graphs. The dataset includes over 10,000 samples and is grounded in formal causal inference rules.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "CRASS"
    ],
    "resources": [
      "https://huggingface.co/datasets/causalNLP/cladder",
      "https://github.com/causalNLP/cladder"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the formal causal reasoning abilities of large language models.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Causal Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated dataset based on causal inference principles and causal graphs.",
    "size": "10,112 samples",
    "format": "JSON",
    "annotation": "Automatically generated using a causal inference engine."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Results computed based on model predictions against ground-truth answers.",
    "interpretation": "Accuracy measures the proportion of correct responses out of total questions.",
    "baseline_results": "Vanilla GPT-4 achieves an accuracy of 62.03%. With CAUSAL COT, it improves to 70.40%.",
    "validation": "Extensive experiments conducted on various language models to verify the effectiveness of the dataset."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Hallucination"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}