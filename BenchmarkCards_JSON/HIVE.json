{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "HIVE (Hybrid Intelligence for Vast Engagements)",
    "abbreviation": "HIVE",
    "overview": "HIVE introduces a real-time strategy game benchmark designed to evaluate the abilities of Large Language Models (LLMs) in coordinating swarms of agents via natural language dialog, focusing on tasks such as agent movement coordination, exploitation of unit weaknesses, and strategic planning.",
    "data_type": "multi-agent coordination tasks",
    "domains": [
      "Natural Language Processing",
      "Computer Vision",
      "Robotics"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://hive.syrkis.com"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the performance of LLMs in coordinating multiple agents to complete complex tasks in a simulated environment.",
    "audience": [
      "Research Scientists",
      "AI Practitioners",
      "Game Developers"
    ],
    "tasks": [
      "Coordination",
      "Strategic Planning",
      "Exploiting Weaknesses",
      "Terrain Utilization"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Tasks designed with game environments and scenarios for LLMs",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Success rate in achieving game objectives",
      "Performance of LLMs in creating effective coordination plans"
    ],
    "calculation": "Success rates are calculated based on the number of objectives completed within set time limits across various scenarios.",
    "interpretation": "A higher success rate indicates better performance in completing the strategic game tasks designed for LLMs.",
    "baseline_results": "N/A",
    "validation": "Scenarios validated through multiple runs with various LLM configurations."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Output bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}