{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "BASIC (Benchmark for Assessing Gender, Race, and Color Stereotypes)",
    "abbreviation": "BASIC",
    "overview": "BASIC is a benchmark for assessing gender, race, and color stereotypes in large vision language models (LVLMs), designed to evaluate the impact of these attributes on the models' outputs.",
    "data_type": "image pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate stereotypes in large vision language models using the Stereotype Content Model.",
    "audience": [
      "AI Researchers",
      "Machine Learning Practitioners"
    ],
    "tasks": [
      "Bias Detection",
      "Stereotype Analysis"
    ],
    "limitations": "While our study presents SCM-based evaluation metrics and introduces BASIC, three limitations remain. First, our findings may not be fully independent from other visual attributes. Second, our findings suggest correlations between architectural differences and stereotype presence without proving causation. Third, we conducted our experiment only in English.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated images simulating various occupations with controlled color and demographic attributes.",
    "size": "18,360 images",
    "format": "JPEG",
    "annotation": "Automatically generated with human oversight to ensure quality."
  },
  "methodology": {
    "methods": [
      "Statistical tests",
      "Pointwise mutual information (PMI) analysis"
    ],
    "metrics": [
      "Competence",
      "Warmth"
    ],
    "calculation": "Metrics are calculated based on word embeddings projected onto the axes of competence and warmth.",
    "interpretation": "Higher scores signify stronger associations with positive traits; lower scores indicate stereotype associations.",
    "baseline_results": null,
    "validation": "Systematic comparison of eight large vision language models."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "Analysis conducted across various gender, race, and color attributes.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}