{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection",
    "abbreviation": "OpenAD",
    "overview": "OpenAD is the first real open-world autonomous driving benchmark for 3D object detection, built upon a corner case discovery and annotation pipeline that integrates with a multimodal large language model (MLLM).",
    "data_type": "bounding box annotations (2D and 3D)",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "nuScenes",
      "KITTI",
      "Waymo"
    ],
    "resources": [
      "https://github.com/VDIGPKU/OpenAD"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate models' abilities in open-world scenarios for 3D object detection in autonomous driving.",
    "audience": [
      "ML Researchers",
      "Autonomous Driving Developers",
      "Computer Vision Practitioners"
    ],
    "tasks": [
      "3D Object Detection"
    ],
    "limitations": "OpenAD exclusively supports 2D and 3D object detection tasks, and all re-annotated data is allocated for benchmarking purposes.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Five autonomous driving perception datasets: Argoverse 2, KITTI, nuScenes, ONCE, and Waymo.",
    "size": "2,000 scenes, 19,761 annotated objects",
    "format": "Unified format for 2D and 3D bounding boxes",
    "annotation": "Manual annotation of corner cases and existing objects combined with automatic annotations from MLLMs."
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Human evaluation"
    ],
    "metrics": [
      "Average Precision (AP)",
      "Average Recall (AR)",
      "Average Translation Error (ATE)",
      "Average Scale Error (ASE)"
    ],
    "calculation": "AP and AR depend on True Positive (TP) metrics, utilizing IoU for positional scores and cosine similarity for semantic scores.",
    "interpretation": "A model's performance is determined through calculated metrics reflecting its detection abilities in both seen and unseen categories.",
    "baseline_results": null,
    "validation": "Evaluated on specialized and open-world models through various designed methodologies."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy",
      "Safety"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Data poisoning"
          ]
        }
      ]
    },
    "demographic_analysis": "The benchmark addresses varying object types across multiple vehicles and environments.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "All data utilized in OpenAD are sourced from published datasets. No personal data is present.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "The study does not foresee potential privacy-related issues."
  }
}