{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "GLEE: A Unified Framework and Benchmark for Language-based Economic Environments",
    "abbreviation": "GLEE",
    "overview": "GLEE provides a unified framework for standardizing research on two-player, sequential, language-based games, defining three base families of games with consistent parameterization and economic measures to evaluate agents' performance.",
    "data_type": "decision-making interactions",
    "domains": [
      "Economics",
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "Rational Players",
      "GAMA-Bench",
      "GTBench",
      "Game theoretic LLM",
      "TMGBench",
      "CompeteAI"
    ],
    "resources": [
      "https://github.com/eilamshapira/GLEE"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the behavior of Large Language Models (LLMs) in language-based economic games.",
    "audience": [
      "ML Researchers",
      "Economists",
      "Behavioral Scientists"
    ],
    "tasks": [
      "Bargaining",
      "Negotiation",
      "Persuasion"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Data collected from LLM vs. LLM and human vs. LLM interactions across diverse economic games.",
    "size": "80,000 games",
    "format": "JSON",
    "annotation": "Automatically generated interactions from predefined game scenarios."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Efficiency",
      "Fairness",
      "Self-gain"
    ],
    "calculation": "Metrics are based on game outcomes and normalized for comparison across setups.",
    "interpretation": "Higher values signify more efficient and fair outcomes.",
    "baseline_results": null,
    "validation": "Cross-validation using statistical models to assess input feature impacts on outputs."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Safety"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Output bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "Potential for misuse of LLM behavior modeling in economic contexts."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "Participants were required to pass attention checks and were informed about data collection.",
    "compliance_with_regulations": "The study follows ethical guidelines for the collection of human data."
  }
}