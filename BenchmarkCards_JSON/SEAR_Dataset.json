{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "SEAR Dataset",
    "abbreviation": "N/A",
    "overview": "The SEAR Dataset is a novel multimodal resource designed to study the emerging threat of social engineering (SE) attacks orchestrated through augmented reality (AR) and multimodal large language models (LLMs). This dataset captures 180 annotated conversations across 60 participants in simulated adversarial scenarios, including meetings, classes and networking events.",
    "data_type": "multimodal data including conversations, audio, and visual cues",
    "domains": [
      "Human-Computer Interaction",
      "Cybersecurity"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/INSLabCN/SEAR-Dataset"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of the benchmark is to provide a resource for studying AR-LLM-driven social engineering behaviors and facilitating the development of defensive mechanisms against such attacks.",
    "audience": [
      "ML Researchers",
      "Cybersecurity Practitioners",
      "Human-Computer Interaction Researchers"
    ],
    "tasks": [
      "Social Engineering Behavior Analysis",
      "AR-LLM Interaction Modeling"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Simulated adversarial scenarios with 60 participants engaged in social engineering interactions.",
    "size": "180 annotated conversations",
    "format": "N/A",
    "annotation": "Manual annotation by researchers"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Trust ratings",
      "Susceptibility assessments"
    ],
    "calculation": "Analysis of participant responses and contextual interactions during simulations.",
    "interpretation": "Higher scores in trust and engagement metrics indicate increased susceptibility to social engineering tactics.",
    "baseline_results": "N/A",
    "validation": "IRB-approved human study with varied conversation settings."
  },
  "targeted_risks": {
    "risk_categories": [
      "Privacy",
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "Analysis of demographic factors including age and gender distribution of participants.",
    "harm": "Potential for manipulation exploiting trust dynamics."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "All human-related data were collected under rigorous ethical guidelines, anonymized prior to analysis, and handled in strict accordance with data protection protocols.",
    "data_licensing": "N/A",
    "consent_procedures": "Informed consent obtained from all participants for data collection.",
    "compliance_with_regulations": "The study adhered to all applicable legal and ethical standards for research involving human subjects."
  }
}