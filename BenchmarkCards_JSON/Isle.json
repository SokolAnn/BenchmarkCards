{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Isle (I Spy with My Little Eye)",
    "abbreviation": "Isle",
    "overview": "The paper introduces two manually curated datasets, Isle-Bricks and Isle-Dots, for testing visual perspective-taking (VPT) skills in Vision Language Models (VLMs). The datasets focus on measuring how well models can understand viewpoints in various scenarios.",
    "data_type": "image-question pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the visual perspective-taking abilities of Vision Language Models and highlight the need for benchmarks specifically designed to capture this capability.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Visual Perspective Taking",
      "Object Detection"
    ],
    "limitations": "The datasets currently include a limited number of subjects, which may restrict the analysis of VPT in more complex scenarios.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Manually curated images and questions specifically designed to test perspective-taking capabilities.",
    "size": "230 pairs of images and questions (100 for Isle-Bricks, 130 for Isle-Dots)",
    "format": "Image and question pairs",
    "annotation": "Manual annotation by authors ensuring consensus on questions and answers."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Model-based evaluation"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Model performance is calculated based on correct answers to perspective-taking and object detection questions.",
    "interpretation": "High accuracy indicates a model's capability in VPT tasks, while low accuracy suggests significant challenges.",
    "baseline_results": "Average model performance in baseline object detection tasks was 83% accuracy.",
    "validation": "Performance was validated by testing multiple commonly used VLMs."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}