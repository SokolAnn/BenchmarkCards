{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Common Pile v0.1",
    "abbreviation": "N/A",
    "overview": "Common Pile v0.1 is an 8TB dataset of openly licensed text designed for LLM pretraining, comprising content from 30 diverse sources, demonstrating the feasibility of achieving performant models without using unlicensed text.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing",
      "Computer Science",
      "Education"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "OLC (Open License Corpus)",
      "Common Corpus",
      "KL3M",
      "The Pile"
    ],
    "resources": [
      "https://github.com/username/repo"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a large, diverse, and openly licensed dataset for pretraining language models to facilitate more ethical AI developments.",
    "audience": [
      "ML Researchers",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Text Classification",
      "Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Common Pile v0.1",
    "size": "8TB",
    "format": "text",
    "annotation": "Curated and validated by filtering, deduplication, and reweighting of diverse openly licensed sources."
  },
  "methodology": {
    "methods": [
      "Model-based evaluation",
      "Data ablation study"
    ],
    "metrics": [
      "Accuracy",
      "F1 Score",
      "MMLU"
    ],
    "calculation": "Metrics are calculated based on model evaluation against multiple benchmarks after training on the dataset.",
    "interpretation": "A higher score is indicative of improved model performance on the tasks evaluated.",
    "baseline_results": "N/A",
    "validation": "Models were validated through controlled experiments comparing performance across different datasets."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness",
      "Privacy",
      "Accuracy",
      "Safety"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Data privacy rights alignment"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Data poisoning"
          ]
        },
        {
          "category": "Transparency",
          "subcategory": [
            "Lack of training data transparency"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Ensured filtering to remove personally identifiable information (PII) and inappropriate content.",
    "data_licensing": "The dataset is curated from openly licensed texts under various licenses such as CC BY, CC BY-SA, and public domain.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}