{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Theory of Mind Benchmarks are Broken for Large Language Models",
    "abbreviation": "N/A",
    "overview": "This paper critiques existing theory of mind benchmarks for large language models (LLMs), arguing that they measure only literal theory of mind rather than functional theory of mind, and introduces functional theory of mind as a critical aspect to evaluate LLMs effectively.",
    "data_type": "multimodal",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2412.19726"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To highlight the limitations of current theory of mind benchmarks and advocate for a new interactive methodology to evaluate functional theory of mind in LLMs.",
    "audience": [
      "ML Researchers",
      "AI Practitioners"
    ],
    "tasks": [
      "Theory of Mind Evaluation",
      "Reinforcement Learning",
      "Multi-Agent Interaction"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Empirical evaluations through simulations and experiments with large language models",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Empirical evaluation",
      "Simulations",
      "Multimodal analysis"
    ],
    "metrics": [
      "Accuracy",
      "Regret"
    ],
    "calculation": "Calculated metrics focus on comparing literal and functional theory of mind performances based on predefined games and policies.",
    "interpretation": "Higher regret signifies poorer functional adaptation capabilities in LLMs.",
    "baseline_results": "N/A",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Prompt injection attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}