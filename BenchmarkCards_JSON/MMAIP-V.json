{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MMAIP-V (Multiple Multimodal Artificial Intelligence Preference Datasets in VQA)",
    "abbreviation": "MMAIP-V",
    "overview": "High-quality video-text preference data crucial for Multimodal Large Language Models (MLLMs) alignment, addressing existing data scarcity with 24,000 entries constructed by sampling from response distributions and using an external scoring function for evaluation.",
    "data_type": "video-text pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To facilitate preference learning and improve alignment capabilities of Multimodal Large Language Models through high-quality video-text preference data.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Video Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Constructed from video question-answering pairs sampled from WebVid, VIDAL, and ActivityNet datasets, combined with responses generated from different MLLM architectures.",
    "size": "24,000 pairs",
    "format": "N/A",
    "annotation": "Automatically scored responses by external visual reward models and GPT-4o for relevance and quality."
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Human evaluation"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Evaluation based on the alignment of model responses to ground truth while incorporating visual information for comprehensive assessments.",
    "interpretation": "Scores indicate alignment accuracy of MLLMs in generating video-based answers.",
    "baseline_results": null,
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Data poisoning"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}