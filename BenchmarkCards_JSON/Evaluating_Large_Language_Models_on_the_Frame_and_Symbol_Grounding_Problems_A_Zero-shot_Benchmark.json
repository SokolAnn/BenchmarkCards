{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark",
    "abbreviation": "N/A",
    "overview": "This study investigates whether modern LLMs possess the cognitive capacities required to address the Frame Problem and the Symbol Grounding Problem by designing two benchmark tasks reflecting the philosophical core of each problem.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/0xshooka/frame-symbol"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To quantitatively evaluate the cognitive capacities of LLMs as they address philosophical challenges.",
    "audience": [
      "ML Researchers",
      "Cognitive Scientists"
    ],
    "tasks": [
      "Frame Problem",
      "Symbol Grounding Problem"
    ],
    "limitations": "Some limitations include reliance on a single evaluator LLM and zero-shot testing conditions.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Custom tasks generated based on the Frame Problem and Symbol Grounding Problem.",
    "size": "N/A",
    "format": "N/A",
    "annotation": "Responses evaluated based on qualitative criteria."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated scoring via another LLM"
    ],
    "metrics": [
      "Contextual reasoning",
      "Semantic coherence",
      "Information filtering"
    ],
    "calculation": "Metrics calculated based on novel scoring criteria designed for each problem.",
    "interpretation": "Scores indicate the extent to which LLMs possess cognitive capabilities required for frame and symbol grounding tasks.",
    "baseline_results": "Closed models scored consistently higher than open-source models.",
    "validation": "Results analyzed through inter-model comparisons and descriptive statistics."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}