{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Deciphering the Underserved: Benchmarking LLM OCR for Low-Resource Scripts",
    "abbreviation": "N/A",
    "overview": "This study investigates the potential of Large Language Models (LLMs), particularly GPT-4o, for Optical Character Recognition (OCR) in low-resource scripts such as Urdu, Albanian, and Tajik, with English serving as a benchmark. Using a meticulously curated dataset of 2,520 images incorporating controlled variations in text length, font size, background color, and blur, the research simulates diverse real-world challenges.",
    "data_type": "image",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English",
      "Urdu",
      "Albanian",
      "Tajik"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/user/repo"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the OCR performance of LLMs across low-resource scripts and address the accessibility gaps in text digitization.",
    "audience": [
      "NLP Researchers",
      "OCR Developers"
    ],
    "tasks": [
      "Optical Character Recognition"
    ],
    "limitations": "The labor-intensive nature of dataset creation limited the dataset size, preventing the inclusion of additional languages and larger datasets.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Curated dataset consisting of 2,520 images from news articles sourced from various outlets in Urdu, English, Albanian, and Tajik.",
    "size": "2,520 images",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Zero-shot inference"
    ],
    "metrics": [
      "Character Error Rate (CER)",
      "Word Error Rate (WER)",
      "BLEU Score"
    ],
    "calculation": "Metrics are calculated based on edit distances and comparison of n-grams with the reference text.",
    "interpretation": "Lower values of CER and WER indicate better OCR performance, while higher BLEU scores reflect better semantic coherence.",
    "baseline_results": "N/A",
    "validation": "The dataset was assessed under controlled dimensions including word count, font size, background color, and Gaussian blur."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}