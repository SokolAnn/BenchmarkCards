{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark",
    "abbreviation": "N/A",
    "overview": "This work creates the first benchmark for zeroth-order (ZO) optimization in the context of LLM fine-tuning, performing a comprehensive study across multiple ZO methods, five LLM families (Roberta, OPT, LLaMA, Vicuna, Mistral), three task complexities, and five fine-tuning schemes to evaluate accuracy and efficiency and to investigate optimization principles and enhancements (block-wise descent, hybrid ZO-FO training, gradient sparsity).",
    "data_type": "text (binary classification, question-answering, commonsense reasoning, multi-sentence reading comprehension)",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": null,
    "similar_benchmarks": [
      "MeZO (Malladi et al., 2023)"
    ],
    "resources": [
      "https://github.com/ZO-Bench/ZO-LLM"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Establish the first benchmark for ZO optimization in LLM fine-tuning to evaluate and compare a broad range of ZO methods, reveal optimization principles (e.g., task alignment, forward gradient role), and propose enhancements to improve memory-efficient fine-tuning.",
    "audience": [
      "N/A"
    ],
    "tasks": [
      "Text Classification",
      "Question Answering",
      "Commonsense Reasoning",
      "Multi-sentence Reading Comprehension"
    ],
    "limitations": "High variance of ZO methods and a scalability bottleneck when dealing with larger models and more complex tasks; crafting effective prompts for task alignment can be non-trivial.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Stanford Sentiment Treebank v2 (SST2); Choice Of Plausible Alternatives (COPA); WinoGrande; MultiRC",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Automated metrics (accuracy and efficiency)",
      "Comparative algorithm benchmarking across ZO and FO optimizers"
    ],
    "metrics": [
      "Accuracy (test accuracy)",
      "Peak Memory Usage (GB)",
      "GPU Resources (number of GPUs)",
      "Query Efficiency (number of function queries)",
      "Runtime Efficiency (per-iteration runtime in seconds)"
    ],
    "calculation": "Accuracy measured as test accuracy on evaluation datasets; memory reported as peak memory usage in GB; GPU resources reported as number of GPUs used; query efficiency measured as number of function queries per gradient estimate (query budget q); runtime reported as per-iteration runtime (seconds), averaged (e.g., averaged over 100 iterations for the reported runtime costs). ZO optimizers typically used q=1 unless otherwise specified.",
    "interpretation": "Higher test accuracy indicates better fine-tuning effectiveness; lower peak memory, fewer GPUs, lower query counts, and lower per-iteration runtime indicate better efficiency. Results are interpreted in light of trade-offs between algorithmic complexity, accuracy, query budget, and memory/runtime efficiency.",
    "baseline_results": "Baselines include FO optimizers FO-SGD and FO-Adam. Example baseline: FO-SGD achieved 91.4% test accuracy on SST2 (Roberta-Large, FT) as reported in Table 2. Comparative results for multiple ZO and FO methods across settings are provided in the paper.",
    "validation": "Hyperparameters selected via grid search for each method; ZO (BP-free) optimizers run for 20,000 iterations and FO optimizers run for 625 iterations unless otherwise stated; runtime averages computed (e.g., runtime averaged over 100 iterations for reported per-iteration runtimes)."
  },
  "targeted_risks": {
    "risk_categories": [
      "Misuse",
      "Privacy",
      "Intellectual Property",
      "Societal Impact"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Misuse",
          "subcategory": [
            "Spreading disinformation",
            "Dangerous use"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Exposing personal information"
          ]
        },
        {
          "category": "Intellectual Property",
          "subcategory": [
            "Copyright infringement"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on the environment"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": [
      "Generating misinformation",
      "Phishing attacks",
      "Releasing copyrighted information",
      "Releasing private information"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}