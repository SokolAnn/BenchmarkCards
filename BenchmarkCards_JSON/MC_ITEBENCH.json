{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MC ITEBENCH",
    "abbreviation": "N/A",
    "overview": "MC ITEBENCH is the first benchmark designed to assess the ability of Multimodal Large Language Models (MLLMs) to generate text with citations in multimodal contexts, featuring diverse information sources and multimodal content.",
    "data_type": "question-answer pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://caiyuhu.github.io/MCiteBench"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the ability of MLLMs to generate text with citations from multimodal input.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Text Generation with Citations"
    ],
    "limitations": "In MC ITEBENCH, citations are limited to the sentence level, meaning that we do not distinguish between multiple claims within a single sentence.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Academic papers collected from OpenReview, along with reviewâ€“rebuttal interactions.",
    "size": "3,000 samples",
    "format": "N/A",
    "annotation": "Data is annotated through manual verification by human annotators to ensure accuracy and consistency."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Citation F1",
      "Source F1",
      "Source Exact Match",
      "Accuracy"
    ],
    "calculation": "Metrics are calculated based on the alignment between cited evidence and generated responses.",
    "interpretation": "Higher scores indicate better model performance in generating citations accurately and reliably.",
    "baseline_results": null,
    "validation": "The benchmark was validated through extensive experiments with model evaluations and human assessments."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}