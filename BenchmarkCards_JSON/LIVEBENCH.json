{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "LIVEBENCH",
    "abbreviation": "N/A",
    "overview": "LiveBench is a new benchmark for LLMs designed to be resistant to both test set contamination and the pitfalls of LLM judging and human crowdsourcing. It contains frequently updated questions from recent information sources, scores answers automatically according to objective ground-truth values, and has a variety of challenging tasks, spanning math, coding, reasoning, language, instruction following, and data analysis.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "Big-Bench Hard",
      "AMPS",
      "IFEval"
    ],
    "resources": [
      "https://livebench.ai",
      "https://github.com/livebench/livebench"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To mitigate both test set contamination and the pitfalls of LLM judging and human crowdsourcing in LLM evaluation.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Math",
      "Coding",
      "Reasoning",
      "Instruction Following",
      "Language Comprehension",
      "Data Analysis"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Questions drawn from recent math competitions, arXiv papers, news articles, and datasets.",
    "size": "1,000 questions",
    "format": "N/A",
    "annotation": "Automatically generated based on objective ground-truth values."
  },
  "methodology": {
    "methods": [
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Metrics are calculated based on the proportion of correctly answered questions.",
    "interpretation": "An accuracy score represents the percentage of correctly answered questions out of the total questions.",
    "baseline_results": "N/A",
    "validation": "LiveBench is validated through regular inspections of incorrect answers and adjustments to scoring functions."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Output bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Apache License 2.0",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}