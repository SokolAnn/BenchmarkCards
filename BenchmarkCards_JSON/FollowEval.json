{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "FollowEval",
    "abbreviation": "N/A",
    "overview": "FollowEval is a benchmark designed to evaluate the instruction-following capabilities of large language models (LLMs) across diverse dimensions such as string manipulation, commonsense reasoning, logical reasoning, spatial reasoning, and adherence to response constraints. It features 200 manually curated test instances in English and Chinese.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English",
      "Chinese"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2311.09829"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a comprehensive evaluation of the instruction-following capabilities of LLMs in both English and Chinese.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Text Classification",
      "Logical Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Manually curated by human experts.",
    "size": "200 examples",
    "format": "N/A",
    "annotation": "Manual curation and regex-based verification."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is calculated as the proportion of correctly answered test instances.",
    "interpretation": "Higher accuracy indicates better instruction-following capabilities of the LLMs.",
    "baseline_results": "Humans achieved 100% accuracy; GPT-4 is the top performer among evaluated models.",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}