{
  "benchmark_details": {
    "name": "Hallucination Elimination and Semantic Enhancement Framework for Vision-Language Models in Traffic Scenarios",
    "overview": "This paper proposes HCOENet, a method to eliminate hallucinations and enhance the description of critical objects overlooked in the initial response by large vision-language models.",
    "data_type": "Image",
    "domains": [
      "Traffic Scenarios"
    ],
    "languages": null,
    "similar_benchmarks": null,
    "resources": [
      "https://github.com/fjq-tongji/HCOENet"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To mitigate hallucinations in vision-language models and enhance the semantic understanding of traffic scenarios.",
    "audience": [
      "Researchers",
      "Developers in AI and autonomous driving"
    ],
    "tasks": [
      "Image description",
      "Hallucination detection and elimination",
      "Dataset creation"
    ],
    "limitations": "Requires specific training to fine-tune existing models for optimal performance.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Novel datasets created include CODA desc and nuScenes desc.",
    "size": "16952 image-text pairs total (9695 for CODA desc and 40157 for nuScenes desc)",
    "format": "N/A",
    "annotation": "Automatic semantic annotation generated by the framework."
  },
  "methodology": {
    "methods": [
      "HCOENet",
      "Cross-checking mechanism",
      "Entity filtering",
      "Critical-object enhancement"
    ],
    "metrics": [
      "F1-score",
      "Precision",
      "Recall",
      "Accuracy"
    ],
    "calculation": "Improvements in F1-scores were calculated comparing performances before and after applying HCOENet.",
    "interpretation": "Based on the comparative results achieving higher scores using different models with HCOENet.",
    "baseline_results": null,
    "validation": "Experimental results validated on the POPE benchmark."
  },
  "targeted_risks": {
    "risk_categories": [
      "Hallucinations in generated text",
      "Safety risks in autonomous driving",
      "Misinterpretation of visual data"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Explainability",
          "subcategory": [
            "Unexplainable output"
          ]
        },
        {
          "category": "Transparency",
          "subcategory": [
            "Lack of training data transparency"
          ]
        }
      ]
    },
    "demographic_analysis": "Not specified.",
    "harm": "Potential safety risks due to hallucinations affecting driving decisions."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}