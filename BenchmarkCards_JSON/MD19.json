{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MEDDISTANT 19",
    "abbreviation": "MD19",
    "overview": "This work presents a more accurate benchmark MEDDISTANT 19 for broad-coverage distantly supervised biomedical relation extraction that addresses shortcomings in existing benchmarks (notably train-test triples overlap) and is obtained by aligning MEDLINE abstracts with the widely used SNOMED CT knowledge base.",
    "data_type": "text (entity-linked sentences; bag-level sentence groups for relation extraction)",
    "domains": [
      "Natural Language Processing",
      "Healthcare"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "UMLS.v1",
      "DTI",
      "UMLS.v2",
      "BioRel",
      "UMLS.v3",
      "TBGA"
    ],
    "resources": [
      "https://arxiv.org/abs/2204.04779",
      "https://github.com/suamin/MedDistant19",
      "https://github.com/pminervini/meddistant-baselines",
      "https://github.com/allenai/scispacy",
      "https://lhncbc.nlm.nih.gov/ii/information/MBR/Baselines/2019.html",
      "https://uts.nlm.nih.gov/license.html",
      "https://download.nlm.nih.gov/umls/kss/2019AB/umls-2019AB-full.zip"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Introduce an accurate broad-coverage distantly supervised biomedical relation extraction benchmark (MEDDISTANT 19) by aligning PubMed MEDLINE abstracts with SNOMED CT and addressing train-test KG triple overlap and data construction inconsistencies.",
    "audience": [
      "Machine Learning Researchers",
      "Biomedical Natural Language Processing Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Relation Extraction",
      "Corpus-level Triples Extraction",
      "Sentence-level Relation Detection"
    ],
    "limitations": "Limited scope of ontologies (focused on SNOMED CT); limited subset of relation types (e.g., does not include may_treat); lacks coverage of some relations such as protein-protein interactions, drug side-effects, and gene relations from other vocabularies (e.g., RxNorm, Gene Ontology). MEDDISTANT 19 is automatically-created and susceptible to noise and should be approached carefully as a potential source for biomedical knowledge.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "PubMed MEDLINE abstracts published up to 2019 (32,151,899 abstracts) aligned with SNOMED CT via a distilled UMLS2019AB; entity linking performed with ScispaCy.",
    "size": "450,071 training instances; 39,434 validation instances; 91,568 test instances; 20,256 unique entities; 22 relations (plus NA); 88,861 training bags; 10,475 validation bags; 22,606 test bags; 150,173,169 unique sentences extracted from MEDLINE.",
    "format": "JSON (OpenNRE-compatible format; examples provided in appendix)",
    "annotation": "Automatically generated via distant supervision by aligning SNOMED CT/UMLS triples to text using ScispaCy entity linking; negative sampling to create NA labels; no manual expert annotation for dataset creation (automatically-created)."
  },
  "methodology": {
    "methods": [
      "Model-based evaluation (baseline neural models fine-tuned on dataset)",
      "Automated metrics (corpus- and sentence-level)",
      "Bag-level and sentence-level evaluation"
    ],
    "metrics": [
      "Area Under the Precision-Recall Curve (AUC, corpus-level)",
      "Micro-F1",
      "Macro-F1",
      "Precision",
      "Recall",
      "F1 Score",
      "Precision-at-k (P@k) for k in {100,200,300,1000,2000}"
    ],
    "calculation": "Corpus-level AUC computed on the Precision-Recall curve; Micro-F1 and Macro-F1 computed at corpus-level; Precision-at-k computed for top-ranked triples; sentence-level Precision, Recall, and F1 computed for sentence-level relation detection. Macro-F1 reported due to imbalance of relational instances.",
    "interpretation": "Higher AUC and F1 indicate better corpus-level relation extraction performance. Macro-F1 is used to evaluate per-relation performance due to class imbalance. Precision-at-k reflects top-scoring triple precision.",
    "baseline_results": "Best reported baseline: BERT fine-tuned at sentence-level with AVG pooling achieved AUC 79.9, F1-micro 76.2, F1-macro 65.4 on the inductive split (Table 10). Sentence-level results for BERT+sent+AVG: Precision 0.79, Recall 0.65, F1 0.71 (Table 9).",
    "validation": "Inductive KG split method (Daza et al., 2021) used to ensure no overlap of triples between train/validation/test (split ratios 70%/10%/20%). Additional validation steps include removing mention-level overlap across splits, type-based mention pruning (removing mentions appearing >10,000 times), enforcing type and role constraints in negative sampling, and creating a transductive split for comparison."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Privacy",
      "Data Laws",
      "Misuse"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Data contamination",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        },
        {
          "category": "Data Laws",
          "subcategory": [
            "Data usage restrictions"
          ]
        },
        {
          "category": "Misuse",
          "subcategory": [
            "Improper usage"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "Overestimation of model performance due to train-test triples overlap (train-test leakage) and potential misuse or redistribution without respecting UMLS licensing."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Uses publicly available PubMed MEDLINE abstracts (mostly English). Authors note they cannot guarantee the absence of confidential or sensitive information (e.g., clinical findings that reveal age/gender) and did not perform a thorough analysis to distill such information.",
    "data_licensing": "Use of the benchmark requires signing the UMLS license/agreement. UMLS contains copyrighted material; users must respect source ontology licenses and obtain agreements for copyrighted sources before commercial or production use (see UMLS license).",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}