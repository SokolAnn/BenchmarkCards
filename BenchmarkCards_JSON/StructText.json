{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation",
    "abbreviation": "StructText",
    "overview": "StructText is an end-to-end framework for automatically generating high-fidelity benchmarks for key-value extraction from text using existing tabular data, facilitating text-to-table extraction research and evaluation.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing",
      "Finance",
      "Healthcare",
      "Legal"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://huggingface.co/datasets/ibm-research/struct-text",
      "https://github.com/ibm/struct-text"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To generate and evaluate benchmarks for text-to-table extraction tasks using synthetic generated texts from existing tabular data.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Text-to-Table Extraction"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic text generated from tabular data",
    "size": "71,539 examples",
    "format": "JSON",
    "annotation": "Automatically generated"
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "LLM-based evaluation"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "F1 Score",
      "Factuality",
      "Hallucination",
      "Coherence"
    ],
    "calculation": "Metrics are calculated from the performance of extraction coupled with LLM as judge assessments across different dimensions.",
    "interpretation": "Scores measure how accurately the models can generate and extract information while maintaining coherence and factual consistency.",
    "baseline_results": "Precision for SEC Financial dataset is 0.344; Recall is 0.669; F1 Score is 0.455.",
    "validation": "The benchmark was validated through extensive evaluation of generated reports and numerical and temporal accuracy assessments."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A - Not discussed",
    "data_licensing": "Creative Commons BY-NC-ND 4.0 International License",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}