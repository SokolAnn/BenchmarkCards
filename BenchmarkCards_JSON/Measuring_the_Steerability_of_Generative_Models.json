{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Measuring the Steerability of Generative Models",
    "abbreviation": "N/A",
    "overview": "This paper introduces a benchmark task to evaluate the steerability of generative models, where users are tasked with prompting models to reproduce sampled outputs. The study finds that several models perform poorly on this task, indicating a need to improve generative model steerability.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/SarahBentley/Steerability"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of the benchmark is to evaluate how well users can steer generative models towards desired outputs.",
    "audience": [
      "ML Researchers",
      "AI Practitioners"
    ],
    "tasks": [
      "Image Generation",
      "Text Generation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Large-scale user study with generative models (text-to-image and large language models).",
    "size": "554 goal images",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "User study",
      "Prompting mechanisms",
      "Reinforcement learning"
    ],
    "metrics": [
      "Satisfaction rate",
      "Image Similarity Rating",
      "Improvement Rate",
      "Prompt-Output Misalignment"
    ],
    "calculation": "Metrics are calculated using human annotations comparing generated images to goal images.",
    "interpretation": "Higher ratings indicate better steerability of the models.",
    "baseline_results": null,
    "validation": "Reinforcement learning and human ratings are used for validation."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}