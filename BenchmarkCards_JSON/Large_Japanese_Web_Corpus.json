{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Large Japanese Web Corpus",
    "abbreviation": "N/A",
    "overview": "This paper builds a large Japanese web corpus by extracting and refining text from the Common Crawl archive, consisting of approximately 312.1 billion characters and approximately 173 million pages. The corpus is the largest available for training Japanese LLMs and has been shown to improve the performance of base LLMs on Japanese benchmark datasets by 6.6–8.1 points.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Japanese"
    ],
    "similar_benchmarks": [
      "CC-100",
      "mC4",
      "OSCAR"
    ],
    "resources": [
      "https://huggingface.co/tokyotech-llm"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To construct a large-scale, high-quality Japanese web corpus useful for training Japanese large language models (LLMs).",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Text Classification",
      "Question Answering",
      "Reading Comprehension",
      "Machine Translation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Extracted and refined text from the Common Crawl archive (21 snapshots from 2020 to 2023).",
    "size": "312,093,428,689 characters (approximately 173 million pages)",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Continual pre-training",
      "Evaluation on Japanese benchmark datasets"
    ],
    "metrics": [
      "Performance improvement measured in points on benchmark datasets"
    ],
    "calculation": "Improvements measured on Japanese benchmark datasets after continual pre-training.",
    "interpretation": "Improvements in model performance indicated the corpus's effectiveness for training.",
    "baseline_results": "Performance gains of 6.6–8.1 points on benchmark datasets.",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Ethics"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Article 30-4 of the Copyright Act in Japan allows use without the permission of the copyright holder as long as the use is not for personal enjoyment.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}