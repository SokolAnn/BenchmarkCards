{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "BanFakeNews: A Dataset for Detecting Fake News in Bangla",
    "abbreviation": "BanFakeNews",
    "overview": "An annotated dataset and benchmark for detecting fake news written in Bangla: the paper introduces an annotated dataset of approximately 50,000 Bangla news items for building automated fake news detection systems, provides dataset analysis, and develops benchmark systems using linguistic features and neural models.",
    "data_type": "text (news articles: headline and article body, with metadata)",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Bangla"
    ],
    "similar_benchmarks": [
      "LIAR"
    ],
    "resources": [
      "https://github.com/Rowan1697/FakeNews"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To create and publicly release an annotated dataset of Bangla news for fake news detection and to develop and evaluate benchmark systems (linguistic-feature based and neural models) for classifying Bangla fake news.",
    "audience": [
      "Machine Learning Researchers",
      "Natural Language Processing Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Text Classification",
      "Fake News Detection"
    ],
    "limitations": "Imbalanced dataset: authentic news are 37.47 times more numerous than fake news in the dataset. The authors have manually annotated around 8,500 news so far and plan to expand to approximately 50,000.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Collected authentic news from 22 mainstream trusted Bangladeshi news portals; fake news collected from satirical sites, manual collection of clickbait sites, and fact-checking sites (jaachai.com and bdfactcheck.com). Metadata collected includes domain, publication time, and category; source and headline-article relation were also annotated for a subset.",
    "size": "Approximately 50,000 news articles (target/total collected); 8,500 news manually annotated so far",
    "format": "N/A",
    "annotation": "Manual annotation by an annotator team of undergraduate students. Labels include authentic vs fake, source information, headline-article relation (Related/Unrelated), and categories mapped into 12 generalized categories."
  },
  "methodology": {
    "methods": [
      "Automated metrics (Micro-F1, Precision, Recall)",
      "Human evaluation (human baseline with 5 annotators)"
    ],
    "metrics": [
      "Micro-F1",
      "Precision",
      "Recall",
      "F1 Score"
    ],
    "calculation": "Micro-F1 computed for overall evaluation; precision, recall and F1 reported for the minority (fake) class. Dataset split 70:30 train:test. For neural models, 10% of test data used as validation. Checkpointing on validation F1 for the fake class. Hyperparameters (e.g., SVM penalty C) tuned on validation.",
    "interpretation": "Authors focus on the F1-Score of the fake class as the main evaluation metric due to class imbalance. Linear classifiers with traditional linguistic features achieve the best reported performance and outperform neural network models and the human baseline on the test sets.",
    "baseline_results": "Best reported: SVM with all linguistic features — 0.91 F1 (fake class). BERT (fine-tuned multilingual cased) — 0.68 F1 (fake class). CNN — 0.59 F1 (fake class). Human baseline (five annotators) fake-class F1-scores: 58%, 65%, 70%, 68%, 63% (authors report an aggregate human F1 of 64.8% on the human baseline subset).",
    "validation": "Train:test split of 70:30. For BiLSTM/CNN/BERT experiments, 10% of the test data used as validation. Models trained up to 50 epochs with checkpoints based on validation F1 of the fake class. SVM penalty parameter tuned based on validation results."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Misuse",
      "Societal Impact"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Misuse",
          "subcategory": [
            "Spreading disinformation"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on affected communities"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Political manipulation (influence on elections and political opinion)",
      "Impact on affected communities (example: 2012 Ramu incident leading to violence against religious sites)",
      "Financial impact (damage in finance sector due to fake news)"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}