{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "FarsEval -PKBETS",
    "abbreviation": "N/A",
    "overview": "FarsEval -PKBETS benchmark is designed for evaluating large language models in Persian, consisting of 4,000 questions across various formats and domains, focusing on linguistic, cultural, and local considerations relevant to the Persian language and Iran.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Healthcare",
      "Legal",
      "Education"
    ],
    "languages": [
      "Persian"
    ],
    "similar_benchmarks": [
      "GLUE",
      "SuperGLUE",
      "MMLU",
      "TruthfulQA",
      "BIG-Bench"
    ],
    "resources": [
      "https://github.com/ParsBench/FarsEval-PKBETS"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To serve as a robust evaluation platform for measuring and comparing the performance of language models specifically trained for the Persian language.",
    "audience": [
      "ML Researchers",
      "Model Developers",
      "Linguists"
    ],
    "tasks": [
      "Text Classification",
      "Question Answering",
      "Text Generation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Self-generated and expert-reviewed questions covering various domains and tasks relevant to Persian language and culture.",
    "size": "4,000 questions",
    "format": "Various formats including multiple-choice, short-answer, and descriptive",
    "annotation": "Expert-reviewed for quality and relevance"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Calculating the accuracy based on correct and semi-correct responses from LLMs across various tasks.",
    "interpretation": "Performance is categorized as Correct, Wrong, or Semi-correct based on the model's responses to the benchmark questions.",
    "baseline_results": null,
    "validation": "Supervised by expert reviewers throughout the development phase."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias",
            "Output bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Toxic outputs",
      "Cultural insensitivity"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}