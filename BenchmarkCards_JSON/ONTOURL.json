{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ONTOURL (Ontology URL)",
    "abbreviation": "ONTOURL",
    "overview": "ONTOURL is the first comprehensive benchmark designed to systematically evaluate LLMs’ capabilities in handling ontologies—formal and symbolic representations of domain knowledge. It assesses understanding, reasoning, and learning through 15 distinct tasks comprising 57,303 questions derived from 40 ontologies across 8 domains.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Science",
      "Finance",
      "Healthcare",
      "Legal",
      "Education",
      "Environmental Science",
      "Media and Entertainment"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://anonymous.4open.science/r/OntoURL_anonymous-44FD"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the capabilities of large language models in understanding, reasoning, and learning with structured symbolic knowledge through ontologies.",
    "audience": [
      "ML Researchers",
      "Ontology Practitioners"
    ],
    "tasks": [
      "Understanding",
      "Reasoning",
      "Learning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Extracted from 40 expert-created, open-source ontologies spanning various domains.",
    "size": "57,303 questions",
    "format": "Multiple-choice questions and open-ended questions",
    "annotation": "Generated using a systematic pipeline involving entity extraction and expert verification for quality assurance."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "BERTScore",
      "F1 Score"
    ],
    "calculation": "Metrics are calculated based on model outputs compared to ground truth answers using standard evaluation practices.",
    "interpretation": "Higher accuracy indicates better performance by the models in answering ontology-related questions.",
    "baseline_results": null,
    "validation": "Evaluated on 20 open-source LLMs using both zero-shot and few-shot settings."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Safety"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Creative Commons Attribution 4.0 International (CC BY 4.0)",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}