{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "AIDBench",
    "abbreviation": "N/A",
    "overview": "AIDBench is a comprehensive benchmark designed to evaluate the authorship identification capabilities of large language models (LLMs). It incorporates several author identification datasets, including emails, blogs, reviews, articles, and research papers, to systematically study privacy risks associated with LLMs.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To assess and demonstrate the potential privacy risks posed by large language models in identifying authorship of anonymous texts.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Privacy Experts"
    ],
    "tasks": [
      "Authorship Identification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "The benchmark includes new and existing datasets such as research papers from arXiv, the Enron email dataset, blogs, IMDb reviews, and articles from The Guardian.",
    "size": "24,095 papers in the research dataset; approximately 500,000 emails in the Enron dataset; 19,320 blog posts; 3,100 IMDb reviews; 650 articles from The Guardian.",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "One-to-one authorship identification",
      "One-to-many authorship identification",
      "Retrieval-Augmented Generation (RAG)-based evaluation"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "Rank@x"
    ],
    "calculation": "Metrics are calculated based on the proportion of correct identifications by LLMs evaluating candidate texts against known authorship.",
    "interpretation": "High precision and recall indicate effective authorship identification capability, while lower rates highlight challenges in distinguishing authorship.",
    "baseline_results": "N/A",
    "validation": "The benchmark includes rigorous evaluation using multiple datasets under varied contexts and exploration of models' capabilities."
  },
  "targeted_risks": {
    "risk_categories": [
      "Privacy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data",
            "Data privacy rights alignment"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "The benchmark aims to detect potential harmful impacts on user privacy through authorship identification."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}