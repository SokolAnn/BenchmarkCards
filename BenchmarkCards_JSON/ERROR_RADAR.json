{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ERROR RADAR",
    "abbreviation": "N/A",
    "overview": "ERROR RADAR is the first benchmark designed to assess Multimodal Large Language Models' capabilities in multimodal error detection tasks, focusing on error step identification and error categorization within complex mathematical reasoning scenarios.",
    "data_type": "multimodal mathematical problems",
    "domains": [
      "Education"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "GSM8K",
      "MATH",
      "MathVista"
    ],
    "resources": [
      "https://github.com/user/repo"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the complex mathematical reasoning capabilities of Multimodal Large Language Models in error detection settings.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Error Step Identification",
      "Error Categorization"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "The dataset is sourced from a global educational organization's question bank, specifically designed for K-12 mathematics.",
    "size": "2,500 multimodal questions",
    "format": "N/A",
    "annotation": "Manual annotation by educational experts"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Model performance is evaluated based on accuracy metrics for both identifying the first erroneous step and categorizing the error.",
    "interpretation": "Accuracy indicates the model's ability to correctly identify error steps and categorize them based on predefined error types.",
    "baseline_results": "Human evaluation accuracy is significantly higher than MLLMs, with 69.8% for step identification and 60.7% for categorization.",
    "validation": "Extensive experiments were conducted to benchmark MLLMs against educational expert evaluators."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}