{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Multi-Turn Puzzles",
    "abbreviation": "MTP",
    "overview": "The Multi-Turn Puzzles benchmark consists of a suite of multi-turn tasks designed to evaluate the reasoning, interactive dialogue, and information-seeking abilities of large language models (LLMs). It includes tasks such as Word Guess, Movie Recommendation, Circuit Decoding, Word Chaining, and Twenty Questions, aiming to provide insights into the strengths and weaknesses of current LLMs in handling complex, interactive scenarios.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://huggingface.co/datasets/arianhosseini/mt_puzzles"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To assess and enhance the interactive reasoning and strategic dialogue capabilities of large language models through a structured benchmark.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Word Guess",
      "Movie Recommendation",
      "Circuit Decoding",
      "Word Chaining",
      "Twenty Questions"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic data created through rule-based environments.",
    "size": "400 unique vocabulary configurations for Word Guess, 1000 configurations for Movie Recommendation, 300 configurations for Circuit Decoding, and 400 configurations for Word Chaining and Twenty Questions.",
    "format": "N/A",
    "annotation": "Automatically evaluated using deterministic scoring rules."
  },
  "methodology": {
    "methods": [
      "Automated metrics"
    ],
    "metrics": [
      "Success Rate",
      "Normalized attempts"
    ],
    "calculation": "Metrics are calculated based on deterministic scoring rules associated with each specific task.",
    "interpretation": "Higher success rates and lower normalized attempts indicate better performance in reasoning and interaction tasks.",
    "baseline_results": "Not explicitly provided.",
    "validation": "Evaluation of frontier models demonstrates performance across the tasks."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}