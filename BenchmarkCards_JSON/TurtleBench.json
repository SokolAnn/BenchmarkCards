{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "TurtleBench",
    "abbreviation": "N/A",
    "overview": "TurtleBench is a dynamic evaluation benchmark that collects real user guesses from an online Turtle Soup Puzzle game, assessing the reasoning capabilities of large language models (LLMs) without relying on external knowledge bases. The dataset includes 1,532 annotated entries.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English",
      "Chinese"
    ],
    "similar_benchmarks": [
      "MMLU",
      "ARC",
      "MT-Bench"
    ],
    "resources": [
      "https://github.com/mazzzystar/TurtleBench"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a reliable evaluation benchmark for assessing LLM reasoning capabilities in natural language understanding and logical reasoning.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Real user guesses collected from the Turtle Soup Puzzle game.",
    "size": "1,532 examples",
    "format": "CSV",
    "annotation": "Manual annotation by annotators who categorized guesses as Correct, Incorrect, or Unknown."
  },
  "methodology": {
    "methods": [
      "Human evaluation"
    ],
    "metrics": [
      "Accuracy",
      "F1 Score"
    ],
    "calculation": "Accuracy is calculated as the ratio of correct answers to total answers; F1 Score is computed based on the true positives, false positives, and false negatives.",
    "interpretation": "Higher scores indicate better reasoning capabilities of the evaluated models.",
    "baseline_results": "Claude-3.5-Sonnet and GPT-4o achieved accuracy above 87% in evaluations.",
    "validation": "Dataset was validated by manual checks of user guesses against established answers."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Data poisoning"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}