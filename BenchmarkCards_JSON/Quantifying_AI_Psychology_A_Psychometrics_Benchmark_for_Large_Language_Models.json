{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models",
    "abbreviation": "N/A",
    "overview": "This paper presents a comprehensive psychometrics benchmark for LLMs that covers six psychological dimensions: personality, values, emotion, theory of mind, motivation, and intelligence. The benchmark includes thirteen datasets featuring diverse scenarios and item types to assess LLMs' psychological attributes.",
    "data_type": "multimodal",
    "domains": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "Psychometrics"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2406.17675"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of the benchmark is to investigate the psychological attributes of large language models (LLMs) through a psychometric framework, providing a comprehensive assessment of their behaviors and abilities.",
    "audience": [
      "ML Researchers",
      "Psychologists",
      "AI Developers",
      "Social Scientists"
    ],
    "tasks": [
      "Psychological Assessment",
      "Behavior Analysis",
      "Model Evaluation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Three sources: standard psychometrics tests, established datasets, and self-designed scenarios.",
    "size": "Thirteen datasets",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Evaluation using psychometric tests",
      "Model-based assessments",
      "Open-ended response validation"
    ],
    "metrics": [
      "Accuracy",
      "Dual Question Accuracy",
      "Kappa coefficient"
    ],
    "calculation": "Metrics are calculated based on averages of scores from item responses and evaluations by LLM raters.",
    "interpretation": "Higher scores represent a stronger manifestation of psychological dimensions in LLMs.",
    "baseline_results": "N/A",
    "validation": "Validation processes include internal consistency checks and inter-rater reliability assessments."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Ethical Concerns",
      "Cultural Sensitivity"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}