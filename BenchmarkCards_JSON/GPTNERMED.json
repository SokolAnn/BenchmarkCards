{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "GPTNERMED",
    "abbreviation": "GPTNERMED",
    "overview": "A custom, synthesized annotated dataset for German medical named entity recognition (NER) created by few-shot prompting of a pretrained language model (GPT NeoX) using a simple markup format; the dataset is used to train medical NER models (GPTNERMED).",
    "data_type": "annotated text (entity-annotated sentences for Named Entity Recognition)",
    "domains": [
      "Natural Language Processing",
      "Healthcare"
    ],
    "languages": [
      "German"
    ],
    "similar_benchmarks": [
      "MIMIC-III",
      "MIMIC-IV",
      "n2c2 (2018 ADE dataset)",
      "UFAL Medical Corpus",
      "Mantra GSC",
      "BRONCO",
      "GGPONC 1.0",
      "GGPONC 2.0"
    ],
    "resources": [
      "https://github.com/frankkramer-lab/GPTNERMED",
      "https://huggingface.co/smanjil/German-MedBERT",
      "https://ufal.mff.cuni.cz/ufal_medical_corpus"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Leverage pretrained language models for training data acquisition to synthesize sufficiently large, domain-aligned annotated datasets for training smaller and more efficient models for use-case specific NLP tasks; demonstrate effectiveness by creating a German medical NER dataset and training NER models.",
    "audience": [
      "German medical NLP research community",
      "Model developers",
      "ML researchers"
    ],
    "tasks": [
      "Named Entity Recognition"
    ],
    "limitations": "The dataset remains synthetic and thus cannot be considered a gold standard-level dataset; limited availability of annotated German medical datasets with differing label classes prevents exhaustive evaluation; synthesized dataset contains structurally similar sentences that may allow models to potentially overfit; high computational costs to generate the dataset.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic corpus generated by GPT NeoX-20B via few-shot prompting with markup-encoded seed sentences (12 seed sentences) and markup-based generation; outputs parsed to obtain silver-standard annotations.",
    "size": "Final dataset: 9,845 sentences; 245,107 tokens; annotation counts: Medikation (#9,868), Dosis (#7,547), Diagnose (#5,996). (Raw baseline prior to filtering: 17,776 sentences.)",
    "format": "Markup-encoded plain text using <s>...</s> sentence tags and <class=\"...\">...</class> entity tags; parsed to produce annotated sentences (silver-standard).",
    "annotation": "Automatically generated annotations via markup-based generation by GPT NeoX and parsed into annotations; silver-standard. Post-processing filters applied: must have closing </s> tag, parseable valid syntax and labels, at least one annotation, labels part of predefined set, and deduplication."
  },
  "methodology": {
    "methods": [
      "Automated metrics (Precision, Recall, F1)",
      "Out-of-distribution evaluation on a small gold-standard German dataset",
      "Training NER models by fine-tuning BERT-based encoders with the synthesized dataset"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "F1 Score"
    ],
    "calculation": "Evaluation computed in strict mode as a character-wise classification task (exact overlaps and label classes are considered).",
    "interpretation": "The authors state that the reported Precision/Recall/F1 scores indicate strong performance of the trained models on all label classes, but caution that high scores may be influenced by dataset homogeneity which can allow models to potentially overfit to structure rather than content.",
    "baseline_results": "Test set (character-wise strict mode) total F1 scores: gbert-large: F1 0.918 (Precision 0.918? table shows totals per row); GottBERT-base: F1 0.910; German-MedBERT: F1 0.883. Out-of-distribution (OoD) dataset Drug/Medikation F1: gbert-large 0.821, GottBERT-base 0.847, German-MedBERT 0.770.",
    "validation": "Random split into 80% training, 10% validation, 10% test. The final model was selected based on the lowest F1 score on the validation set (as stated by the authors)."
  },
  "targeted_risks": {
    "risk_categories": [
      "Privacy",
      "Robustness",
      "Accuracy",
      "Societal Impact"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Privacy",
          "subcategory": [
            "Exposing personal information"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Extraction attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on the environment"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Authors discuss privacy concerns regarding potential training data extraction attacks that could uncover patient-related data for models trained on sensitive data. Authors also state that the synthetic nature of the corpus allows providing the dataset and trained models publicly without further access restrictions, avoiding pseudonymization and related legal ramifications.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}