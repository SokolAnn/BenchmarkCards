# THaMES

## üìä Benchmark Details

**Name**: THaMES

**Overview**: THaMES is an end-to-end framework that evaluates and mitigates hallucinations in Large Language Models (LLMs) through automated testset generation, multifaceted benchmarking techniques, and flexible mitigation strategies.

**Data Type**: Text

**Domains**:
- Political news articles
- Academic papers
- Wikipedia articles

**Languages**:
- English

**Similar Benchmarks**:
- HaluEval
- DelucionQA

**Resources**:
- [GitHub Repository](https://github.com/holistic-ai/THaMES)

## üéØ Purpose and Intended Users

**Goal**: To provide a framework for evaluating and mitigating hallucinations generated by language models.

**Target Audience**:
- Researchers
- Developers
- AI practitioners

**Tasks**:
- Hallucination evaluation
- Dataset generation
- Mitigation strategy application

**Limitations**: Due to computational constraints, evaluation was limited to quantized models.

**Out of Scope Uses**:
- General AI applications beyond hallucination evaluation

## üíæ Data

**Source**: Generated from a mix of academic papers, political news articles, and Wikipedia articles.

**Size**: 2100 question-answer sets

**Format**: JSON

**Annotation**: Includes correct answers and hallucinated answers.

## üî¨ Methodology

**Methods**:
- Automated testset generation
- Evaluation of hallucination types
- Application of mitigation strategies

**Metrics**:
- Answer Faithfulness
- Answer Relevancy
- Answer Correctness
- Answer Similarity
- Accuracy

**Calculation**: Metrics calculated using predefined evaluation criteria based on LLM outputs.

**Interpretation**: Scores represent LLM performance on hallucination-related tasks.

**Validation**: Evaluation across multiple LLMs to determine effectiveness of mitigation strategies.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy risk
- Transparency risk
- Fairness risk

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Transparency**: Lack of training data transparency
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
