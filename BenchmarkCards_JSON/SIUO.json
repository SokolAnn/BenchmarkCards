{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "SIUO (Safe Inputs but Unsafe Output)",
    "abbreviation": "SIUO",
    "overview": "SIUO introduces a cross-modality benchmark that evaluates the safety alignment of Large Vision-Language Models by considering cases where single modalities may be safe on their own but can lead to unsafe outputs when combined.",
    "data_type": "image-text pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [],
    "similar_benchmarks": [
      "VLSafe",
      "GOAT-Bench",
      "MM-Safetybench"
    ],
    "resources": [
      "https://sinwang20.github.io/SIUO/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate the cross-modality safety alignment of Large Vision-Language Models by identifying safety vulnerabilities when combining safe inputs.",
    "audience": [
      "AI Researchers",
      "Developers of Large Vision-Language Models",
      "Safety Analysts"
    ],
    "tasks": [
      "Safety Evaluation",
      "Effectiveness Evaluation"
    ],
    "limitations": "The current dataset size is not large but covers 9 safety aspects and 33 subcategories.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Human curation and AI-assisted curation methods were utilized to construct the SIUO dataset.",
    "size": "1,079 test cases",
    "format": "JSONL",
    "annotation": "Data annotated through manual reviews and consensus by team members, ensuring quality."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics using GPT-4V"
    ],
    "metrics": [
      "Safe Rate",
      "Effective Rate"
    ],
    "calculation": "Safe Rate is the ratio of safe responses to total responses, and Effective Rate is the ratio of effective responses to total responses.",
    "interpretation": "Safe responses are those that do not lead to unsafe behavior, while effective responses are those that adequately address user inquiries.",
    "baseline_results": null,
    "validation": "Dual validation through automated model safety reviews and human evaluations."
  },
  "targeted_risks": {
    "risk_categories": [
      "Safety",
      "Privacy",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": null,
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Data derived from publicly available sources, ensuring compliance with privacy regulations and anonymizing identifiable information.",
    "data_licensing": "Dataset sourced from public and openly licensed datasets, adhering to relevant copyright policies.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}