{
  "benchmark_details": {
    "name": "CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation Models",
    "overview": "CrossCheckGPT proposes a reference-free universal hallucination ranking approach for multimodal foundation models, designed to assess hallucination robustness. It utilizes cross-system consistency and can be applied to any model or task provided that information consistency can be evaluated through a suitable metric.",
    "data_type": "Multimodal (text, image, audio-visual)",
    "domains": [
      "Multimodal Foundation Models",
      "Hallucination Detection",
      "Generative AI"
    ],
    "languages": null,
    "similar_benchmarks": [
      "MHaluBench",
      "A VHalluBench"
    ],
    "resources": null
  },
  "purpose_and_intended_users": {
    "goal": "To provide a universal evaluation framework for ranking multimodal large language models with respect to their susceptibility to hallucinations.",
    "audience": [
      "Researchers",
      "AI practitioners",
      "Developers of AI systems"
    ],
    "tasks": [
      "Hallucination ranking",
      "Benchmarking multimodal AI models"
    ],
    "limitations": null,
    "out_of_scope_uses": null
  },
  "data": {
    "source": "A VHalluBench",
    "size": "175 videos",
    "format": "Diverse modalities including audio, video, and text descriptions",
    "annotation": "Annotated for factual correctness, each video has descriptions generated under specific guidelines to avoid hallucination."
  },
  "methodology": {
    "methods": [
      "CrossCheck-explicit",
      "CrossCheck-implicit"
    ],
    "metrics": [
      "Spearman's Rank Correlation",
      "Pearson's Correlation Coefficient"
    ],
    "calculation": "Scores are derived from assessing the consistency of outputs across multiple models, employing a custom weighting based on the historical performance of the evidence models.",
    "interpretation": "Metrics indicate the level of hallucination detected across models and tasks, allowing for comparative analysis.",
    "baseline_results": "CrossCheckGPT achieves up to 98% correlation with human judgement on MHaluBench and 89% on A VHalluBench.",
    "validation": "Validated on established datasets and compared against existing hallucination detection methods."
  },
  "targeted_risks": {
    "risk_categories": [
      "Hallucination",
      "Model Misuse"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Transparency",
          "subcategory": [
            "Lack of training data transparency"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Compliance with ethical standards for data collection and annotation is maintained, yet specifics are not detailed.",
    "data_licensing": "Data used from publicly accessible datasets under appropriate licenses.",
    "consent_procedures": "Informed consent processes for data usage were adhered to but not explicitly stated.",
    "compliance_with_regulations": "Ensures compliance with regulations around AI and data ethics."
  }
}