{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution",
    "abbreviation": "N/A",
    "overview": "This paper establishes a comprehensive and coherent benchmark to evaluate the defense performance of textual defenders against adversarial word substitution attacks in NLP models. It aims to provide reliable insights into the effectiveness of various defense algorithms.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/RockyLzy/TextDefender"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To systematically study the advantages and disadvantages of different textual defense methods against adversarial word substitution attacks.",
    "audience": [
      "ML Researchers",
      "Defense Algorithm Developers"
    ],
    "tasks": [
      "Text Classification",
      "Sentiment Analysis"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "AG-News and IMDB datasets for experiments on text classification and sentiment analysis tasks.",
    "size": "N/A",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Empirical evaluation of defense methods using adversarial attacks",
      "Quantitative benchmarking against various attack algorithms"
    ],
    "metrics": [
      "Clean Accuracy",
      "Accuracy Under Attack",
      "Attack Success Rate",
      "Number of Queries"
    ],
    "calculation": "Metrics were calculated based on model performance metrics under both clean and adversarial conditions.",
    "interpretation": "Higher clean accuracy and lower attack success rate indicate better defense methods.",
    "baseline_results": "BERT base model performance reported.",
    "validation": "Extensive experiments conducted to compare the performance of various defense methods."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}