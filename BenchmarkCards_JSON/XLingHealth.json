{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "XLingHealth (Cross-Lingual Healthcare Benchmark)",
    "abbreviation": "XLingHealth",
    "overview": "XLingHealth is a cross-lingual healthcare benchmark for clinical health inquiry that focuses on evaluating multilingual capabilities of large language models (LLMs) in relation to healthcare queries. It incorporates datasets translated into Hindi, Chinese, and Spanish, and uses the framework XLingEval for comprehensive assessments.",
    "data_type": "question-answering pairs",
    "domains": [
      "Healthcare"
    ],
    "languages": [
      "English",
      "Spanish",
      "Chinese",
      "Hindi"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/claws-lab/XLingEval"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of XLingHealth is to assess the multilingual capabilities of large language models (LLMs) in healthcare contexts, ensuring equitable access to health information across languages.",
    "audience": [
      "Healthcare practitioners",
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Developed from three healthcare datasets: HealthQA, LiveQA, and MedicationQA, which are originally curated in English and translated into other languages.",
    "size": "2,070 question-answer pairs",
    "format": "N/A",
    "annotation": "Expert-annotated by medical professionals."
  },
  "methodology": {
    "methods": [
      "Automated evaluation",
      "Human evaluation"
    ],
    "metrics": [
      "Correctness",
      "Consistency",
      "Verifiability"
    ],
    "calculation": "Metrics are calculated through comparative analyses of LLM-generated responses against ground truth answers across multiple languages.",
    "interpretation": "Higher scores indicate better performance in providing correct, consistent, and verifiable responses.",
    "baseline_results": null,
    "validation": "Through a combined approach of algorithmic evaluation and expert human evaluation."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on cultural diversity"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}