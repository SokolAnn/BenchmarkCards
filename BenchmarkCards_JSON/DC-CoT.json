{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "DC-CoT (Data-Centric Chain-of-Thought)",
    "abbreviation": "DC-CoT",
    "overview": "DC-CoT is the first data-centric benchmark designed to investigate data manipulation in chain-of-thought (CoT) distillation from method, model, and data perspectives, systematically assessing the effectiveness of various distillation approaches.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "SQA",
      "CSQA",
      "ARC",
      "GSM8K",
      "MATH",
      "ANLI",
      "Webarena",
      "Visual-CoT"
    ],
    "resources": [
      "https://arxiv.org/abs/2505.18759"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To systematically evaluate how data-centric strategies improve the distillation of reasoning capabilities from larger models to smaller, more efficient student models.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Textual Reasoning",
      "Agentic Reasoning",
      "Visual Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Various reasoning datasets including SQA, CSQA, ARC, GSM8K, MATH, ANLI, and others.",
    "size": "Multiple datasets with varying sizes, including 100,000+ examples for training.",
    "format": "N/A",
    "annotation": "Generated through various augmentation techniques and filtering methods."
  },
  "methodology": {
    "methods": [
      "Data Augmentation",
      "Data Filtering",
      "Data Mixing"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Metrics are calculated based on performance evaluations using various reasoning tasks.",
    "interpretation": "Higher accuracy indicates better performance of the student models in reasoning tasks.",
    "baseline_results": null,
    "validation": "Extensive experiments across diverse teacherâ€“student pairs, tasks, and datasets."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "Various licenses including MIT, Apache, CC BY-NC, etc.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}