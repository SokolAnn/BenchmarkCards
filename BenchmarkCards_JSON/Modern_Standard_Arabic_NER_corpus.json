{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Modern Standard Arabic NER corpus",
    "abbreviation": "N/A",
    "overview": "This work provides a new structured dataset for Named Entity Recognition (NER) in the Arabic language covering seven domains (Geography, History, Medical, Sport, Technology, News, and Cooking) using the BIOES format; the dataset consists of more than thirty-six thousand records. The paper also proposes LSTM and GRU models for Arabic NER and reports approximately 80% precision on validation and test sets.",
    "data_type": "Token-level labeled text (word, tag pairs)",
    "domains": [
      "Natural Language Processing",
      "Geography",
      "History",
      "Medical",
      "Sport",
      "Technology",
      "News",
      "Cooking"
    ],
    "languages": [
      "Arabic",
      "Modern Standard Arabic"
    ],
    "similar_benchmarks": [],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Provide a new structured dataset for Arabic named entity recognition covering seven fields and evaluate LSTM and GRU models on it.",
    "audience": [],
    "tasks": [
      "Named Entity Recognition",
      "Text Classification",
      "Sentence Classification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "New dataset created by the authors, organized into training, validation, and test sets; dataset covers seven fields (Geography, History, Medical, Sport, Technology, News, Cooking) and is stored as multiple Excel files.",
    "size": "143 files; 2,104 sentences; 36,380 words (Training: 120 files, 1,731 sentences, 31,586 words; Validation: 15 files, 218 sentences, 3,107 words; Test: 8 files, 155 sentences, 1,687 words)",
    "format": "Excel files (each with four columns: file_name, sentence, word, tag)",
    "annotation": "Annotated using BIOES format; nine entity categories: Person (PER), Location (LOC), Geopolitical (GPE), Time (TIM), Profession (PRO), Organization (ORG), Disease (DIS), Geography (GEO), Miscellaneous (MISC)."
  },
  "methodology": {
    "methods": [
      "Model evaluation using trained LSTM and GRU models",
      "Automated metrics (precision) using held-out validation and test sets"
    ],
    "metrics": [
      "Precision"
    ],
    "calculation": "The accuracy measure used in this work is precision, which equals dividing the accurately predicted labels by the total number of labels in the sentence.",
    "interpretation": "Results around approximately 80% precision are described as relatively good; authors state models can generalize and successfully detect named entities in validation and test sets. Increasing iterations did not necessarily improve results beyond a reached threshold.",
    "baseline_results": "Table 3 results: 500 iterations - LSTM validation 81.86%, test 80.24%; 500 iterations - GRU validation 78.86%, test 77.78%. 1000 iterations - LSTM validation 79.88%, test 80.06%; 1000 iterations - GRU validation 76.26%, test 75.38%. Number of trainable parameters: LSTM 608,937; GRU 603,887.",
    "validation": "Dataset split into training (120 files), validation (15 files), and test (8 files); results reported on validation and test sets."
  },
  "targeted_risks": {
    "risk_categories": [],
    "atlas_risks": {
      "risks": null
    },
    "demographic_analysis": null,
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}