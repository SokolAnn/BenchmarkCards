{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "REALM (Real-world Applications of Large Language Models)",
    "abbreviation": "REALM",
    "overview": "REALM is a dataset of over 94,000 LLM use cases collected from Reddit and news articles that captures diverse applications of LLMs and the demographics of their users. It provides insights into LLM adoption across different domains.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing",
      "Social Science",
      "Human-Computer Interaction"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://realm-e7682.web.app/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a comprehensive understanding of real-world LLM applications and their societal impacts.",
    "audience": [
      "Researchers",
      "Policy makers",
      "Industry professionals"
    ],
    "tasks": [
      "Use case analysis",
      "Trend analysis",
      "Impact assessment"
    ],
    "limitations": "The dataset is exclusively derived from Reddit and news articles, excluding other significant platforms such as Twitter and Facebook.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Collected from Reddit and news articles via NewsAPI and Academic Torrents.",
    "size": "94,000 examples",
    "format": "JSON",
    "annotation": "Annotated using a systematic pipeline involving expert and automated methods."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics",
      "Expert annotation"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "F1 Score"
    ],
    "calculation": "Metrics calculated based on the performance of the classification and annotation pipelines.",
    "interpretation": "A high recall indicates good identification of use cases despite the low prior prevalence.",
    "baseline_results": null,
    "validation": "Validated through expert annotations achieving high inter-annotator agreement."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Data privacy rights alignment"
          ]
        }
      ]
    },
    "demographic_analysis": "The dataset includes demographic breakdowns based on the professions of users.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "User data is anonymized to protect personal information.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}