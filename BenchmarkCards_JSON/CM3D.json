{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CM3D (Chinese Multimodal Metaphor Mapping Dataset)",
    "abbreviation": "CM3D",
    "overview": "The CM3D dataset includes annotations of metaphorical expressions within both target and source domains, specifically focused on the Chinese language. It aims to facilitate further research on metaphors, particularly in non-English linguistic contexts.",
    "data_type": "text-image pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Chinese"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://gitfront.io/r/GiveATry/nNCeJacwmNpG/CM3D/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a dedicated resource for understanding multimodal metaphors by identifying target and source domains in Chinese advertisements.",
    "audience": [
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Metaphor Mapping Identification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Curated from Chinese advertisements featuring metaphors with visual and textual elements.",
    "size": "6,108 pairs",
    "format": "N/A",
    "annotation": "Manually annotated by experts in computational linguistics, focusing on identifying target and source domains."
  },
  "methodology": {
    "methods": [
      "Chain-of-Thought prompting",
      "Bi-Level Optimization"
    ],
    "metrics": [
      "Accuracy",
      "BertScore",
      "Human Evaluation"
    ],
    "calculation": "Metrics are computed based on the model's performance in accurately identifying the target and source domains.",
    "interpretation": "Higher scores indicate better performance in identifying metaphorical domains accurately.",
    "baseline_results": "N/A",
    "validation": "Assessments were conducted through human evaluation with significant agreement among annotators."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}