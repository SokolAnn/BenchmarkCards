{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "HateDefCon",
    "abbreviation": "N/A",
    "overview": "HateDefCon is the first dataset for hate speech definitions encompassing 493 definitions from over 100 cultures across five domains, aiming to analyze and understand the impact of varying definitions on hate speech detection using LLMs.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/katkorre/SCA-of-Hate-Speech.git"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a comprehensive resource for hate speech definitions and their semantic components, facilitating cross-cultural and cross-domain analysis.",
    "audience": [
      "ML Researchers",
      "Social Scientists",
      "Legal Experts"
    ],
    "tasks": [
      "Text Classification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Collected definitions from the Global Handbook of Hate Speech Laws, Wikipedia articles, academic research papers, online dictionaries, and online platform policies.",
    "size": "493 definitions",
    "format": "N/A",
    "annotation": "Annotated using Semantic Componential Analysis (SCA) with manual review and binary annotations for presence of components."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "F1 Score"
    ],
    "calculation": "Measured based on the ability of LLMs to classify hate speech using different definitions.",
    "interpretation": "Performance varies based on the complexity and comprehensiveness of the definitions used.",
    "baseline_results": null,
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}