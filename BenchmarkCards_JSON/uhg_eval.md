# UHG Eval

## üìä Benchmark Details

**Name**: UHG Eval

**Overview**: Unconstrained Hallucination Generation Evaluation (UHG Eval) benchmark for assessing hallucination phenomena in large language models (LLMs) through unconstrained text generation. The benchmark allows for a wider range of real-world hallucination scenarios as opposed to constrained generation techniques.

**Data Type**: Text

**Domains**:
- News
- Education
- Science
- Society
- Finance
- Technology

**Languages**:
- Chinese

**Similar Benchmarks**:
- TruthfulQA
- HaluEval
- HaDes

**Resources**:
- [Resource](https://iaar-shanghai.github.io/UHGEval/)

## üéØ Purpose and Intended Users

**Goal**: To evaluate and benchmark the hallucination phenomena in Chinese large language models (LLMs).

**Target Audience**:
- Researchers
- Developers
- AI practitioners

**Tasks**:
- Benchmarking LLMs
- Understanding hallucination in LLMs
- Testing model reliability

**Limitations**: Limited to Chinese language models and specific to hallucination aspects in generation.

**Out of Scope Uses**:
- Applications outside of hallucination evaluation
- Non-Linguistic models

## üíæ Data

**Source**: Collected from historical Chinese news articles, covering various topics from January 2015 to January 2017.

**Size**: 5,141 hallucinated continuations

**Format**: Text

**Annotation**: Annotated for hallucinations by a mix of automatic labeling and manual verification.

## üî¨ Methodology

**Methods**:
- Unconstrained generation
- Human annotation
- Keyword extraction
- Fluency assessment

**Metrics**:
- Accuracy
- Precision
- Recall
- BLEU-4
- ROUGE-L
- kwPrec
- BERTScore

**Calculation**: Metrics calculated based on comparison between generated continuations and reference information across various dimensions.

**Interpretation**: The metrics indicate the extent of hallucinations and the reliability of LLM outputs based on generated continuations.

**Validation**: Each dataset entry underwent a two-stage validation process comprising automated labeling and human re-checking.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Hallucination generation risks
- Data quality risks

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Robustness**: Hallucination
- **Fairness**: Output bias

**Demographic Analysis**: Analysis focused on performance across various demographics in Chinese language processing models.

**Potential Harm**: Potential harm related to the propagation of false or misleading information generated by LLMs.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Data collected from publicly available news sources, no personally identifiable information included.

**Data Licensing**: Datasets derived from public domain news articles and existing datasets with proper citations.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Complies with applicable regulations regarding the use of public data.
