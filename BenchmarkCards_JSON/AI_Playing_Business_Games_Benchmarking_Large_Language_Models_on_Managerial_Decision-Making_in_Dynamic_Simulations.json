{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations",
    "abbreviation": "N/A",
    "overview": "This research proposes a reproducible, open-access management simulator for evaluating the performance of Large Language Models (LLMs) in long-term managerial decision-making through a business game, addressing a research gap in AI benchmarks for complex, multi-step decisions.",
    "data_type": "tabular",
    "domains": [
      "Natural Language Processing",
      "Business Management"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "Vending-Bench"
    ],
    "resources": [
      "https://sourceforge.net/projects/supply-chain-competition-game/files/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To benchmark leading LLMs in a dynamic management simulation and evaluate their decision-making capabilities over a 12-month period.",
    "audience": [
      "ML Researchers",
      "Business Educators",
      "Industry Practitioners"
    ],
    "tasks": [
      "Managerial Decision Making"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Open-access management simulation developed in Microsoft Excel.",
    "size": "12 months of simulated decision data",
    "format": "Excel",
    "annotation": "The decisions made by LLMs are recorded alongside performance metrics."
  },
  "methodology": {
    "methods": [
      "Quantitative analysis",
      "Qualitative analysis of LLM rationales"
    ],
    "metrics": [
      "Revenue",
      "Net Income",
      "Market Share"
    ],
    "calculation": "Metrics are calculated based on the outputs of the simulation for each of the 12 months.",
    "interpretation": "Results reflect each LLM's coherence, adaptability, and decision-making effectiveness in business management.",
    "baseline_results": null,
    "validation": "The simulation promotes reproducibility and transparency, intended for rigorous comparison."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}