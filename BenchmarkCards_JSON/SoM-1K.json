{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials",
    "abbreviation": "SoM-1K",
    "overview": "SoM-1K is the first large-scale multimodal benchmark dataset dedicated to evaluating foundation models on problems in the strength of materials. It contains 1,065 annotated SoM problems, which integrate both textual problem statements and schematic diagrams.",
    "data_type": "multimodal",
    "domains": [
      "Engineering"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://som-1k.github.io/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To establish a rigorous benchmark for engineering AI and evaluate the problem-solving abilities of foundation models in strength of materials.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers",
      "Domain Experts"
    ],
    "tasks": [
      "Multimodal Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Problems selected from widely-used university textbooks and mechanics competitions.",
    "size": "1,065 problems",
    "format": "PDF",
    "annotation": "Problems annotated by a team of experienced researchers and educators in structural engineering."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Majority voting"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Evaluation based on manually scored correctness of model outputs for each problem type.",
    "interpretation": "An accuracy score of 56.6% indicates the best-performing foundation model in this benchmark.",
    "baseline_results": "Top-performing models are Qwen-plus (56.6%), DeepSeek-R1 (52.4%), and Doubao (48.5%).",
    "validation": "Manually reviewed by human experts to ensure reliable performance ratings."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}