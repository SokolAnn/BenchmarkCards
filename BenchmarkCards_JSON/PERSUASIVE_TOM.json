{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "PERSUASIVE TOM (Persuasive Theory of Mind)",
    "abbreviation": "PERSUASIVE TOM",
    "overview": "PERSUASIVE TOM is a benchmark designed to evaluate the Theory of Mind (ToM) abilities of Large Language Models (LLMs) in persuasive dialogues by assessing their capacity to reason about mental states and apply this understanding to predict and assess persuasion strategies.",
    "data_type": "multi-turn persuasive dialogues",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "ToMi",
      "FANToM",
      "NegotiationToM"
    ],
    "resources": [
      "https://github.com/Yu-Fangxu/PersuasiveToM"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate LLMs' Theory of Mind capabilities in dynamic, multi-turn persuasive dialogues.",
    "audience": [
      "ML Researchers",
      "AI Developers"
    ],
    "tasks": [
      "ToM Reasoning",
      "ToM Application"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Annotated on the multi-turn persuasive dialogue dataset DailyPersuasion.",
    "size": "19,000 questions",
    "format": "N/A",
    "annotation": "Annotated by graduate students and enhanced with LLM assistance."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Measured based on responses to ToM reasoning and application tasks.",
    "interpretation": "Understanding of dynamic mental states and persuasive strategies.",
    "baseline_results": "Human performance on benchmark tasks serves as a comparative baseline.",
    "validation": "Experiments conducted across eight leading LLMs with comparative analysis."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Prompt injection attack"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}