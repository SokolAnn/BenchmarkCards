{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "A Benchmark for Cross-Domain Argumentative Stance Classification on Social Media",
    "abbreviation": "N/A",
    "overview": "We propose a scalable and extensible benchmark for cross-domain argumentative stance classification comprising 4,498 topical claims and 30,961 arguments sourced from social media platforms and large language models, spanning 21 diverse domains without the need for human annotation.",
    "data_type": "argument pairs",
    "domains": [
      "Natural Language Processing",
      "Social Media"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "SemEval"
    ],
    "resources": [
      "N/A"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To construct a diverse and multisource stance classification benchmark that provides robust baselines for evaluating stance classification methodologies.",
    "audience": [
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Stance Classification"
    ],
    "limitations": "The benchmark construction is limited by the types of platforms available for stance label extraction.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Social media (ChangeMyView subreddit), debate websites, and arguments generated by large language models.",
    "size": "30,961 arguments across 4,498 topical claims",
    "format": "N/A",
    "annotation": "No human annotation; relies on platform rules and expert-curated content."
  },
  "methodology": {
    "methods": [
      "Fully supervised learning",
      "Zero-shot learning",
      "Few-shot learning"
    ],
    "metrics": [
      "F1 Score",
      "Macro F1 Score"
    ],
    "calculation": "Evaluated using traditional machine learning models and contemporary LLMs.",
    "interpretation": "Higher macro-F1 scores indicate better performance in stance classification tasks.",
    "baseline_results": "The study provides strong baselines across diverse domains.",
    "validation": "Models were validated against traditional benchmarks and various learning settings."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Prompt leaking"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "No personally identifiable information is involved in the dataset.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}