{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Dataset Grouper",
    "abbreviation": "N/A",
    "overview": "Dataset Grouper, a library to create large-scale group-structured (e.g., federated) datasets, enabling federated learning simulation at the scale of foundation models. The library facilitates creation of group-structured versions of existing datasets based on user-specified partitions, is engineered for efficiency and scalability, and is framework-agnostic.",
    "data_type": "text (group-structured language modeling sequences)",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "TensorFlow Federated",
      "LEAF",
      "FedNLP",
      "FedScale",
      "FedML",
      "FedJAX",
      "WILDS",
      "FLAIR",
      "FLamby",
      "Motley",
      "pFL-bench"
    ],
    "resources": [
      "https://github.com/google-research/dataset_grouper",
      "https://github.com/google-research/dataset_grouper/tree/main/dataset_grouper/examples/datasets",
      "https://pypi.org/project/dataset-grouper/",
      "https://arxiv.org/abs/2307.09619"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Enable creation of large-scale group-structured (federated) datasets and provide scalable, efficient dataset pipelines suitable for foundation-model-scale federated learning simulation, pre-training, fine-tuning, and downstream personalization experiments.",
    "audience": [
      "Federated Learning Researchers",
      "Machine Learning Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Language Modeling",
      "Pre-training",
      "Fine-tuning",
      "Federated Learning simulation",
      "Personalization",
      "Evaluation (group-level evaluation)"
    ],
    "limitations": "Dataset Grouper does not host datasets and instead creates partitioned versions of existing datasets; users must ensure that their use falls under the license of the base dataset and abide by associated terms. The library requires partition functions to be embarrassingly parallel for scalability.",
    "out_of_scope_uses": [
      "Creating partition methods that require sequential or non-embarrassingly-parallel operations (Dataset Grouper supports only embarrassingly parallel partition methods).",
      "Guaranteeing hosting of partitioned datasets in perpetuity (Dataset Grouper does not host datasets)."
    ]
  },
  "data": {
    "source": "Group-structured versions of existing datasets created via partitioning: Colossal Clean Crawled Corpus (C4) -> FedC4 (partitioned by web domain), Wikipedia (English) -> FedWiki (one full English article per client), BookCorpusOpen -> FedBookCO (one book per client), CC-News -> FedCCnews (partitioned by web domain). Base datasets accessed via TensorFlow Datasets and HuggingFace Datasets.",
    "size": "FedC4: 15.6M clients; 132B words; 0.36B examples. FedWiki: 6.5M clients; 3B words; 6.5M examples. FedBookCO: 18K clients; 1.2B words; 18K examples. FedCCnews: 8.8K clients; 0.3B words; 0.7M examples. (Numbers from Tables 6 and 7 in the paper.)",
    "format": "TFRecord (streaming TFRecord files; datasets exposed via tf.data and nested iterators of tensors compatible with TensorFlow and NumPy).",
    "annotation": "Not annotated (raw text for language modeling); N/A for supervised labels."
  },
  "methodology": {
    "methods": [
      "Federated training experiments (FedAvg, FedSGD)",
      "Automated metrics evaluation (causal language modeling loss / cross-entropy)",
      "Per-group evaluation (histograms and percentile summaries across clients)",
      "Iteration/time profiling of dataset pipelines"
    ],
    "metrics": [
      "Causal language modeling loss (cross-entropy; equals logarithm of perplexity)",
      "Per-client validation loss percentiles (10th percentile, median, 90th percentile)",
      "Iteration time (seconds) to iterate over dataset and percentage of training time spent on data iteration",
      "Pre-personalization loss and Post-personalization loss (average causal language modeling loss before and after client fine-tuning)"
    ],
    "calculation": "Per-round training loss: average the loss over all batches seen by a given client within the round, then average that quantity across participating clients. Pre-personalization loss: average causal language modeling loss of the model on all examples held by a client before personalization. Post-personalization loss: average causal language modeling loss after fine-tuning the model for a single epoch on the client's dataset. Iteration time: time to iterate over all examples in all group datasets in serial on a single CPU (average and standard deviation over trials).",
    "interpretation": "Lower causal language modeling loss (log perplexity) indicates better model performance. The paper interprets that FedAvg behaves more like a meta-learning algorithm (leading to much lower post-personalization loss) while FedSGD behaves more like empirical risk minimization (better pre-personalization loss). Dataset iteration taking under ~10% of runtime indicates efficient streaming format.",
    "baseline_results": "Table 5 (FedC4 validation): FedAvg pre-personalization loss percentiles (10th: 5.13, median: 5.64, 90th: 6.27); FedAvg post-personalization (10th: 0.002, median: 0.012, 90th: 0.934). FedSGD pre-personalization (10th: 4.38, median: 4.93, 90th: 5.40); FedSGD post-personalization (10th: 1.25, median: 3.38, 90th: 4.53). (Additional experimental results and ablations reported in paper figures and tables.)",
    "validation": "Validation uses the held-out validation split of the base datasets (e.g., C4 validation split) partitioned with the same group structure. Per-client histograms and percentile statistics are computed across all validation clients (FedWiki personalization samples 20K clients due to size). Iteration time and memory usage are measured on a single CPU; training experiments run on TPU Pod slice (16 TPU v3 chips)."
  },
  "targeted_risks": {
    "risk_categories": [
      "Privacy",
      "Legal Compliance",
      "Governance",
      "Accuracy",
      "Intellectual Property"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        },
        {
          "category": "Data Laws",
          "subcategory": [
            "Data usage restrictions"
          ]
        },
        {
          "category": "Governance",
          "subcategory": [
            "Incomplete usage definition"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Data contamination"
          ]
        },
        {
          "category": "Intellectual Property",
          "subcategory": [
            "Copyright infringement",
            "Data usage rights restrictions"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Privacy and memorization concerns of training data (discussion of user-level differential privacy and memorization)",
      "Enshrinement of datasets as 'sole benchmarks' and misuse beyond intended tasks",
      "Possible copyright issues and dataset licensing concerns (noted for BookCorpusOpen and base datasets)"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "The paper discusses privacy and memorization concerns and the need for user-level differential privacy; no specific anonymization procedures for the provided partitioned datasets are detailed.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}