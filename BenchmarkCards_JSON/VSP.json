{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "VSP (Visual Spatial Planning)",
    "abbreviation": "VSP",
    "overview": "VSP is introduced to evaluate the spatial planning capabilities of vision language models (VLMs), focusing on tasks that require understanding spatial arrangements of objects and devising action plans in visual scenes.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "MME",
      "MMMU",
      "MathVision",
      "SeedBench",
      "MM-Vet"
    ],
    "resources": [
      "https://github.com/UCSB-NLP-Chang/Visual-Spatial-Planning"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate and diagnose the spatial planning capabilities of vision language models.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Spatial Planning",
      "Single Object Perception",
      "Spatial Relation Perception",
      "Environment Perception",
      "Spatial Reasoning"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "The images and tasks are based on simulations of maze navigation and block-moving tasks developed with tools such as OpenAI Gym and sampled images from the BIRD dataset.",
    "size": "4,400 questions",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Metrics calculated based on correct and incorrect responses to the questions posed in the VSP tasks.",
    "interpretation": "A high accuracy indicates better spatial understanding and planning capabilities of the model.",
    "baseline_results": "Previous state-of-the-art models were evaluated against the VSP benchmark and demonstrated considerable deficiencies.",
    "validation": "The benchmark was validated by testing with multiple models, highlighting their performance across various tasks."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": []
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "MIT License",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}