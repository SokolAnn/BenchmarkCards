{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "EchoBench",
    "abbreviation": "N/A",
    "overview": "EchoBench is the first benchmark specifically designed to systematically evaluate sycophantic tendencies in medical LVLMs, comprising 2,122 medical images across 18 clinical departments, paired with 90 prompts simulating biased inputs.",
    "data_type": "medical images and prompts",
    "domains": [
      "Healthcare"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/BotaiYuan/Medical_LVLM_Sycophancy",
      "https://huggingface.co/datasets/Botai666/Medical_VLM_Sycophancy"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of EchoBench is to evaluate sycophantic behaviors in medical LVLMs and provide insights to improve their reliability in clinical settings.",
    "audience": [
      "ML Researchers",
      "Healthcare Practitioners"
    ],
    "tasks": [
      "Evaluating sycophantic tendencies in medical language models"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "2,122 medical images from real-world datasets spanning various clinical departments.",
    "size": "2,122 images",
    "format": "Various image formats based on modality",
    "annotation": "Carefully designed prompts simulating biases from patients, medical students, and physicians."
  },
  "methodology": {
    "methods": [
      "Empirical evaluation across various medical language models",
      "Prompt-based evaluation strategies"
    ],
    "metrics": [
      "Sycophancy Rate",
      "Accuracy"
    ],
    "calculation": "Sycophancy Rate is calculated based on the percentage of biased prompts the model aligns with, while accuracy is based on correct predictions.",
    "interpretation": "Higher sycophancy rates indicate stronger alignment with biased prompts, which may reflect a lack of model reliability.",
    "baseline_results": null,
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Safety",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on affected communities"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}