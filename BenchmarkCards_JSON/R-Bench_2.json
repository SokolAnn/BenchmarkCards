{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "R-Bench (Reasoning Bench)",
    "abbreviation": "R-Bench",
    "overview": "R-Bench is a graduate-level, multi-disciplinary, multilingual benchmark designed to evaluate complex reasoning capabilities for both language and multimodal models, spanning 1,094 questions across 108 subjects for language model evaluation and 665 questions across 83 subjects for multimodal model testing.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English",
      "Chinese"
    ],
    "similar_benchmarks": [
      "MMLU",
      "MMMU"
    ],
    "resources": [
      "https://github.com/user/repo"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To build a reliable complex reasoning benchmark for both large language models (LLMs) and multimodal large language models (MLLMs).",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Complex Reasoning Evaluation"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Questions curated from graduate college courses across 19 departments at Tsinghua University.",
    "size": "10,270 questions",
    "format": "Excel sheets",
    "annotation": "Expert-reviewed and digitized with automated verification."
  },
  "methodology": {
    "methods": [
      "Expert evaluation",
      "Model-based evaluation"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is measured based on the performance of models on the R-Bench questions.",
    "interpretation": "A higher score indicates better reasoning capability of models. R-Bench challenges current models more effectively compared to existing benchmarks.",
    "baseline_results": "OpenAI o1 achieved 69.0% accuracy on R-Bench-T and 53.2% on R-Bench-M.",
    "validation": "R-Bench was validated through expert scoring and model scoring comparisons."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": []
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}