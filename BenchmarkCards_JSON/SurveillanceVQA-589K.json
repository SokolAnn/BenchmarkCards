{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "SurveillanceVQA-589K",
    "abbreviation": "N/A",
    "overview": "SurveillanceVQA-589K is the largest open-ended video question answering (VQA) benchmark tailored to the surveillance domain, comprising 589,380 QA pairs across 12 cognitively diverse question types, enabling comprehensive semantic understanding of both normal and abnormal video content.",
    "data_type": "question-answering pairs",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://huggingface.co/datasets/fei213/SurveillanceVQA-589K"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To advance video-language understanding in safety-critical applications such as intelligent monitoring, incident analysis, and autonomous decision-making.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Four surveillance video datasets used for annotation: MSAD, MEVA, NWPU, and UCA.",
    "size": "589,380 QA pairs",
    "format": "JSON",
    "annotation": "Hybrid annotation combining human-written captions with Large Vision-Language Model (LVLM) assisted QA generation."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "Detail Orientation",
      "Contextual Understanding",
      "Temporal Understanding"
    ],
    "calculation": "Average Score (Avg) calculated by normalizing individual scores across multiple dimensions.",
    "interpretation": "Scores are on a 0-5 scale, with 5 indicating full accuracy and relevance.",
    "baseline_results": "N/A",
    "validation": "Evaluation was carried out on the test set of the SurveillanceVQA-589K dataset."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}