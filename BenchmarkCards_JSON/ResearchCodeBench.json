{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ResearchCodeBench",
    "abbreviation": "N/A",
    "overview": "ResearchCodeBench is a benchmark of 212 coding challenges that evaluates LLMsâ€™ ability to translate cutting-edge ML contributions from top 2024-2025 research papers into executable code.",
    "data_type": "coding challenges",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "HumanEval",
      "MBPP",
      "LiveCodeBench",
      "BigCodeBench",
      "SUPER",
      "CORE-Bench",
      "SciCode",
      "MLE-Bench",
      "MLAgentBench",
      "MLGym",
      "PaperBench"
    ],
    "resources": [
      "https://researchcodebench.github.io/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate whether large language models (LLMs) can translate novel machine learning contributions from recent research papers into correct, executable code.",
    "audience": [
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Code Generation",
      "Evaluation of LLMs on implementing novel ML research"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "20 recently released ML papers from top venues (e.g., NeurIPS, ICLR, CVPR) and arXiv.",
    "size": "212 coding challenges",
    "format": "N/A",
    "annotation": "Manually annotated code snippets marked with XML-style tags to indicate regions of interest."
  },
  "methodology": {
    "methods": [
      "Equivalence Tests",
      "Unit Tests"
    ],
    "metrics": [
      "Pass Rate",
      "Scaled Pass Rate"
    ],
    "calculation": "Scaled Pass Rate is defined as the percentage of code snippets for which the model generates outputs that pass all correctness tests, weighted by the number of executable lines of code.",
    "interpretation": "Higher pass rates indicate better performance in generating correct code.",
    "baseline_results": "Gemini-2.5-Pro-Preview achieved the highest average performance with a 37.3% success rate.",
    "validation": "Generated code is evaluated against provided correctness tests from the original paper authors or domain experts."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Robustness",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Prompt leaking"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}