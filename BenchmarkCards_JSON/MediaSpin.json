{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MediaSpin",
    "abbreviation": "N/A",
    "overview": "The MediaSpin dataset characterizes the bias in how prominent news outlets editorialize news headlines after publication. It includes 78,910 pairs of headlines annotated with 13 distinct types of media bias, using human-supervised LLM labeling.",
    "data_type": "headline pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://anonymous.4open.science/r/mediaspin-A5C7"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To systematically identify and analyze types of media bias in editorialized news headlines.",
    "audience": [
      "ML Researchers",
      "Media Analysts",
      "Content Moderation Practitioners"
    ],
    "tasks": [
      "Bias Detection",
      "Text Classification"
    ],
    "limitations": "The dataset contains subjective and editorialized references to gender, ethnicity, and religion, with potential for misuse.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated from revisions of news headlines from five major English language media outlets.",
    "size": "78,910 pairs",
    "format": "CSV",
    "annotation": "Annotated using an LLM pipeline, specifically GPT-3.5-turbo."
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Human evaluation"
    ],
    "metrics": [
      "Accuracy",
      "F1 Score"
    ],
    "calculation": "Metrics were calculated based on model performance in classifying annotated biases.",
    "interpretation": "Higher accuracy indicates better model performance in correctly identifying types of bias.",
    "baseline_results": "DeBERTa-v3-small achieved 0.773 accuracy for subjective bias.",
    "validation": "Human validation with an inter-annotator agreement of 84.9%."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        }
      ]
    },
    "demographic_analysis": "Participants included a variety of demographics focusing on political affiliation and education.",
    "harm": [
      "Potential misuse in content moderation applications."
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}