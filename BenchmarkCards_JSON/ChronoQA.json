{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ChronoQA",
    "abbreviation": "N/A",
    "overview": "ChronoQA is a benchmark dataset for Chinese question answering focused on evaluating temporal reasoning in Retrieval-Augmented Generation (RAG) systems. It contains 5,176 questions derived from over 300,000 news articles published between 2019 and 2024, covering absolute, aggregate, and relative temporal types with both explicit and implicit time expressions.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Chinese"
    ],
    "similar_benchmarks": [
      "Natural Questions",
      "TriviaQA",
      "CRAG",
      "DomainRAG"
    ],
    "resources": [
      "https://github.com/czy1999/ChronoQA"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To evaluate temporal-sensitive RAG systems and enhance performance in handling time-sensitive questions.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Constructed from over 300,000 news articles published between 2019 and 2024.",
    "size": "5,176 questions",
    "format": "JSON, CSV",
    "annotation": "Generated via a robust multi-stage pipeline that includes LLM-based extraction, structured question synthesis, and rigorous validation."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "Mean Average Precision (MAP)"
    ],
    "calculation": "Metrics are calculated based on the performance of models on the dataset.",
    "interpretation": "Higher scores indicate better performance in retrieving temporally relevant information.",
    "baseline_results": "N/A",
    "validation": "Multi-stage validation process combining rule-based checks, LLM evaluations, and manual verification."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "CC BY 4.0",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}