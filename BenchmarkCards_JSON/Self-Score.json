{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Self-Score",
    "abbreviation": "N/A",
    "overview": "SelfScore is a novel benchmark designed to assess the performance of automated Large Language Model (LLM) agents on help desk and professional consultation tasks. It enables the comparison of automated agents and human workers by evaluating agents on problem complexity and response helpfulness.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Science"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2410.16285"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To quantitatively compare the performance of automated LLM agents to human agents in help desk and consultation tasks.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Customer Support",
      "Help Desk Assistance"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Stack Exchange forum posts",
    "size": "2,360 entries",
    "format": "JSON",
    "annotation": "Automatically generated"
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Human evaluation"
    ],
    "metrics": [
      "Accuracy",
      "Helpfulness",
      "Complexity"
    ],
    "calculation": "Scores are derived from a 10-point scale based on user and agent helpfulness assessments.",
    "interpretation": "Higher scores indicate better performance in responding to customer inquiries, and reflect the quality of both the agent's responses and the user's input.",
    "baseline_results": "Human control group had a final score of 23.12.",
    "validation": "The benchmark was validated by comparing automated LLM agent performances against human interactions."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}