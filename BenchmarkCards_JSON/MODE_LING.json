{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MODE LING",
    "abbreviation": "N/A",
    "overview": "MODE LING is a novel benchmark of Linguistics Olympiad-style puzzles which tests few-shot reasoning in AI systems, requiring compositional generalization and inductive reasoning based on a small number of examples.",
    "data_type": "linguistic puzzles",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Ayutla Mixe",
      "Bangime",
      "Chimalapa Zoque",
      "Dogon",
      "Engenni",
      "Guugu Yimithirr",
      "Kalam",
      "Komi-Zyrian",
      "Kutenai",
      "Mapudungan",
      "Misantla Totonac",
      "Mixtepec Zapotec",
      "Ngadha",
      "Niuean",
      "Rapa Nui",
      "Seri",
      "Totonac"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/nathanchi/modeLing"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of the benchmark is to evaluate LLMsâ€™ capacity to reason analytically in unseen foreign languages.",
    "audience": [
      "ML Researchers",
      "Language Model Evaluators",
      "Linguists"
    ],
    "tasks": [
      "Linguistic Reasoning"
    ],
    "limitations": "The authors of the paper are not native speakers of the languages included, and there cannot be guaranteed accuracy of the sentences used.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated and curated by the authors specifically for this benchmark.",
    "size": "48 puzzles, 272 questions",
    "format": "N/A",
    "annotation": "Problems were test-solved and rated for difficulty by two International Linguistics Olympiad medalists."
  },
  "methodology": {
    "methods": [
      "Exact Match Evaluation"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is computed based on exact matches for puzzle solutions.",
    "interpretation": "Good performance is indicated by higher exact match accuracy.",
    "baseline_results": null,
    "validation": "Validated through evaluation against existing knowledge of the languages without training data leakage."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Data Contamination"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Data contamination"
          ]
        }
      ]
    },
    "demographic_analysis": "The choice of extremely low-resource languages aims to improve diversity in NLP evaluations, but bias in the selection process may exist.",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}