{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation",
    "abbreviation": "WikiHint",
    "overview": "WikiHint is the first manually curated dataset for the Automatic Hint Generation task, containing 5,000 hints for 1,000 questions, designed to assist users in finding correct answers through hints instead of direct responses.",
    "data_type": "hint-question pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "SQuAD",
      "Natural Questions"
    ],
    "resources": [
      "https://github.com/DataScienceUIBK/WikiHint"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To support users in developing reasoning skills by providing hints for question answering instead of direct answers.",
    "audience": [
      "ML Researchers",
      "Educators",
      "Information Retrieval Researchers"
    ],
    "tasks": [
      "Hint Generation",
      "Hint Ranking"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Wikipedia articles, human annotations via Amazon MTurk",
    "size": "5,000 hints and 1,000 questions",
    "format": "CSV",
    "annotation": "Manual annotation by crowdworkers"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Relevance",
      "Readability",
      "Convergence",
      "Familiarity",
      "Answer Leakage"
    ],
    "calculation": "Metrics are calculated based on automated assessments and human judgments.",
    "interpretation": "Higher values in Relevance and Convergence indicate better hint quality.",
    "baseline_results": "N/A",
    "validation": "Hints were verified by multiple judges for quality and correctness."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "This work is licensed under a Creative Commons Attribution 4.0 International License.",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}