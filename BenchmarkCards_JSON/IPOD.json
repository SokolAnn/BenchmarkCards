{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Industrial and Professional Occupations Dataset (IPOD)",
    "abbreviation": "IPOD",
    "overview": "This work presents the Industrial and Professional Occupations Dataset (IPOD), a publicly available corpus of occupation entries crawled from LinkedIn (192,295 job titles from 56,648 profiles). The paper demonstrates IPOD's usefulness by (i) proposing Title2vec, a contextual job-title vector representation using a bidirectional Language Model (biLM) approach, and (ii) addressing occupational Named Entity Recognition (NER) using Conditional Random Fields (CRF) and bidirectional LSTM-CRF models.",
    "data_type": "text (job title entries)",
    "domains": [
      "Natural Language Processing",
      "Occupational Data Mining"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "CoNLL-2003",
      "Ontonotes",
      "CHEMDNER",
      "SQuAD",
      "APS (American Physical Society dataset)"
    ],
    "resources": [
      "https://www.github.com/junhua/ipod",
      "https://arxiv.org/abs/1910.10495"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Provide a large, publicly available dataset of job title entries to support occupational data mining and analysis, and to enable upstream tasks such as job title embedding (Title2vec) and occupational Named Entity Recognition (NER).",
    "audience": [
      "Industry Practitioners",
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Named Entity Recognition",
      "Embedding (Job Title Embedding / Representation Learning)"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Crawled from LinkedIn profiles (Asia and the United States); 56,648 unique profiles.",
    "size": "192,295 occupation entries",
    "format": "Formatted for NER tasks with BIOES tagging scheme",
    "annotation": "Knowledge-based gazetteer created by three annotators (HR personnel, senior recruiter, seasoned business professional). Top 1,500 tokens were tagged; inter-rater reliability: 0.853 Percentage Agreement and 0.778 Cohen's Kappa. Labels use BIOES positional prefixes."
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Human evaluation"
    ],
    "metrics": [
      "Exact Match (EM)",
      "F1 Score",
      "Precision",
      "Recall"
    ],
    "calculation": "F1 is computed as F1 = 2 * Precision * Recall / (Precision + Recall). Exact Match (EM) measures the percentage agreement between the ground truth and predicted labels with exact matches.",
    "interpretation": "Higher EM and F1 indicate better NER performance. Human baseline reported as EM = 91.3% and F1 = 95.4%; models exceeding these are considered to outperform human baseline (paper reports CRF and LSTM-CRF outperform human and baselines in EM and F1).",
    "baseline_results": "Reported overall results (Precision, Recall, EM, F1): LogReg: P 90.80 R 93.20 EM 85.10 F1 92.00; LSTM: P 99.71 R 99.90 EM 99.61 F1 99.80; CRF: P 99.90 R 99.81 EM 99.71 F1 99.85; LSTM-CRF: P 99.86 R 99.97 EM 99.83 F1 99.91; Human: P 91.60 R 99.60 EM 91.30 F1 95.40.",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [],
    "atlas_risks": {
      "risks": null
    },
    "demographic_analysis": "The corpus comprises entries from United States (56.7%) and Asia (43.3%). Most titles fall within five words (91.7%). Median title length: overall 3 words; US median 3 words; Asia median 2 words â€” paper notes Asian titles tend to be shorter than US titles.",
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}