{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "An Interpretable Benchmark for Clickbait Detection and Tactic Attribution",
    "abbreviation": "N/A",
    "overview": "This paper presents a synthetic dataset for explainable clickbait detection, generated by systematically augmenting real news headlines using predefined clickbait strategies. It allows for controlled experimentation and detailed analysis of model behavior, focusing on both clickbait detection and tactic attribution.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/LLM-HITCS25S/ClickbaitTacticsDetection"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To advance the detection and explanation of clickbait content through a rigorous framework that identifies both clickbait and the specific strategies employed.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Clickbait Detection",
      "Tactic Attribution"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic dataset generated from real news headlines using clickbait tactics",
    "size": "N/A",
    "format": "N/A",
    "annotation": "Each generated clickbait headline is annotated with the exact set of tactics used during its creation."
  },
  "methodology": {
    "methods": [
      "Fine-tuned BERT classifier",
      "Large language models (GPT-4.0, Gemini 2.5 Flash)",
      "Zero-shot prompting",
      "Few-shot prompting"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "F1 Score"
    ],
    "calculation": "Precision, recall, and F1-score were used to evaluate detection and tactic attribution performance.",
    "interpretation": "Higher scores indicate better performance in detecting clickbait and attributing tactics.",
    "baseline_results": "Fine-tuned BERT achieved a precision of 0.89, recall of 0.93, and F1-score of 0.91.",
    "validation": "Evaluated multiple models and prompting strategies to compare performance."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Transparency"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}