{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "AIReg-Bench",
    "abbreviation": "N/A",
    "overview": "AIReg-Bench is the first benchmark dataset designed to test how well Large Language Models (LLMs) can assess compliance with the EU AI Act (AIA), consisting of 120 technical documentation excerpts annotated by legal experts.",
    "data_type": "text",
    "domains": [
      "Legal"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "LegalAgentBench"
    ],
    "resources": [
      "https://github.com/camlsys/aireg-bench"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a standardized method for quantitatively evaluating LLMs in assessing compliance with the EU AI Act.",
    "audience": [
      "ML Researchers",
      "Legal Compliance Experts",
      "AI Practitioners"
    ],
    "tasks": [
      "Compliance Assessment"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Generated by an LLM and reviewed by legal experts.",
    "size": "120 excerpts",
    "format": "text",
    "annotation": "Annotated by legal experts to indicate compliance with specific articles of the AIA."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Cohen's Kappa",
      "Spearman's Rank Correlation"
    ],
    "calculation": "Metrics are calculated based on the agreement between LLM outputs and human expert annotations.",
    "interpretation": "Higher values indicate better alignment between LLM assessments and human expert judgments.",
    "baseline_results": "Gemini 2.5 Pro achieved the highest Kappa score of 0.863.",
    "validation": "Validated through evaluation of 10 frontier LLMs using the dataset."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}