{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "Exploratory Data Analysis on Code-mixed Misogynistic Comments",
    "abbreviation": "N/A",
    "overview": "This paper presents a novel dataset of YouTube comments in mix-code Hinglish that are weakly labelled as ‘Misogynistic’ and ‘Non-misogynistic’. It provides exploratory data analysis techniques to understand the dataset's characteristics.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English",
      "Hindi"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://isdsi2023.iimranchi.ac.in"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a new dataset of YouTube comments for misogyny detection in Hinglish, and to perform exploratory data analysis on the dataset.",
    "audience": [
      "Researchers in Natural Language Processing",
      "Data Scientists",
      "Machine Learning Practitioners"
    ],
    "tasks": [
      "Misogyny Detection",
      "Exploratory Data Analysis"
    ],
    "limitations": "The dataset is sparsely annotated since it currently has only one annotator.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "YouTube comments from videos discussing current social issues in India",
    "size": "2,229 comments",
    "format": "N/A",
    "annotation": "Weakly annotated by a single annotator into categories: Misogynistic (‘MGY’) and Not-misogynistic (NOT)"
  },
  "methodology": {
    "methods": [
      "Exploratory Data Analysis",
      "Sentiment Analysis",
      "Principal Component Analysis"
    ],
    "metrics": [
      "Sentiment polarity scores"
    ],
    "calculation": "Sentiment scores were calculated using TextBlob and other descriptive statistics were derived from the comments.",
    "interpretation": "Misogynistic comments are generally longer than non-misogynistic comments; most comments show slightly positive sentiment score.",
    "baseline_results": null,
    "validation": "Feedback from experts on the study's workflow was solicited."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Safety",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": "The dataset aims to improve misogyny detection in code-mixed languages, aiming to reduce harmful online discourse."
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "Data was gathered with established ethical approval.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}