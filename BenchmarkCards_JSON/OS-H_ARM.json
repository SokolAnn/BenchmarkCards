{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "OS-H ARM",
    "abbreviation": "N/A",
    "overview": "OS-H ARM is a benchmark for measuring the safety of computer use agents, focusing on assessing the risks posed by deliberate user misuse, prompt injection attacks, and model misbehavior across various operating system applications.",
    "data_type": "task-based interactions",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/tml-epfl/os-harm"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To comprehensively measure the safety risks associated with computer use agents and ensure their alignment with acceptable usage policies.",
    "audience": [
      "ML Researchers",
      "Safety Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Deliberate User Misuse",
      "Prompt Injection",
      "Model Misbehavior"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "OSWorld environment",
    "size": "150 tasks",
    "format": "N/A",
    "annotation": "N/A"
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "LLM-based evaluation"
    ],
    "metrics": [
      "F1 Score",
      "Task Completion Rate"
    ],
    "calculation": "F1 score computed on the evaluation outputs comparing automated scoring and human annotations.",
    "interpretation": "A higher F1 score indicates better agreement between model evaluations and safety expectations.",
    "baseline_results": "The average unsafe execution rates across models are reported, with varying performance on task completion.",
    "validation": "Evaluated against a variety of frontier agent models."
  },
  "targeted_risks": {
    "risk_categories": [
      "Safety",
      "Security"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}