{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MultiProSE (Multi-label Arabic Dataset for Propaganda, Sentiment, and Emotion Detection)",
    "abbreviation": "MultiProSE",
    "overview": "The MultiProSE dataset is released as the first multi-label Arabic dataset for propaganda detection, sentiment analysis, and emotion recognition. The dataset is an extension of the ArPro dataset, annotated with sentiment and emotion dimensions, to facilitate research on the interaction between these opinion dimensions.",
    "data_type": "text",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Arabic"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/xxx/xxx"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a comprehensive dataset for the classification of propaganda, sentiment, and emotion in Arabic news texts.",
    "audience": [
      "ML Researchers",
      "Domain Experts"
    ],
    "tasks": [
      "Propaganda Detection",
      "Sentiment Analysis",
      "Emotion Recognition"
    ],
    "limitations": "During the annotation process, the annotators faced several challenges such as time constraints, the need for clear annotation guidelines, and the complexity of emotions and sentiments in diverse topics.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "The dataset was collected from several Arabic news domains, derived from the existing ArPro dataset along with an in-house collection.",
    "size": "8,000 examples",
    "format": "N/A",
    "annotation": "Manually annotated by three native Arabic speakers with strict guidelines and quality control measures to ensure accuracy."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Micro-F1",
      "Macro-F1",
      "Accuracy"
    ],
    "calculation": "Metrics are calculated using results from several pre-trained and large language models for the respective tasks.",
    "interpretation": "Higher Micro-F1 and Macro-F1 scores indicate better model performance in each task.",
    "baseline_results": "AraBERT achieved a Micro-F1 score of 0.769 for propaganda detection, while GPT-4o-Mini achieved the highest score for sentiment analysis at 0.842.",
    "validation": "Inter-Annotator Agreement (IAA) was assessed using Light's Kappa and Fleissâ€™ Kappa measures."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": []
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}