{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ASE Dataset (Automated Optical Inspection for Defect Classification)",
    "abbreviation": "ASE",
    "overview": "The ASE dataset is proposed for defect classification and addresses challenges such as data insufficiency and monotonous patterns in images, which are not effectively handled by traditional models. By leveraging vision-language models (VLM) and large-language models (LLM) through a prompting strategy, the dataset aims to capture external-modal features to enhance classification performance.",
    "data_type": "image-text pairs",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/breezedeus/cnocr"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a dataset for enhancing defect classification in industrial manufacturing through the use of multimodal learning techniques.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners"
    ],
    "tasks": [
      "Defect Classification"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Provided by ASE corporation, consisting of image and corresponding statistical data about defects.",
    "size": "455 samples",
    "format": "N/A",
    "annotation": "Numeric and textual information recorded corresponding to visual data."
  },
  "methodology": {
    "methods": [
      "Prompting with VLM-LLM",
      "Progressive Feature Alignment (PFA)",
      "Cross-modality attention fusion (CMAF)"
    ],
    "metrics": [
      "F1 Score",
      "Macro F1 Score"
    ],
    "calculation": "F1 Score is calculated as 2 * (precision * recall) / (precision + recall), with macro F1 Score being the average across classes.",
    "interpretation": "Higher F1 and Macro F1 Scores indicate better classification performance across the dataset.",
    "baseline_results": null,
    "validation": "Model performance is validated through experiments comparing results across multiple defect classification methods."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias",
            "Output bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": null,
    "harm": null
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}