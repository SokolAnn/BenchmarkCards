{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "CMB (Comprehensive Medical Benchmark in Chinese)",
    "abbreviation": "CMB",
    "overview": "CMB is a localized medical benchmark designed to measure the effectiveness of large language models (LLMs) within the context of Chinese medical knowledge, integrating both traditional Chinese medicine and modern medical practices. It includes multiple-choice questions and complex clinical diagnostic questions.",
    "data_type": "multiple-choice questions and clinical diagnostic questions",
    "domains": [
      "Healthcare"
    ],
    "languages": [
      "Chinese"
    ],
    "similar_benchmarks": [
      "MultiMedBench",
      "BioLAMA"
    ],
    "resources": [
      "https://github.com/FreedomIntelligence/CMB"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To establish a standardized benchmark for evaluating LLMs in medical contexts, specifically tailored to the Chinese healthcare environment.",
    "audience": [
      "ML Researchers",
      "Medical Professionals",
      "Model Developers"
    ],
    "tasks": [
      "Question Answering",
      "Medical Diagnosis"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Publicly available examination questions and clinical diagnostic materials vetted by medical experts.",
    "size": "280,839 questions",
    "format": "N/A",
    "annotation": "Expert-reviewed and curated medical questions and clinical cases."
  },
  "methodology": {
    "methods": [
      "Automated metrics",
      "Expert evaluation"
    ],
    "metrics": [
      "Accuracy",
      "Fluency",
      "Completeness",
      "Relevance",
      "Proficiency"
    ],
    "calculation": "Metrics calculated based on answer matching against expert-curated solutions.",
    "interpretation": "Higher scores indicate better performance in medical reasoning and knowledge application.",
    "baseline_results": "N/A",
    "validation": "Performance of models evaluated against expert benchmarks."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness",
      "Privacy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Potential propagation of inaccuracies in medical information"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "All data processed to ensure no personal information is included.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}