{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ACCESS (Abstra CtCausal Event Di Scovery and ReaSoning)",
    "abbreviation": "ACCESS",
    "overview": "ACCESS is designed for discovery and reasoning over abstract causal events, focusing on causality of everyday life events at an abstraction level. The benchmark includes 725 event abstractions and 1,494 causal relations.",
    "data_type": "causal pairs",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "CRAB",
      "GLUCOSE"
    ],
    "resources": [
      "https://github.com/isVy08/ACCESS"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To explore event causality at the abstraction level as a more efficient representation of knowledge.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Causal Discovery",
      "Event Abstraction"
    ],
    "limitations": "ACCESS is built upon GLUCOSE with a scope limited to everyday children's stories, which may introduce biases.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "GLUCOSE (Mostafazadeh et al., 2020)",
    "size": "1,494 causal pairs",
    "format": "N/A",
    "annotation": "Manual annotation by experts"
  },
  "methodology": {
    "methods": [
      "Statistical structure learning algorithms",
      "Human annotation",
      "Clustering algorithms"
    ],
    "metrics": [
      "Precision",
      "Recall",
      "F1 Score",
      "Accuracy"
    ],
    "calculation": "Metrics are calculated based on the performance of models against the causal pairs and event abstractions extracted.",
    "interpretation": "Higher scores indicate better performance in identifying causal relations and reasoning.",
    "baseline_results": "N/A",
    "validation": "Validated through expert annotation and comparison with existing benchmarks."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data",
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "All necessary measures have been taken to ensure privacy and informed consent during data collection.",
    "data_licensing": "N/A",
    "consent_procedures": "Each annotator was required to adhere to ethical standards and take breaks as needed during the annotation process.",
    "compliance_with_regulations": "N/A"
  }
}