{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "testbed of six publicly available data sources (YFCC, LAION, Conceptual Captions, WIT, RedCaps, Shutterstock)",
    "abbreviation": "N/A",
    "overview": "We introduce a testbed of six publicly available data sources—YFCC, LAION, Conceptual Captions, WIT, RedCaps, Shutterstock—to investigate how pre-training distributions induce robustness in CLIP. We measure zero-shot accuracy on ImageNet and several ImageNet-derived distribution shifts and study how individual sources, dataset combinations (input mixing), output ensembling, and filtering affect robustness.",
    "data_type": "image-text pairs",
    "domains": [
      "Computer Vision",
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "ImageNet",
      "ImageNet-V2",
      "ImageNet-R",
      "ImageNet-Sketch",
      "ObjectNet",
      "WILDS"
    ],
    "resources": [
      "https://github.com/mlfoundations/clip_quality_not_quantity",
      "https://commoncrawl.org/",
      "https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/",
      "https://doi.org/10.5281/zenodo.5143773"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Investigate the impact of pre-training dataset composition on the robustness of CLIP models to natural distribution shifts, and study interactions of data sources, mixing strategies, and filtering.",
    "audience": [
      "ML Researchers",
      "Model Developers",
      "Dataset Designers",
      "Practitioners interested in dataset design and robust pre-training"
    ],
    "tasks": [
      "Zero-shot Image Classification",
      "Robustness Evaluation / Out-of-distribution Evaluation (distribution shift)"
    ],
    "limitations": "The pre-training datasets used in the testbed range from 5M to 15M samples, which is smaller than current state-of-the-art web-scale datasets; full-scale experiments were not performed due to resource constraints (see Section 7.1).",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Six publicly available image-text datasets collected from web sources: YFCC (Flickr), LAION (Common Crawl), Conceptual Captions (web HTML alt-text), RedCaps (curated Reddit subreddits), Shutterstock (Shutterstock website), WIT (Wikipedia reference descriptions).",
    "size": "YFCC: 14,826,000 examples; LAION: 15,504,742 examples; CC-12M (Conceptual Captions): 9,594,338 examples; RedCaps: 11,882,403 examples; WIT: 5,038,295 examples; ShutterStock: 15,540,452 examples.",
    "format": "N/A",
    "annotation": "Image-text pairs as provided by original sources (e.g., Flickr captions, HTML alt-text, Wikipedia reference descriptions, Shutterstock captions); no additional manual annotation procedure for labels reported."
  },
  "methodology": {
    "methods": [
      "Zero-shot evaluation",
      "Automated metrics (top-1 accuracy)",
      "Effective Robustness analysis (probit-transformed accuracy and linear trend)",
      "Input mixing (randomly combining samples from multiple sources)",
      "Output mixing / Ensembling (ensembling logits of separately trained models)",
      "Theoretical analysis (simple binary classification model to explain empirical phenomena)"
    ],
    "metrics": [
      "Top-1 Accuracy",
      "Zero-shot Accuracy",
      "Effective Robustness (probit-transformed accuracy; linear trend between accuracies on two test sets)"
    ],
    "calculation": "Robustness is measured by comparing zero-shot Top-1 Accuracy on a reference test set (ImageNet) and several related distribution-shifted test sets (ImageNet-V2, ImageNet-R, ImageNet-Sketch, ObjectNet). Effective Robustness is analyzed via probit-transforming accuracies and examining linear trends/slopes between paired test distributions.",
    "interpretation": "Models closer to the y=x line (or with a slope closer to 1 in the probit-transformed accuracy plot) are considered more robust to distribution shift. Mixtures interpolate between individual-source trends; ensembling outputs of single-source models predicts the trend of input-mixed training.",
    "baseline_results": "Qualitative baseline comparisons reported: no single pre-training source dominates across shifts; Shutterstock shows best out-of-distribution performance on ImageNet-Sketch, RedCaps shows strongest effective robustness on ObjectNet, and LAION/CC-12M/Shutterstock perform relatively well on ImageNet-R. No single numeric universal baseline reported for all settings.",
    "validation": "Experiments were repeated with multiple sample sizes per source (1M to 15M) and averaged over 3 random seeds for data-efficiency plots (Figure 17). Evaluation uses multiple standard distribution-shift test sets (ImageNet-V2, ImageNet-R, ImageNet-Sketch, ObjectNet). Theoretical results (Theorems 1-3) complement empirical findings."
  },
  "targeted_risks": {
    "risk_categories": [
      "Robustness",
      "Transparency",
      "Value Alignment",
      "Governance",
      "Societal Impact"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Transparency",
          "subcategory": [
            "Lack of training data transparency",
            "Uncertain data provenance"
          ]
        },
        {
          "category": "Governance",
          "subcategory": [
            "Lack of data transparency",
            "Incomplete usage definition"
          ]
        },
        {
          "category": "Value Alignment",
          "subcategory": [
            "Harmful output"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on affected communities"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Potential presence of harmful content (paper cites concerns such as misogyny, pornography, and malignant stereotypes as discussed in Birhane et al.)"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "The paper notes dataset curation steps such as ensuring LAION-chosen samples have NSFW tags marked 'UNLIKELY' and discusses broadly the potential presence of harmful content in web-crawled multimodal datasets. No systematic anonymization procedures are described.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}