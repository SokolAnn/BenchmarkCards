{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "TRACSUM: A New Benchmark for Aspect-Based Summarization with Sentence-Level Traceability in Medical Domain",
    "abbreviation": "TRACSUM",
    "overview": "TRACSUM is a benchmark for generating traceable, aspect-based summaries of medical abstracts, paired with sentence-level citations to support factual accuracy. It includes a dataset of annotated medical abstracts across seven aspects, resulting in 3.5K summary-citation pairs, and establishes a fine-grained evaluation framework for assessing completeness and consistency in generated content.",
    "data_type": "summary-citation pairs",
    "domains": [
      "Natural Language Processing",
      "Healthcare"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": null,
    "resources": [
      "https://github.com/chubohao/TracSum"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a benchmark for evaluating traceable aspect-based summarization in the medical domain.",
    "audience": [
      "ML Researchers",
      "Medical Professionals",
      "NLP Practitioners"
    ],
    "tasks": [
      "Aspect-Based Summarization"
    ],
    "limitations": "The dataset was generated using the Mistral Large model, which may introduce model-specific biases.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Annotated medical abstracts from PubMed focusing on melanoma, filtered for key criteria and annotated for seven medical aspects.",
    "size": "3,500 summary-citation pairs",
    "format": "JSON",
    "annotation": "Annotated by a team of medical students and NLP researchers, incorporating qualitative evaluation metrics."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Completeness",
      "Conciseness",
      "Traceability"
    ],
    "calculation": "Metrics are calculated based on the recall and precision of generated summaries and their corresponding citations using predefined evaluation frameworks.",
    "interpretation": "Higher values for completeness and conciseness indicate better performance of the summarization model.",
    "baseline_results": "TRACK-THEN-SUM (TTS) serves as the baseline method against which other systems are compared.",
    "validation": "The performance is evaluated through a combination of qualitative human assessments and quantitative metrics based on the dataset."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Accuracy",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": []
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "Participants gave explicit consent for data usage for research purposes during the annotation process.",
    "compliance_with_regulations": "N/A"
  }
}