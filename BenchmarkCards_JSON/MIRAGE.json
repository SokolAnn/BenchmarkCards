{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "MIRAGE (MetaInductive ReAsonin G Evaluation)",
    "abbreviation": "MIRAGE",
    "overview": "MIRAGE is a synthetic dataset aimed at evaluating and explaining the inductive reasoning process in large language models (LLMs). It provides both inductive and deductive evaluation tasks, tailored for flexible test data with various forms, distributions, and difficulty levels.",
    "data_type": "inductive and deductive evaluation tasks",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "ARC",
      "MiniSCAN",
      "ListFunctions",
      "MiniARC",
      "1D-ARC",
      "Case2Code"
    ],
    "resources": [
      "https://github.com/BugMakerzzz/mirage"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To comprehensively evaluate and analyze the inductive reasoning capabilities of large language models (LLMs) through flexible and varied testing scenarios.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Rule Induction",
      "Example Inference"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Synthetic data generated based on various vector operations and rules.",
    "size": "N/A",
    "format": "N/A",
    "annotation": "Automatically generated"
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy",
      "F1 Score"
    ],
    "calculation": "Metrics are calculated based on model performance in the inductive and deductive tasks using synthetic data.",
    "interpretation": "A high accuracy rate indicates effective inductive reasoning capabilities, while discrepancies between rule induction and example inference suggest reliance on neighbor-based reasoning.",
    "baseline_results": "N/A",
    "validation": "N/A"
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}