{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "FakeCTI",
    "abbreviation": "N/A",
    "overview": "FakeCTI is the first dataset that systematically links fake news articles to known disinformation campaigns and threat actors, consisting of 12,155 articles from 43 distinct campaigns, each annotated with metadata specifying the associated campaign, threat actor, and dissemination medium.",
    "data_type": "text",
    "domains": [
      "Cybersecurity",
      "Natural Language Processing"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://github.com/user/repo"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide a structured foundation for attribution studies in disinformation analysis.",
    "audience": [
      "Research Community",
      "Cybersecurity Analysts"
    ],
    "tasks": [
      "Fake News Attribution",
      "Disinformation Campaign Analysis"
    ],
    "limitations": "Dataset reflects only the accessible portion of the content of the campaigns due to the removal of false content after reporting.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Data collected from archives of fake news reports linked by Wikipedia.",
    "size": "12,155 articles",
    "format": "CSV",
    "annotation": "Manually labeled based on association with specific disinformation campaigns and threat actors."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Measured accuracy of various attribution techniques including lexical and semantic similarity methods.",
    "interpretation": "Accuracy in fake news attribution techniques evaluated up to 94%, highlighting the effectiveness of the methodologies employed.",
    "baseline_results": "Achieved attribution accuracy up to 94% using fine-tuned LLMs.",
    "validation": "Experimental analysis of attribution techniques assessed using the FakeCTI dataset."
  },
  "targeted_risks": {
    "risk_categories": [
      "Accuracy",
      "Fairness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Accuracy",
          "subcategory": [
            "Unrepresentative data"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}