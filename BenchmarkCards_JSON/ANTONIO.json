{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ANTONIO (Abstract domaiN Tool fOr Nlp verIficatiOn)",
    "abbreviation": "ANTONIO",
    "overview": "Proposes practical methods and heuristics for preparing NLP datasets and models to make them amenable to state-of-the-art neural network verification methods; implements these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou, and demonstrates the tool on the R-U-A-Robot dataset to generate verification benchmarks and queries.",
    "data_type": "text (sentence classification examples and sentence embeddings)",
    "domains": [
      "Natural Language Processing",
      "Formal Verification"
    ],
    "languages": [],
    "similar_benchmarks": [
      "R-U-A-Robot"
    ],
    "resources": [
      "https://github.com/ANTONIONLP/ANTONIO",
      "https://vnnlib.org/",
      "https://github.com/onnx/onnx"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "Provide practical methods and heuristics to prepare NLP datasets and models to be amenable to neural network verification methods; implement these as the Python library ANTONIO linking to ERAN and Marabou; enable inclusion of NLP problems into neural network verification competitions.",
    "audience": [
      "Neural network verification community",
      "Natural Language Processing researchers"
    ],
    "tasks": [
      "Text Classification",
      "Verification of neural networks",
      "Adversarial robustness testing"
    ],
    "limitations": "Evaluation in this tool paper is performed on the R-U-A-Robot dataset only. State-of-the-art transformers are beyond the reach of state-of-the-art verifiers and verification efforts focus on classifiers on top of embeddings rather than verifying large pre-trained transformers end-to-end.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "R-U-A-Robot dataset (used in experiments); augmented via character-level, word-level, and sentence-level perturbations generated by ANTONIO; embeddings produced via Sentence-BERT.",
    "size": "6,800 examples",
    "format": "Sentence embeddings (384-dimensional vectors) for geometric processing; generated neural networks exported in ONNX format and verification queries in VNNLIB format.",
    "annotation": "R-U-A-Robot labels: positive (question demands identification), negative (question about something else), ambiguous."
  },
  "methodology": {
    "methods": [
      "Automated metrics (accuracy, robustness metrics)",
      "Model-based evaluation using neural network verifiers (ERAN, Marabou)",
      "Adversarial testing and attack-based dataset augmentation",
      "Translation of networks to ONNX and verification queries to VNNLIB"
    ],
    "metrics": [
      "Accuracy",
      "Robustness to attack (accuracy on adversarial test samples)",
      "Percentage of verified hyper-rectangles (verification success rate)"
    ],
    "calculation": "Accuracy: standard classification accuracy on test set. Robustness to attack: generate perturbations of the test set and compute accuracy on perturbed samples. Percentage of verified hyper-rectangles: run verifiers (ERAN, Marabou) on generated VNNLIB queries corresponding to hyper-rectangles and compute percentage of hyper-rectangles for which the verifier proves the desired property.",
    "interpretation": "It is important to avoid significant drops in standard accuracy when training for robustness; robustness metric measures classifier accuracy under generated perturbations; higher percentage of verified hyper-rectangles indicates greater success of verifiers on the defined input regions.",
    "baseline_results": "Table 4 (excerpt): Marabou - Nbase: H*_{ϵ=0.05}=1.79, H*_{char}=4.88, H*_{word}=11.69; N_{ϵ=0.05}: 18.46, 21.99, 41.93; N_{char-adv}: 7.37, 30.41, 41.93; N_{word-adv}: 12.17, 25.82, 45.12. ERAN - Nbase: 0.00, 0.87, 1.80; N_{ϵ=0.05}: 0.12, 4.18, 10.16; N_{char-adv}: 0.00, 4.43, 8.97; N_{word-adv}: 0.04, 4.05, 10.75.",
    "validation": "Validated by generating ONNX neural networks and VNNLIB verification queries and running them on two state-of-the-art verifiers (ERAN and Marabou); results reported (Table 4). Conforms to VNN-COMP standards (ONNX for networks and VNNLIB for verification queries)."
  },
  "targeted_risks": {
    "risk_categories": [
      "Safety",
      "Robustness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Legal Compliance",
          "subcategory": [
            "Legal accountability"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Evasion attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "User discomfort or deception (preventing chatbot deception)",
      "Legal implications for chatbot designers"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "Mentions proposed legislation and regulatory context, e.g., the EU Artificial Intelligence Act and California Senate Bill No. 1001 regarding chatbot identification requirements."
  }
}