{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "SOLD (Sinhala Offensive Language Dataset)",
    "abbreviation": "SOLD",
    "overview": "SOLD is a manually annotated dataset for offensive language identification in Sinhala containing 10,000 tweets annotated at sentence-level (Offensive / Not Offensive) and token-level (rationales). The paper also introduces SemiSOLD, a semi-supervised dataset with more than 145,000 Sinhala tweets annotated using a semi-supervised (democratic co-learning) approach. The resources are released to enable research on offensive language detection, explainability, transfer learning and data augmentation in a low-resource language.",
    "data_type": "text (Twitter posts / tweets)",
    "domains": [
      "Natural Language Processing"
    ],
    "languages": [
      "Sinhala"
    ],
    "similar_benchmarks": [
      "OffensEval",
      "TRAC",
      "HASOC",
      "HatEval",
      "AbuseEval",
      "OLID",
      "OGDT",
      "MOLD",
      "SOLID",
      "HateXplain",
      "TSD"
    ],
    "resources": [
      "https://github.com/Sinhala-NLP/SOLD",
      "https://huggingface.co/datasets/sinhala-nlp/SOLD",
      "https://huggingface.co/datasets/sinhala-nlp/SemiSOLD",
      "https://huggingface.co/sinhala-nlp/"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To provide the largest publicly available Sinhala offensive language dataset (SOLD) annotated at sentence-level and token-level to support offensive language identification and explainability in a low-resource language, and to release SemiSOLD (semi-supervised) to address data scarcity and enable transfer learning and data augmentation research.",
    "audience": [
      "Natural Language Processing researchers",
      "Machine Learning researchers",
      "Model developers",
      "Content Moderators"
    ],
    "tasks": [
      "Text Classification",
      "Token Classification",
      "Explainability (rationale extraction)"
    ],
    "limitations": "Dataset is limited to Twitter data written in Sinhala script (the authors filtered out Roman and mixed-script tweets). Token-level inter-annotator agreement is lower than sentence-level (majority of token-level pairwise Kappa scores between 0.6-0.7). SemiSOLD contains noisy labels (semi-supervised) and the authors report that filtering by model uncertainty is necessary; overly permissive thresholds can reduce model performance. The dataset covers only tweets collected via keyword filtering and a Twitter language filter.",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "SOLD: 10,000 tweets collected from Twitter using the Twitter API and keyword-based collection; SemiSOLD: more than 145,000 Sinhala tweets collected from Twitter for semi-supervised annotation.",
    "size": "10,000 tweets (SOLD); more than 145,000 tweets (SemiSOLD)",
    "format": "N/A",
    "annotation": "SOLD: Manual annotation via LightTag by ten native Sinhala annotators; each tweet annotated by three annotators; sentence-level labels (OFF/NOT) and token-level rationales (tokens contributing to offensiveness) collected; majority voting used to decide gold labels. Inter-annotator agreement measured with pairwise Fleiss' Kappa (sentence-level majority 0.7-0.8; token-level majority 0.6-0.7). SemiSOLD: annotated using a semi-supervised (democratic co-learning) approach where multiple ML models predict confidences and aggregated labels are assigned with uncertainty-based filtering."
  },
  "methodology": {
    "methods": [
      "Human annotation (crowdsourcing via LightTag) for gold labels",
      "Automated metrics (model evaluation)",
      "Cross-lingual transfer learning",
      "Semi-supervised data augmentation (democratic co-learning)",
      "Weakly-supervised token extraction using LIME"
    ],
    "metrics": [
      "Macro-averaged F1 Score",
      "Precision",
      "Recall",
      "Weighted F1 Score"
    ],
    "calculation": "Macro-averaged F1 computed across the OFF and NOT classes. Per-class Precision, Recall and F1 reported. Experiments run with five random seeds and mean values reported. For token-level evaluation, Precision, Recall and Macro F1 of offensive tokens were used. SemiSOLD labeling used model confidence averages and uncertainty thresholds (examples filtered by standard deviation thresholds 0.05, 0.1, 0.15).",
    "interpretation": "Macro-averaged F1 is used to account for class imbalance; higher Macro-F1 indicates better balanced performance across offensive and not-offensive classes. Models are compared against majority/minority baselines and improvements are reported as absolute scores and percentage differences versus non-transfer / non-augmented baselines.",
    "baseline_results": "Best reported sentence-level result: XLM-R achieved Macro F1 = 0.83. Best reported token-level result: XLM-R achieved F1 = 0.72. Majority-class baselines reported in paper for comparison.",
    "validation": "Dataset split randomly into 75% training and 25% testing. During model training an evaluation set consisting of one-fifth of the training data was used for early stopping. Experiments repeated with five random seeds; mean reported. Inter-annotator agreement computed (Fleiss' Kappa for sentence-level; character-offset pairwise Kappa for token-level). SemiSOLD filtered by model uncertainty thresholds and validated by improvements in downstream evaluation on the SOLD test set."
  },
  "targeted_risks": {
    "risk_categories": [
      "Privacy",
      "Fairness",
      "Societal Impact"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Privacy",
          "subcategory": [
            "Personal information in data"
          ]
        },
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Societal Impact",
          "subcategory": [
            "Impact on affected communities",
            "Impact on human agency"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": [
      "Offensive content",
      "Hate speech",
      "Cyber-bullying",
      "Toxicity"
    ]
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "The authors do not collect Twitter user IDs and replace username mentions with @USER tokens and URLs with <URL> tokens to conceal personally identifiable information.",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}