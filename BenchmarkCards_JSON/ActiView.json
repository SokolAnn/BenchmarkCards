{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "ActiView",
    "abbreviation": "N/A",
    "overview": "ActiView evaluates active perception in Multimodal Large Language Models (MLLMs) through Visual Question Answering (VQA) tasks that require models to perform view shifting and zooming to gather information from images to answer questions.",
    "data_type": "question-answering pairs",
    "domains": [
      "Natural Language Processing",
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [
      "BLINK",
      "V*",
      "CNT"
    ],
    "resources": [
      "https://github.com/THUNLP-MT/ActiView"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "The primary objective of ActiView is to develop methods for MLLMs to understand multimodal inputs in a more natural and holistic way by evaluating their active perception capabilities.",
    "audience": [
      "ML Researchers",
      "Model Developers"
    ],
    "tasks": [
      "Visual Question Answering"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Manually curated images and question-answer pairs with visual clues.",
    "size": "314 images, 1,625 evaluation instances",
    "format": "N/A",
    "annotation": "Manual annotation with specific guidelines for question and options related to visual clues."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics"
    ],
    "metrics": [
      "Accuracy"
    ],
    "calculation": "Accuracy is calculated based on the proportion of correct answers among the given responses.",
    "interpretation": "A higher accuracy indicates better performance in understanding multimodal images and reasoning based on visual information.",
    "baseline_results": "Human performance achieved an average accuracy of 84.67%.",
    "validation": "Benchmarked against 30 models, including proprietary and open-source."
  },
  "targeted_risks": {
    "risk_categories": [
      "Bias",
      "Fairness",
      "Robustness"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Robustness",
          "subcategory": [
            "Hallucination",
            "Evasion attack"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": []
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}