{
  "benchmark_details": {
    "is_benchmark": true,
    "name": "HPIR (Human Preference of Image Retrieval)",
    "abbreviation": "HPIR",
    "overview": "HPIR is a test set designed for evaluating the alignment of image retrieval systems with human aesthetic preferences. It leverages 150 pseudo queries generated to reflect user interests in aesthetics, where human evaluators compare groupings of image results for accuracy and aesthetic appeal.",
    "data_type": "image",
    "domains": [
      "Computer Vision"
    ],
    "languages": [
      "English"
    ],
    "similar_benchmarks": [],
    "resources": [
      "https://arxiv.org/abs/2406.09397"
    ]
  },
  "purpose_and_intended_users": {
    "goal": "To benchmark the alignment of human aesthetics in image retrieval systems.",
    "audience": [
      "ML Researchers",
      "Industry Practitioners",
      "Model Developers"
    ],
    "tasks": [
      "Image Retrieval"
    ],
    "limitations": "N/A",
    "out_of_scope_uses": []
  },
  "data": {
    "source": "Human-labeled dataset constructed from pseudo queries.",
    "size": "150 queries",
    "format": "N/A",
    "annotation": "Human labelers evaluate groups of images for aesthetic quality, with evaluations repeated to ensure reliability."
  },
  "methodology": {
    "methods": [
      "Human evaluation",
      "Automated metrics",
      "Reinforcement learning"
    ],
    "metrics": [
      "Accuracy",
      "Aesthetic quality"
    ],
    "calculation": "Calculated as average accuracy and aesthetic ratings from human labels.",
    "interpretation": "Higher scores indicate better alignment with human aesthetic preferences.",
    "baseline_results": null,
    "validation": "Validated through multiple rounds of human comparisons for robustness."
  },
  "targeted_risks": {
    "risk_categories": [
      "Fairness",
      "Accuracy"
    ],
    "atlas_risks": {
      "risks": [
        {
          "category": "Fairness",
          "subcategory": [
            "Data bias"
          ]
        },
        {
          "category": "Accuracy",
          "subcategory": [
            "Poor model accuracy"
          ]
        }
      ]
    },
    "demographic_analysis": "N/A",
    "harm": "N/A"
  },
  "ethical_and_legal_considerations": {
    "privacy_and_anonymity": "N/A",
    "data_licensing": "N/A",
    "consent_procedures": "N/A",
    "compliance_with_regulations": "N/A"
  }
}