# GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving

## üìä Benchmark Details

**Name**: GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving

**Overview**: GeoEval is a comprehensive benchmark designed to evaluate the performance of large language models (LLMs) and multi-modal models (MMs) in solving geometry math problems, consisting of various subsets with different problem complexities.

**Data Type**: geometry math problems with textual and diagram inputs

**Domains**:
- Education
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- Geometry3K
- PGPS9K
- UniGeo
- GeoQA+
- GeometryQA

**Resources**:
- [GitHub Repository](https://github.com/GeoEval/GeoEval)

## üéØ Purpose and Intended Users

**Goal**: To provide a standardized benchmark for evaluating the geometry problem-solving capabilities of AI models.

**Target Audience**:
- ML Researchers
- Model Developers
- Education Researchers

**Tasks**:
- Geometry Problem Solving

**Limitations**: N/A

## üíæ Data

**Source**: Sourced from seven public datasets and includes newly created problems.

**Size**: 5,050 geometry math problems

**Format**: N/A

**Annotation**: Annotated with complexity ratings for each problem.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy calculated as the percentage of correct answers out of total questions.

**Interpretation**: Higher accuracy indicates better model performance on geometry problems.

**Baseline Results**: WizardMath-70B achieved 55.67% accuracy on the GeoEval-2000 subset.

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy
- Robustness

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
