# BICAUSE (Bilingual Causal Chains)

## 📊 Benchmark Details

**Name**: BICAUSE (Bilingual Causal Chains)

**Overview**: BICAUSE is a structured bilingual dataset for causal reasoning, including semantically aligned Chinese and English samples in both forward and reversed causal forms, aiming to analyze the impacts of language structure on reasoning in large language models.

**Data Type**: causal reasoning pairs

**Domains**:
- Natural Language Processing

**Languages**:
- Chinese
- English

**Resources**:
- [GitHub Repository](https://github.com/Aurora-cx/BabelLLM_public)

## 🎯 Purpose and Intended Users

**Goal**: To systematically examine how large language models represent causal reasoning across languages and understand the internal mechanisms influenced by linguistic structures.

**Target Audience**:
- ML Researchers
- Language Model Developers

**Tasks**:
- Causal Reasoning

**Limitations**: N/A

## 💾 Data

**Source**: Constructed bilingual dataset designed for fine-grained analysis.

**Size**: 400 samples

**Format**: N/A

**Annotation**: Annotated for causal components with conjunction elements.

## 🔬 Methodology

**Methods**:
- Quantitative analysis
- Attention mechanism analysis

**Metrics**:
- Accuracy

**Calculation**: Statistical analysis of attention scores and reasoning accuracy across input samples.

**Interpretation**: Measures how language-specific biases affect causal reasoning outcomes.

**Validation**: Evaluated primarily using Qwen1.5-1.8B-Chat model.

## ⚠️ Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
