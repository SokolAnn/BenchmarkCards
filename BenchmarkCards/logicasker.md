# LogicAsker

## üìä Benchmark Details

**Name**: LogicAsker

**Overview**: LogicAsker is an automatic framework designed to evaluate and enhance the logical reasoning skills of large language models (LLMs) by utilizing Minimum Functionality Tests (MFTs). It identifies reasoning failures and improves model performance through targeted examples and fine-tuning data.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/yxwan123/LogicAsker)

## üéØ Purpose and Intended Users

**Goal**: To evaluate and improve the logical reasoning capabilities of large language models using a comprehensive set of formal reasoning skills.

**Target Audience**:
- ML Researchers
- Model Developers
- Domain Experts

**Tasks**:
- Logical Reasoning

**Limitations**: N/A

## üíæ Data

**Source**: Constructed through automatic generation following established propositional and predicate logic rules.

**Size**: N/A

**Format**: N/A

**Annotation**: Automatically generated based on formal logic rules.

## üî¨ Methodology

**Methods**:
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy is calculated based on the number of correct answers out of total responses to logical reasoning test cases.

**Interpretation**: Higher accuracy indicates better reasoning ability of the LLMs according to defined logic rules.

**Validation**: Extensive testing across six state-of-the-art LLMs.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
