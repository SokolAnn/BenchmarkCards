# A BENCHMARK AND EVALUATION FOR REAL-WORLD OUT-OF-DISTRIBUTION DETECTION USING VISION-LANGUAGE MODELS

## üìä Benchmark Details

**Name**: A BENCHMARK AND EVALUATION FOR REAL-WORLD OUT-OF-DISTRIBUTION DETECTION USING VISION-LANGUAGE MODELS

**Overview**: This paper introduces three novel out-of-distribution (OOD) detection benchmarks: ImageNet-X, ImageNet-FS-X, and Wilds-FS-X, designed to evaluate model performance under challenging semantic and covariate shifts, reflecting real-world conditions.

**Data Type**: image

**Domains**:
- Computer Vision

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/hoshi23/OOD-X-Benchmarks)

## üéØ Purpose and Intended Users

**Goal**: To provide challenging and practical evaluations of OOD detection methods to support a precise understanding of model characteristics.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Out-of-Distribution Detection

**Limitations**: N/A

## üíæ Data

**Source**: ImageNet-1k, Wilds datasets

**Size**: 25,000 images for ImageNet-X, 5,000 images for ImageNet-FS-X, varied for Wilds-FS-X

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Area Under ROC Curve (AUC-ROC)

**Calculation**: Metrics are calculated based on performance comparisons across different OOD detection methods.

**Interpretation**: Higher AUROC values indicate better OOD detection performance.

**Baseline Results**: N/A

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Robustness
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
