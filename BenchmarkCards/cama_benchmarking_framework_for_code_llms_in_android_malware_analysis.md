# Cama (Benchmarking framework for Code LLMs in Android Malware Analysis)

## üìä Benchmark Details

**Name**: Cama (Benchmarking framework for Code LLMs in Android Malware Analysis)

**Overview**: Cama is a benchmarking framework designed to systematically evaluate the effectiveness of Code LLMs in Android malware analysis. It specifies structured model outputs to support key malware analysis tasks, including malicious function identification and malware purpose summarization, and integrates evaluation metrics of consistency, fidelity, and semantic relevance.

**Data Type**: malware samples comprising over 7.5 million distinct functions

**Domains**:
- Cybersecurity

**Languages**:
- English

**Resources**:
- [Resource](https://zenodo.org/records/15155917)

## üéØ Purpose and Intended Users

**Goal**: The primary objective of Cama is to provide a structured framework for the evaluation of Code LLMs in Android malware analysis, facilitating comparison of their performance across different tasks.

**Target Audience**:
- ML Researchers
- Cybersecurity Analysts

**Tasks**:
- Malicious Function Identification
- Malware Purpose Summarization

**Limitations**: N/A

## üíæ Data

**Source**: Collected from various Android malware families using Androguard for decompilation.

**Size**: 118 Android malware samples covering over 7.5 million distinct functions

**Format**: JSON

**Annotation**: Manually inspected and labeled according to their maliciousness.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Consistency
- Fidelity
- Semantic Relevance (BLEU, METEOR, ROUGE-L)

**Calculation**: Metrics are calculated based on the structured outputs generated by the Code LLMs, comparing them against ground truth labels.

**Interpretation**: The framework allows for the evaluation of how well Code LLMs output structured representations relevant for malware analysis.

**Baseline Results**: N/A

**Validation**: The effectiveness of the framework and models is validated through benchmarking studies involving multiple Code LLMs.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
