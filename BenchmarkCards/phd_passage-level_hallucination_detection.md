# PHD (Passage-level Hallucination Detection)

## üìä Benchmark Details

**Name**: PHD (Passage-level Hallucination Detection)

**Overview**: A benchmark developed to assess passage-level hallucination detection methods in large language models, focusing on detecting factual errors.

**Data Type**: Annotated passages

**Domains**:
- PHD-Low
- PHD-Medium
- PHD-High

**Languages**:
- English

**Similar Benchmarks**:
- WikiBio-GPT3

**Resources**:
- [GitHub Repository](https://github.com/maybenotime/PHD)

## üéØ Purpose and Intended Users

**Goal**: To facilitate research on zero-resource passage-level hallucination detection methods.

**Target Audience**:
- Researchers
- Practitioners in NLP

**Tasks**:
- Detect and evaluate passage-level hallucinations in language models.

**Limitations**: The method may not be suitable for sentence-level hallucination detection.

**Out of Scope Uses**:
- Non-passage level hallucination detection

## üíæ Data

**Source**: Wikipedia and outputs generated by ChatGPT

**Size**: 300 passages annotated in total (100 from each domain)

**Format**: Text

**Annotation**: Passages were annotated with labels: factual, non-factual, and unverifiable by human annotators.

## üî¨ Methodology

**Methods**:
- Reverse Validation (RV)
- Question Generation (QG)
- Entity Matching (EM)

**Metrics**:
- Precision
- Recall
- F1 Score
- Accuracy

**Calculation**: Precision is calculated as the portion of non-factual passages out of the rejected passages. Recall is the portion of passages rejected out of all non-factual passages.

**Interpretation**: Higher precision indicates a lower false positive rate, while higher recall indicates a lower false negative rate.

**Baseline Results**: The best performing method achieved an F1 score of 59.1 on the PHD benchmark.

**Validation**: The reverse validation method was validated via annotation by qualified human workers.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Privacy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias
- **Privacy**: Personal information in prompt

**Demographic Analysis**: N/A

**Potential Harm**: Potential propagation of misinformation due to incorrect classifications.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: No personal data was used; all data is publicly available from Wikipedia.

**Data Licensing**: All annotation processes adhered to ethical guidelines; no proprietary data was used.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Complied with ethical standards for AI research.
