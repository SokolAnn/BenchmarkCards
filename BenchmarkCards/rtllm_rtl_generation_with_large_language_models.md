# RTLLM (RTL Generation with Large Language Models)

## 📊 Benchmark Details

**Name**: RTLLM (RTL Generation with Large Language Models)

**Overview**: RTLLM is an open-source benchmark for generating design RTL with natural language instructions. It supports quantitative evaluation based on syntax correctness, functionality equivalence, and design quality metrics.

**Data Type**: design RTL

**Domains**:
- Electrical Engineering
- Computer Engineering

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/hkust-zhiyao/RTLLM)

## 🎯 Purpose and Intended Users

**Goal**: To provide a comprehensive platform for evaluating RTL design generation using natural language.

**Target Audience**:
- ML Researchers
- Hardware Designers
- Academics

**Tasks**:
- RTL Design Generation

**Limitations**: N/A

## 💾 Data

**Source**: Created by the authors, consisting of 30 designs with various complexities and functionalities.

**Size**: 30 designs

**Format**: design RTL files in Verilog

**Annotation**: Ground-truth design created by human designers for comparison.

## 🔬 Methodology

**Methods**:
- Automated evaluation

**Metrics**:
- Syntax correctness
- Functionality correctness
- Design quality metrics (PPA)

**Calculation**: Evaluates syntax by checking synthesizability, functionality through testbench results, and design quality through PPA values after synthesis.

**Interpretation**: A design is deemed successful if it meets the syntax, functionality, and quality goals.

**Baseline Results**: Reference designs (ground-truth) generated by human engineers.

**Validation**: Validation through automated scripts incorporated within the benchmark.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Robustness

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
