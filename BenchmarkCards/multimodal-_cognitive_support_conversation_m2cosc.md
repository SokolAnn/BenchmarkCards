# MultiModal- Cognitive Support Conversation (M2CoSC)

## üìä Benchmark Details

**Name**: MultiModal- Cognitive Support Conversation (M2CoSC)

**Overview**: M2CoSC is a novel multimodal conversational cognitive reframing dataset that pairs synthetic dialogues generated by LLMs with corresponding images reflecting clients' facial expressions, aimed at enhancing AI psychotherapy.

**Data Type**: dialogue-image pairs

**Domains**:
- Natural Language Processing
- Healthcare

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/nobel-postech/M2CoSC)

## üéØ Purpose and Intended Users

**Goal**: To enhance the therapeutic capabilities of AI in psychotherapy by integrating multimodal cognitive reframing methods that utilize non-verbal cues.

**Target Audience**:
- ML Researchers
- Mental Health Professionals
- AI Developers

**Tasks**:
- Cognitive Reframing
- Dialogue Generation

**Limitations**: The dataset is limited to virtual clients whose facial images and dialogues are consistent, and it does not fully capture the complexities of real-world interactions.

## üíæ Data

**Source**: Synthetic dialogues generated with LLMs paired with facial expression images created using DALL-E 3.

**Size**: 429 conversations

**Format**: N/A

**Annotation**: Data cleansing was conducted by native English speakers to ensure dialogue clarity and consistency.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics
- Model-based evaluation

**Metrics**:
- Empathy
- Logical Coherence
- Guidance

**Calculation**: Metrics were calculated based on a scoring system evaluating empathy, logical coherence, and guidance.

**Interpretation**: Higher scores indicate better performance in effectively capturing client-emotional states and providing rational, empathetic interventions.

**Baseline Results**: The dataset serves as a baseline for evaluation against models trained with multimodal inputs compared to standard text-only models.

**Validation**: Model performance was validated through extensive evaluation involving both human experts and GPT-4.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy
- Safety

**Atlas Risks**:
- **Fairness**
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: The dataset includes implications for biases in facial expression recognition across cultures.

**Potential Harm**: Inadequate response to client crises and failure to provide forward-looking strategies were observed as potential harms.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: The dataset's images were generated and do not use real client data, adhering to privacy protocols.

**Consent Procedures**: All generated data was produced under consent protocols with simulated interactions.

**Compliance With Regulations**: The study complies with ethical guidelines for AI usage in mental health.
