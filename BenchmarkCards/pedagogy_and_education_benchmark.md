# Pedagogy and Education Benchmark

## 📊 Benchmark Details

**Name**: Pedagogy and Education Benchmark

**Overview**: A new benchmark for evaluating LLM performance in the field of pedagogy and education, based on psychometric principles and designed to address limitations of existing benchmarks.

**Data Type**: multiple-choice questions

**Domains**:
- Education

**Languages**:
- Russian

**Similar Benchmarks**:
- MMLU (Massive Multitask Language Understanding)

**Resources**:
- [Resource](N/A)

## 🎯 Purpose and Intended Users

**Goal**: To evaluate LLMs' professional competencies in the field of pedagogy and education.

**Target Audience**:
- Educators
- Test Developers
- AI Researchers

**Tasks**:
- Assessment of educational competencies
- Evaluation of pedagogical knowledge

**Limitations**: N/A

## 💾 Data

**Source**: Constructed by a consortium of educational experts and pedagogical specialists.

**Size**: 3,936 items

**Format**: Multiple-choice questions

**Annotation**: Expert-reviewed and validated for content relevance and difficulty.

## 🔬 Methodology

**Methods**:
- Empirical Testing
- Expert Review

**Metrics**:
- Percent Correct

**Calculation**: Scored dichotomously based on correct responses.

**Interpretation**: Performance evaluated based on percentage of correct answers across different pedagogical competencies.

**Baseline Results**: GPT-4 scored 39.2% on the Pedagogy and Education Benchmark.

**Validation**: Validated through expert review and empirical testing.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Data contamination

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
