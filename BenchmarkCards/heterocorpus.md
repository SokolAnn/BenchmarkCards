<div align="center">

# HeteroCorpus

<small><em>Original: 2022.gebnlp-1.23.json</em></small>

<hr style="height:2px;border-width:0;color:gray;background-color:#007acc">

<p>
<img src="https://img.shields.io/badge/NaturalLanguageProcessing-blue?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAGwSURBVDhPjZLPSxtBFMe/s5tkE7PRqBhjQKwgFj3Ug5dignoTL/4FHrz1qIjHCl568NSLiojgwasn8SJYsAqCUigWTG1jiMuSsO6PzWTnvSTb1mLpCx8Y5vH9zHvzRpRKJTQaDZRKpfv1ev2JEOKBptr9eTJNs6jrert/OLg4Ho/L3W73QcgVnkqSMEHsXqlUSjLh3DeHItRqNfc7BcGMrusjTdOGqqpeidx7g4K3mUzmKB6P78fjA6lpWsXzvJu+/YdMp9PrDGo2m0u+70fZUCm93/DtJZRIJH6yofl8PsonPgtKbJpmK5PJnOXz+Us69hn1xWLxje/78W63u+H7wRmEvC1oNBoRx3FiZMhut7tZLBZf0fEzoVkEx0aj0RWaOBDVahU5jjOiHh1K7zgOnpJ5y7ZtYdu2X4BR13VFPp/3CoWCm0wm39JEe0JySGjJcZyNTqfjuK67atu2BhAWCoUZ6qs0cZdCJiL8IKlU6vP29naMfn/B3cxms7her49ITTqdVpPJ5Mna2trLcDj8ie6NGYTw1Ov1Iq7rhlhJ27YnmqYNQ6HQIBKJ/KJrf0n8D78BoVOBAJYE9eEAAAAASUVORK5CYII=" alt="Natural Language Processing" style="margin-right:5px;">
<img src="https://img.shields.io/badge/GenderStudies-blue?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAGwSURBVDhPjZLPSxtBFMe/s5tkE7PRqBhjQKwgFj3Ug5dignoTL/4FHrz1qIjHCl568NSLiojgwasn8SJYsAqCUigWTG1jiMuSsO6PzWTnvSTb1mLpCx8Y5vH9zHvzRpRKJTQaDZRKpfv1ev2JEOKBptr9eTJNs6jrert/OLg4Ho/L3W73QcgVnkqSMEHsXqlUSjLh3DeHItRqNfc7BcGMrusjTdOGqqpeidx7g4K3mUzmKB6P78fjA6lpWsXzvJu+/YdMp9PrDGo2m0u+70fZUCm93/DtJZRIJH6yofl8PsonPgtKbJpmK5PJnOXz+Us69hn1xWLxje/78W63u+H7wRmEvC1oNBoRx3FiZMhut7tZLBZf0fEzoVkEx0aj0RWaOBDVahU5jjOiHh1K7zgOnpJ5y7ZtYdu2X4BR13VFPp/3CoWCm0wm39JEe0JySGjJcZyNTqfjuK67atu2BhAWCoUZ6qs0cZdCJiL8IKlU6vP29naMfn/B3cxms7her49ITTqdVpPJ5Mna2trLcDj8ie6NGYTw1Ov1Iq7rhlhJ27YnmqYNQ6HQIBKJ/KJrf0n8D78BoVOBAJYE9eEAAAAASUVORK5CYII=" alt="Gender Studies" style="margin-right:5px;">
</p>

</div>

## Table of Contents

- [ğŸ“Š Benchmark Details](#-benchmark-details)
- [ğŸ¯ Purpose and Intended Users](#-purpose-and-intended-users)
- [ğŸ’¾ Data](#-data)
- [ğŸ”¬ Methodology](#-methodology)
- [âš ï¸ Targeted Risks](#ï¸-targeted-risks)
- [ğŸ”’ Ethical and Legal Considerations](#-ethical-and-legal-considerations)

<hr>

## ğŸ“Š Benchmark Details

<table>
<tr><td width="20%" align="center"><strong>Name</strong></td><td>
HeteroCorpus
</td></tr>
<tr><td width="20%" align="center"><strong>Overview</strong></td><td>
A corpus created specifically for studying heteronormative language in English, consisting of 7,265 manually annotated tweets.
</td></tr>
<tr><td width="20%" align="center"><strong>Data Type</strong></td><td>
Tweets
</td></tr>
<tr><td width="20%" align="center"><strong>Domains</strong></td><td>
<ul>
<li>Natural Language Processing</li>
<li>Gender Studies</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Languages</strong></td><td>
<ul>
<li>English</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Similar Benchmarks</strong></td><td>
<ul>
<li>Gender bias text corpora</li>
<li>Sexism detection datasets</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Resources</strong></td><td>
<ul>
<li><a href="https://github.com/juanmvsa/HeteroCorpus">GitHub Repository</a></li>
</ul>
</td></tr>
</table>

## ğŸ¯ Purpose and Intended Users

<table>
<tr><td width="20%" align="center"><strong>Goal</strong></td><td>
To identify and mitigate heteronormative language in NLP systems.
</td></tr>
<tr><td width="20%" align="center"><strong>Target Audience</strong></td><td>
<ul>
<li>Research community</li>
<li>NLP practitioners</li>
<li>Gender studies researchers</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Tasks</strong></td><td>
<ul>
<li>Heteronormative language detection</li>
<li>Gender bias analysis</li>
<li>NLP system evaluation</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Limitations</strong></td><td>
N/A
</td></tr>
<tr><td width="20%" align="center"><strong>Out of Scope Uses</strong></td><td>
<ul>
<li>Hate speech detection</li>
</ul>
</td></tr>
</table>

## ğŸ’¾ Data

<table>
<tr><td width="20%" align="center"><strong>Source</strong></td><td>
Twitter
</td></tr>
<tr><td width="20%" align="center"><strong>Size</strong></td><td>
7,265 tweets
</td></tr>
<tr><td width="20%" align="center"><strong>Format</strong></td><td>
Annotated textual data
</td></tr>
<tr><td width="20%" align="center"><strong>Annotation</strong></td><td>
Manually annotated by six annotators
</td></tr>
</table>

## ğŸ”¬ Methodology

<table>
<tr><td width="20%" align="center"><strong>Methods</strong></td><td>
<ul>
<li>SVM classification</li>
<li>Logistic regression</li>
<li>BERT-based models</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Metrics</strong></td><td>
<ul>
<li>Accuracy</li>
<li>F1-score</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Calculation</strong></td><td>
Metrics calculated based on the classification performance of the models.
</td></tr>
<tr><td width="20%" align="center"><strong>Interpretation</strong></td><td>
BERT models outperformed traditional classifiers indicating the complexity of identifying heteronormativity.
</td></tr>
<tr><td width="20%" align="center"><strong>Baseline Results</strong></td><td>
None
</td></tr>
<tr><td width="20%" align="center"><strong>Validation</strong></td><td>
Cohen's Kappa and Fleiss' Kappa used to assess annotation reliability.
</td></tr>
</table>

## âš ï¸ Targeted Risks

<table>
<tr><td width="20%" align="center"><strong>Risk Categories</strong></td><td>
<ul>
<li>Bias in language processing</li>
<li>Misrepresentation of gender</li>
<li>Harm to LGBTQIA+ communities</li>
</ul>
</td></tr>
<tr><td width="20%" align="center"><strong>Atlas Risks</strong></td><td>
No specific atlas risks defined
</td></tr>
<tr><td width="20%" align="center"><strong>Demographic Analysis</strong></td><td>
N/A
</td></tr>
<tr><td width="20%" align="center"><strong>Potential Harm</strong></td><td>
Potential perpetuation of stereotypes and exclusion of non-binary identities.
</td></tr>
</table>

## ğŸ”’ Ethical and Legal Considerations

<table>
<tr><td width="20%" align="center"><strong>Privacy And Anonymity</strong></td><td>
All tweets posted publicly with identifying characteristics removed.
</td></tr>
<tr><td width="20%" align="center"><strong>Data Licensing</strong></td><td>
Dataset follows Twitter's privacy policy and is not fully released.
</td></tr>
<tr><td width="20%" align="center"><strong>Consent Procedures</strong></td><td>
Not Applicable
</td></tr>
<tr><td width="20%" align="center"><strong>Compliance With Regulations</strong></td><td>
Not Applicable
</td></tr>
</table>

<hr>

<div align="center">
<p><em>This benchmark card was automatically generated.</em></p>
</div>