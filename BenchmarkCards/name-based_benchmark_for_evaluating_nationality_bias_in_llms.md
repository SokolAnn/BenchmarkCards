# Name-based Benchmark for Evaluating Nationality Bias in LLMs

## üìä Benchmark Details

**Name**: Name-based Benchmark for Evaluating Nationality Bias in LLMs

**Overview**: We introduce a novel name-based benchmarking approach derived from the Bias Benchmark for QA (BBQ) dataset to investigate the impact of substituting explicit nationality labels with culturally indicative names, exploring how this affects both bias magnitude and accuracy across a spectrum of LLMs.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- BBQ (Bias Benchmark for Question Answering)

**Resources**:
- [Resource](https://arxiv.org/abs/2507.16989)

## üéØ Purpose and Intended Users

**Goal**: To investigate how LLMs handle nationality-based stereotypes when explicit country labels are replaced by culturally indicative names.

**Target Audience**:
- ML Researchers
- Ethics in AI Professionals
- Bias Mitigation Practitioners

**Tasks**:
- Bias Evaluation
- Question Answering

**Limitations**: Our study focuses primarily on nationality-based biases and may not capture the complexity of identities and cultural contexts.

## üíæ Data

**Source**: BBQ (Bias Benchmark for Question Answering) dataset and re-engineered datasets created for this research.

**Size**: 3,080 unique prompts

**Format**: JSON

**Annotation**: Derived from validated expert templates, augmented with culturally indicative names.

## üî¨ Methodology

**Methods**:
- Metric comparison
- Error retention analysis
- Bias scoring

**Metrics**:
- Accuracy
- Bias Score
- Error Retention Ratio (ERR)

**Calculation**: Bias scores are computed based on how often the model's outputs conform to stereotypes when answers are incorrect.

**Interpretation**: Lower bias scores indicate reduced reliance on stereotypes, while higher accuracy reflects improved model performance.

**Baseline Results**: Accuracy comparisons for various models based on nationality vs. name datasets were documented.

**Validation**: Using comparative analyses across multiple models from OpenAI, Google, and Anthropic.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias, Output bias
- **Accuracy**

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Creative Commons License for BBQ dataset.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
