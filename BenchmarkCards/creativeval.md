# CreativEval

## üìä Benchmark Details

**Name**: CreativEval

**Overview**: CreativEval is a framework for evaluating the creativity of LLMs within the context of generating hardware designs, quantifying four creative sub-components: fluency, flexibility, originality, and elaboration.

**Data Type**: functional Verilog modules

**Domains**:
- Hardware Design

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/matthewdelorenzo/CreativEval/)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the creativity of LLMs in generating hardware code.

**Target Audience**:
- ML Researchers
- Hardware Designers

**Tasks**:
- Code Generation

**Limitations**: N/A

## üíæ Data

**Source**: Prompts for functionality, fluency, and originality consist of 111 HDLBits prompts sourced through AutoChip.

**Size**: 120 prompts

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Quantitative analysis
- Comparative evaluation

**Metrics**:
- Fluency
- Flexibility
- Originality
- Elaboration

**Calculation**: Each metric is derived based on the number of unique, functional Verilog solutions generated by LLMs.

**Interpretation**: Higher metrics indicate greater creativity and effectiveness in generating novel hardware solutions.

**Baseline Results**: GPT-3.5 achieved the highest creativity score among evaluated models.

**Validation**: Evaluated functional responses for their compliance with provided prompts.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Creativity

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
