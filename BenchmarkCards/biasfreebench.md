# BIASFREEBENCH

## üìä Benchmark Details

**Name**: BIASFREEBENCH

**Overview**: BIASFREEBENCH is an empirical benchmark that comprehensively compares eight mainstream bias mitigation techniques for large language models (LLMs) on two test scenarios: multi-choice QA and open-ended multi-turn QA. It reorganizes existing datasets into a unified query-response setting and introduces a response-level metric, Bias-Free Score, to evaluate fairness, safety, and anti-stereotypical behavior of LLM responses.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- BBQ
- FairMT-Bench

**Resources**:
- [GitHub Repository](https://github.com/xxupiano/BiasFreeBench)

## üéØ Purpose and Intended Users

**Goal**: To establish a unified testbed for evaluating bias mitigation methods in large language models through comprehensive empirical comparisons.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Tasks**:
- Bias Mitigation Evaluation
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Existing bias evaluation datasets such as BBQ and FairMT-Bench have been reorganized and reformatted for the benchmark.

**Size**: 10,195 examples

**Format**: JSON

**Annotation**: The responses have been annotated based on their degree of bias present in the generated outputs.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Bias-Free Score

**Calculation**: Bias-Free Score is calculated by measuring the proportion of responses that are safe, fair, and anti-stereotypical compared to biased responses.

**Interpretation**: Higher Bias-Free Score indicates better bias mitigation effectiveness. A score of 1 means no bias present, while a score approaching 0 indicates high levels of bias.

**Baseline Results**: N/A

**Validation**: Evaluated against benchmarks like BBQ and FairMT-Bench with majority voting for consistency.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias
- **Robustness**: Prompt injection attack

**Demographic Analysis**: N/A

**Potential Harm**: The benchmark aims to prevent harm that arises from biased responses generated by LLMs.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
