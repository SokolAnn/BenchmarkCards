# VideoHallu

## üìä Benchmark Details

**Name**: VideoHallu

**Overview**: VideoHallu is a benchmark of over 3,000 video QA pairs built from synthetic videos and expert-crafted counterintuitive QA to evaluate the critical thinking abilities of Multi-modal Large Language Models (MLLMs) on visual abnormalities.

**Data Type**: question-answering pairs

**Domains**:
- Computer Vision

**Languages**:
- English

**Similar Benchmarks**:
- MVBench
- MovieChat

**Resources**:
- [GitHub Repository](https://github.com/zli12321/VideoHallu.git)

## üéØ Purpose and Intended Users

**Goal**: To evaluate and enhance the capabilities of Multi-modal Large Language Models in detecting abnormalities in synthetic videos that violate commonsense and physical laws.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Synthetic videos generated by models like Veo2, Sora, and Kling, paired with expert-crafted QA.

**Size**: 3,233 QA pairs

**Format**: N/A

**Annotation**: Expert annotations by human evaluators.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Metrics are calculated based on model responses to benchmark QA pairs compared to ground truth answers.

**Interpretation**: Higher accuracy indicates better performance in identifying and reasoning about visual abnormalities.

**Validation**: The benchmark validation is conducted by manually annotating and reviewing selected model responses for agreement with ground truth.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy
- Robustness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Robustness**: Evasion attack

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
