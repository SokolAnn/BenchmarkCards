# RTVLM (Red Teaming Visual Language Models)

## ğŸ“Š Benchmark Details

**Name**: RTVLM (Red Teaming Visual Language Models)

**Overview**: RTVLM is the first red teaming dataset to benchmark current Visual Language Models (VLMs) in terms of four aspects: faithfulness, privacy, safety, and fairness. The dataset includes 10 sub-tasks under these aspects.

**Data Type**: image-text pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Resources**:
- [Resource](https://huggingface.co/datasets/MMInstruction/RedTeamingVLM)

## ğŸ¯ Purpose and Intended Users

**Goal**: To evaluate the robustness and vulnerabilities of Visual Language Models through a comprehensive red teaming methodology.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Faithfulness Evaluation
- Privacy Protection
- Safety Assurance
- Fairness Assessment

**Limitations**: N/A

## ğŸ’¾ Data

**Source**: The RTVLM dataset comprises 5,200 samples collected from various sources including public domain images and diffusion-generated content.

**Size**: 5,200 samples

**Format**: JSON

**Annotation**: Annotated by humans and generated by GPT-4 with self-instruct.

## ğŸ”¬ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Evaluation based on scoring criteria established for each task aspect.

**Interpretation**: Scores are assigned on a scale of 1-10 based on model output quality against established guidelines.

**Baseline Results**: GPT-4V serves as the benchmark, demonstrating superior performance compared to other models tested.

**Validation**: Performance of VLMs on RTVLM has been validated through both human evaluation and automated assessments.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Fairness
- Safety
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Unrepresentative data
- **Robustness**: Data poisoning

**Demographic Analysis**: N/A

**Potential Harm**: The dataset aims to detect harmful content generation and ensure ethical model outputs.

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
