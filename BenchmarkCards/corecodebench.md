# CORECODEBENCH

## üìä Benchmark Details

**Name**: CORECODEBENCH

**Overview**: CORECODEBENCH is a configurable multi-scenario repository-level benchmark designed to evaluate the performance of Large Language Models (LLMs) on engineering-level code through diverse scenarios including Development, BugFix, and Test-Driven Development tasks.

**Data Type**: coding problems and test cases

**Domains**:
- Software Engineering

**Languages**:
- Python

**Similar Benchmarks**:
- SWEBench
- BigCodeBench
- REPOEXEC

**Resources**:
- [GitHub Repository](https://github.com/AGI-Eval-Official/CoreCodeBench)
- [Resource](https://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa)

## üéØ Purpose and Intended Users

**Goal**: To systematically evaluate and compare the capabilities of LLMs in real-world engineering tasks using a diverse range of coding problems and scenarios.

**Target Audience**:
- ML Researchers
- Software Engineers
- Model Developers

**Tasks**:
- Code Generation
- Bug Fixing
- Test-Driven Development

**Limitations**: The benchmark requires repositories with substantial unit tests for effective evaluation.

## üíæ Data

**Source**: Generated from real-world repositories selected from the PyPI library

**Size**: 1,545 problems across various types

**Format**: N/A

**Annotation**: Automated generation of problems using a fully automated pipeline (CorePipe)

## üî¨ Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Pass@1
- PassRate

**Calculation**: Pass@1 is the percentage of problems where the first solution generated by a model passes all associated unit tests; PassRate measures improvement over a baseline.

**Interpretation**: Higher Pass@1 scores indicate better model performance in generating correct code solutions directly from problems.

**Baseline Results**: N/A

**Validation**: Quality inspection through both automated methods and manual checks by experienced developers.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Privacy
- Fairness
- Robustness
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
