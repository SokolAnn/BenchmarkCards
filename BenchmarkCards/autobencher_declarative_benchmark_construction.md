# AutoBencher (Declarative Benchmark Construction)

## üìä Benchmark Details

**Name**: AutoBencher (Declarative Benchmark Construction)

**Overview**: AutoBencher is a declarative framework for automatic benchmark construction, producing datasets to evaluate language models' capabilities and safety. It operationalizes benchmark desiderata like salience, difficulty, separability, and novelty as optimization problems and constructs datasets accordingly.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- MMLU (Massive Multitask Language Understanding)
- XSTest
- HarmBench

**Resources**:
- [GitHub Repository](https://github.com/XiangLi1999/AutoBencher.git)

## üéØ Purpose and Intended Users

**Goal**: To efficiently generate datasets that reveal novel insights and model vulnerabilities through automatic benchmark construction.

**Target Audience**:
- ML Researchers
- Model Developers
- Safety Analysts

**Tasks**:
- Text Classification
- Safety Evaluation

**Limitations**: N/A

## üíæ Data

**Source**: Generated by AutoBencher using language models and datasets descriptions.

**Size**: 4,000 examples

**Format**: JSON

**Annotation**: Automatically generated with human oversight for correctness and salience.

## üî¨ Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Novelty
- Difficulty
- Separability
- Attack Success Rate (ASR)

**Calculation**: Metrics are calculated based on model performance on constructed datasets compared to existing benchmarks.

**Interpretation**: Higher scores in novelty indicate datasets that provide new insights into model performance. Difficulty is assessed based on the error rates of models, while separability measures how well models differ in performance.

**Baseline Results**: AutoBencher datasets achieve 27% lower rank correlation and 22% more difficulty than existing human-constructed benchmarks like MMLU.

**Validation**: Human validation is performed to ensure the quality and relevance of generated datasets.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety

**Atlas Risks**:
- **Fairness**: Data bias
- **Robustness**: Evasion attack
- **Societal Impact**: Impact on education: bypassing learning

**Demographic Analysis**: N/A

**Potential Harm**: ['Potential for generating harmful prompts that models fail to reject.']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
