# PrinciplismQA

## üìä Benchmark Details

**Name**: PrinciplismQA

**Overview**: PrinciplismQA is a comprehensive benchmark designed to systematically evaluate the ethical reasoning of Large Language Models in medicine, grounded in core principles of medical ethics and combining knowledge-based questions with practice-oriented case studies.

**Data Type**: multiple-choice questions and open-ended case studies

**Domains**:
- Healthcare

**Languages**:
- English

**Similar Benchmarks**:
- MedSafetyBench
- MedEthicEval
- MedEthicsQA

**Resources**:
- [Resource](https://arxiv.org/abs/2508.05132)

## üéØ Purpose and Intended Users

**Goal**: To assess the ethical reasoning capabilities of large language models in the medical domain, ensuring models align with established medical ethics principles.

**Target Audience**:
- Medical Researchers
- AI Ethics Researchers
- Healthcare Practitioners

**Tasks**:
- Medical Ethics Assessment
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Curated from 350 authoritative medical ethics textbooks and case analysis articles from the AMA Journal of Ethics.

**Size**: 3,648 questions

**Format**: N/A

**Annotation**: Questions validated by medical experts.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Model performance is measured based on the proportion of correct responses to questions.

**Interpretation**: Higher scores indicate better ethical reasoning alignment with medical ethics.

**Baseline Results**: N/A

**Validation**: Evaluated through the LLM-as-a-Judge paradigm and human expert review.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
