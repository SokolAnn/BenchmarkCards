# H²VU-Benchmark (Hierarchical Holistic Video Understanding)

## 📊 Benchmark Details

**Name**: H²VU-Benchmark (Hierarchical Holistic Video Understanding)

**Overview**: The H²VU-Benchmark is designed to evaluate both general video and online streaming video comprehension, addressing limitations in existing benchmarks regarding coverage, task diversity, and scene adaptability.

**Data Type**: video

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- MSRVTT-QA
- MSVD-QA
- ActivityNet-QA
- NExT-QA
- Streaming Bench

**Resources**:
- [GitHub Repository](https://github.com/siriusrecco/H2VU-BenchMark)

## 🎯 Purpose and Intended Users

**Goal**: To comprehensively evaluate multimodal large language models’ real-world video understanding ability.

**Target Audience**:
- Research Community
- Model Developers

**Tasks**:
- Video Comprehension
- Counterfactual Reasoning
- Trajectory State Tracking

**Limitations**: N/A

## 💾 Data

**Source**: Combination of existing datasets and newly collected first-person streaming videos.

**Size**: 5,902 video clips

**Format**: Multiple-choice Question-Answer (QA) format

**Annotation**: Manual and semi-automatic annotation

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy is calculated by comparing model outputs with ground truth.

**Interpretation**: Higher accuracy indicates better performance in video understanding tasks.

**Validation**: Extensive evaluation of various models against the benchmark.

## ⚠️ Targeted Risks

**Risk Categories**:
- Bias
- Robustness
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
