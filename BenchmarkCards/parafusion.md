# ParaFusion

## üìä Benchmark Details

**Name**: ParaFusion

**Overview**: ParaFusion is a large-scale, high-quality English paraphrase dataset developed using Large Language Models (LLMs) to enhance lexical and syntactic diversity while maintaining semantic similarity, addressing challenges in existing datasets.

**Data Type**: paraphrase sentence pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- Microsoft Research Paraphrase Corpus
- Quora Question Pair Dataset
- PAWS Dataset
- ParaNMT
- ParaBank

**Resources**:
- [Resource](https://arxiv.org/abs/2404.12010)

## üéØ Purpose and Intended Users

**Goal**: To provide a high-quality resource for improving NLP applications, particularly in paraphrase generation.

**Target Audience**:
- ML Researchers
- NLP Practitioners
- Model Developers

**Tasks**:
- Paraphrase Generation
- Data Augmentation

**Limitations**: The dataset is focused on English paraphrases, which may limit its applicability to other languages.

## üíæ Data

**Source**: Developed from existing datasets including MRPC, Quora, PAWSWiki, with additional sentences generated to enhance quality.

**Size**: around 2 million unique paraphrase sentence pairs

**Format**: N/A

**Annotation**: Generated by ChatGPT (gpt-3.5-turbo) with filtering for hate speech and non-English sentences.

## üî¨ Methodology

**Methods**:
- Human evaluation
- LLM evaluation
- Automated metrics

**Metrics**:
- Semantic Similarity
- Lexical Diversity
- Syntactic Diversity
- Grammatical Correctness

**Calculation**: Metrics calculated using various models and scoring techniques including cosine similarity for semantic similarity, tree edit distances for syntactic diversity, and BLEU scores for lexical diversity.

**Interpretation**: Higher scores indicate better quality in terms of similarity, diversity, and correctness.

**Baseline Results**: ParaFusion shows at least 25% improvement in syntactic and lexical diversity compared to original datasets.

**Validation**: Evaluated through both human annotators and LLM, with consistent results showing higher quality than existing datasets.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety

**Atlas Risks**:
- **Fairness**: Data bias
- **Privacy**: Personal information in data

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Filtered out hate speech and offensive content to ensure dataset safety.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
