# FEABench

## üìä Benchmark Details

**Name**: FEABench

**Overview**: FEABench is a new benchmark that simultaneously assesses model performance in both facial expression recognition (FER) and action unit detection (AUD) tasks, enabling a more comprehensive assessment of Multimodal Large Language Models' capabilities in emotional perception and facial emotion analysis.

**Data Type**: image

**Domains**:
- Computer Vision

**Languages**:
- N/A

**Resources**:
- [GitHub Repository](https://github.com/953206211/FEALLM)

## üéØ Purpose and Intended Users

**Goal**: To provide a comprehensive benchmark for evaluating models' performance in facial emotion analysis, particularly in FER and AUD tasks.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Facial Expression Recognition
- Action Unit Detection

**Limitations**: N/A

## üíæ Data

**Source**: Constructed from the Aff-Wild2 dataset, which includes labeled facial expressions and action units.

**Size**: 16,227 images

**Format**: N/A

**Annotation**: Annotations validated by multiple domain experts.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- F1 Score

**Calculation**: Accuracy is used to measure the model‚Äôs ability to recognize facial expressions, while F1 scores are used for action unit detection.

**Interpretation**: High accuracy indicates strong performance in recognizing facial expressions, while F1 scores reflect precision in detecting action units.

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
