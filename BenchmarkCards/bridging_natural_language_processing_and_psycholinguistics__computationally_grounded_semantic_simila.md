# Bridging Natural Language Processing and Psycholinguistics: computationally grounded semantic similarity datasets for Basque and Spanish

## ðŸ“Š Benchmark Details

**Name**: Bridging Natural Language Processing and Psycholinguistics: computationally grounded semantic similarity datasets for Basque and Spanish

**Overview**: We present a computationally-grounded word similarity dataset based on two well-known Natural Language Processing resources; text corpora and knowledge bases. This dataset aims to fulfil a gap in psycholinguistic research by providing a variety of quantifications of semantic similarity in an extensive set of noun pairs controlled by variables that play a significant role in lexical processing.

**Data Type**: text (noun pairs with similarity scores and linguistic features)

**Domains**:
- Natural Language Processing
- Psycholinguistics

**Languages**:
- Basque
- Spanish

**Similar Benchmarks**:
- RG65 (RG)
- SimLex999 (SL)
- Wordsim353 (WS)

**Resources**:
- [Resource](http://compling.hss.ntu.edu.sg/omw/)
- [Resource](https://wordnet.princeton.edu/)
- [Resource](https://www.nltk.org/howto/wordnet.html)
- [Resource](https://linguatools.org/tools/corpora/wikipedia-monolingual-corpora/)
- [Resource](http://ixa.ehu.eus/euscrawl/)
- [Resource](https://fasttext.cc/docs/en/crawl-vectors.html)
- [Resource](https://www.statmt.org/europarl/)

## ðŸŽ¯ Purpose and Intended Users

**Goal**: To create a computationally-grounded dataset of noun pairs that provides multiple quantifications of semantic similarity (text-based, WordNet-based and hybrid embeddings) controlled for concreteness, frequency, semantic neighbourhood density and phonological neighbourhood density, to support psycholinguistic experiments and NLP analyses.

**Target Audience**:
- Psycholinguistics researchers
- Natural Language Processing researchers

**Tasks**:
- Word Similarity
- Semantic Similarity
- Embedding Evaluation

**Limitations**: Dataset is restricted to single-word nouns (multiword expressions excluded) and to Basque and European Spanish; phonological neighbours and nouns with fewer than three characters were excluded; some external evaluation gold sets (e.g., RG) are small and may have low statistical power.

## ðŸ’¾ Data

**Source**: Derived from Open Multilingual Wordnet (OMW) linked to Princeton WordNet 3.0; Spanish 2018 Wikipedia dump (text corpora); Euscrawl corpus for Basque; WordNet-based pseudo-corpora generated by random walks; embeddings computed with fastText and hybrid mapping (vecmap) combining text and WordNet embeddings.

**Size**: Spanish text corpus: 608 million tokens; Basque text corpus: 288 million tokens; WordNet-based pseudo-corpora: Spanish 406 million tokens (72 million random walks), Basque 166 million tokens (36.3 million random walks); WordNet lexicalizations: English 147,306 lexicalizations, Spanish 53,039 lexicalizations, Basque 26,701 lexicalizations. Feature dictionary sizes: various (e.g., concreteness dictionary Basque 19,660 entries, Spanish 14,771 entries as reported).

**Format**: N/A

**Annotation**: Automatically computed: concreteness via WordNet hypernymy depth (averaged synset depths), semantic neighbourhood density via counting first-degree WordNet synset relations (averaged across synsets), phonological neighbourhood density via Levenshtein distance (distance <= 1), frequency via Zipf frequencies (wordfreq for Spanish; counts from Euscrawl for Basque converted to Zipf). No human annotation reported.

## ðŸ”¬ Methodology

**Methods**:
- Embedding computation using fastText for text and pseudo-corpora and hybrid embeddings (vecmap mapping)
- Cosine similarity between embedding vectors to compute pairwise similarity
- Spearman correlation against gold-standard similarity datasets for evaluation
- K-Nearest Neighbors clustering (two clusters) on L2-normalized features to create noun pairs

**Metrics**:
- Cosine Similarity
- Spearman correlation

**Calculation**: Cosine similarity computed as the dot product of two vectors divided by the product of their Euclidean norms (range 0 to 1). Embedding similarity rankings compared to gold standards using Spearman correlation. Features L2-normalised and clustered with KNN (two groups: low/high) to form noun pairs sharing cluster membership across four features.

**Interpretation**: Cosine similarity ranges from 0 (no similarity) to 1 (complete similarity). Higher Spearman correlation between embedding-derived similarities and human gold standards indicates better alignment with human judgments. Hybrid embeddings (FThyb) are reported to show overall best Spearman correlation performance across datasets.

**Baseline Results**: As reported in Table 3 (Spearman correlation results): Basque (EUBaseline) RG: 77.05, WS: 65.7; FTtxt RG: 77.86, WS: 73.31; FTkb RG: 85.67, WS: 65.88; FThyb RG: 86.55, WS: 74.57. Spanish (ESBaseline) RG: 87.9, WS: 57.8, SL: 36.58; FTtxt RG: 86.57, WS: 57.28, SL: 28.7; FTkb RG: 72.84, WS: 57.32, SL: 39.93; FThyb RG: 87.25, WS: 63.45, SL: 40.57.

**Validation**: Embeddings and similarity measurements validated by computing Spearman correlations against existing gold-standard similarity/relatedness datasets (RG65, SimLex999, Wordsim353) in both languages and by comparing to baseline fastText embeddings.

## âš ï¸ Targeted Risks

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## ðŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
