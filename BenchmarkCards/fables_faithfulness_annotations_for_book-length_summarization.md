# FABLES (Faithfulness Annotations for Book-Length Summarization)

## üìä Benchmark Details

**Name**: FABLES (Faithfulness Annotations for Book-Length Summarization)

**Overview**: FABLES is the first large-scale human evaluation of faithfulness and content selection in LLM-generated summaries of fictional books, collecting 3,158 claim-level annotations from 26 books to assess summarization quality.

**Data Type**: claim-level annotations

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- LongEval
- FactScore

**Resources**:
- [GitHub Repository](https://github.com/mungg/FABLES)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the faithfulness and content selection in book-length summarization generated by LLMs.

**Target Audience**:
- ML Researchers
- Model Developers
- Domain Experts

**Tasks**:
- Summarization Evaluation
- Claim Extraction

**Limitations**: N/A

## üíæ Data

**Source**: Human annotations based on LLM-generated summaries of 26 recently published books.

**Size**: 3,158 claim-level annotations

**Format**: N/A

**Annotation**: Manual annotation by human evaluators who have read the books.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- F1 Score

**Calculation**: Metrics calculated based on human annotation performance on claim-level summarization.

**Interpretation**: Higher accuracy and F1 scores indicate better summarization fidelity and content selection.

**Baseline Results**: CLAUDE-3-OPUS outperformed other models in faithfulness, with 90% of its claims rated as faithful.

**Validation**: Inter-annotator agreement and self-consistency metrics were used to validate the quality of annotations.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Privacy
- Robustness
- Fairness
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Unrepresentative data
- **Robustness**: Evasion attack

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: All annotators provided consent for their contributions and received fair compensation.

**Data Licensing**: Not Applicable

**Consent Procedures**: Annotators consented to the use and publication of their annotations.

**Compliance With Regulations**: Not Applicable
