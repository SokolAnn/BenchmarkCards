# AgentFail

## 📊 Benchmark Details

**Name**: AgentFail

**Overview**: A dataset of 307 annotated failure logs from platform-orchestrated agentic systems, constructed to aid in identifying root causes of failures in these systems, providing a corresponding taxonomy and benchmark for automated diagnosis.

**Data Type**: failure logs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- Who&When

**Resources**:
- [Resource](https://anonymous.4open.science/r/ICLR26-27B2/)

## 🎯 Purpose and Intended Users

**Goal**: To systematically identify root causes of failures in platform-orchestrated agentic systems and provide guidelines for more reliable system development.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Failure Diagnosis

**Limitations**: N/A

## 💾 Data

**Source**: Failure logs collected from two representative agentic AI development platforms, Dify and Coze.

**Size**: 307 examples

**Format**: N/A

**Annotation**: Annotated by independent experts using Grounded Theory method.

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy of root cause identification is calculated based on the success rate of identifying failures

**Interpretation**: An accuracy of 33.6% indicates a challenging diagnosis task.

**Baseline Results**: N/A

**Validation**: Systematic qualitative validation through expert consensus.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
