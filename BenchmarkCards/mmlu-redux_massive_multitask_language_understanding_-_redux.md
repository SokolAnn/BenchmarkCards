# MMLU-Redux (Massive Multitask Language Understanding - Redux)

## üìä Benchmark Details

**Name**: MMLU-Redux (Massive Multitask Language Understanding - Redux)

**Overview**: This paper explores the consistency of small LLMs in answering multiple-choice questions from the benchmarks MMLU-Redux and MedQA across varying inference temperatures and model parameters, proposing new analytical tools and visualizations to measure the answer consistency.

**Data Type**: multiple-choice questions

**Domains**:
- Natural Language Processing
- Healthcare

**Languages**:
- English

**Resources**:
- [Resource](https://huggingface.co/datasets/MMLU-Redux)
- [Resource](https://huggingface.co/datasets/MedQA)

## üéØ Purpose and Intended Users

**Goal**: To quantify the non-determinism of small LLMs by examining answer consistency across multiple-choice questions.

**Target Audience**:
- ML Researchers
- Model Developers
- Healthcare Practitioners

**Tasks**:
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: MMLU-Redux benchmark dataset and MedQA dataset.

**Size**: N/A

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Experimental evaluation across multiple-choice questions

**Metrics**:
- Accuracy
- Consistency

**Calculation**: Metrics calculated based on the percentage of consistent answers and overall accuracy.

**Interpretation**: Higher consistency correlates with greater accuracy among consistent answers at lower temperatures.

**Baseline Results**: N/A

**Validation**: Empirical evaluation via multiple trials.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
