# Harry Potter Dialogue (HPD)

## üìä Benchmark Details

**Name**: Harry Potter Dialogue (HPD)

**Overview**: We introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character.

**Data Type**: text (multi-turn dialogue sessions with scene, speaker, character-attribute and relation annotations)

**Domains**:
- Natural Language Processing

**Languages**:
- English
- Chinese

**Similar Benchmarks**:
- PchatbotW
- PeDialog
- KvPI
- P-CHAT
- WOW
- Fri-QA
- Focus
- UltraChat
- LaMP
- Wizard of Wikipedia
- FriendsQA

**Resources**:
- [Resource](https://nuochenpku.github.io/HPD.github.io)
- [GitHub Repository](https://github.com/tatsu-lab/stanfordalpaca)

## üéØ Purpose and Intended Users

**Goal**: Align dialogue agents with characters in a story such that generated responses are not only relevant to the context but also seem like something the target character (Harry Potter) would say given the dialogue history, scene, and participant information.

**Target Audience**:
- Research community

**Tasks**:
- Dialogue Generation
- Retrieval-based Response Selection
- Persona-based Response Generation

**Limitations**: The data in the proposed dataset from the Harry Potter Series is restricted to a specific area, that is, Harry Potter Magic World. Considering the high cost of annotation, our character relation annotation work is restricted to Harry Potter.

**Out of Scope Uses**:
- Commercial use

## üíæ Data

**Source**: All dialogue sessions that Harry participates in from the Harry Potter novels (English and Chinese versions); supplemented with annotated dialogue scenes, speaker attributes, and character relations; scenes summarized with GPT-4 and calibrated by annotators.

**Size**: Training: 1,042 dialogue sessions; Test: 149 dialogue sessions. Test sessions contain on average 1-3 positive responses and 9 negative responses. 113 important characters annotated; 13 types of attributes and 12 types of relations collected.

**Format**: Same as data examples in Table 11 (line and page numbers for each dialogue plus annotations); authors supply a script to extract corresponding raw dialogue data from the novels according to provided line and page numbers.

**Annotation**: Manual annotation by professional annotators (four avid Harry Potter fans). Attributes and relations are annotated chapter by chapter by three annotators with a holdout (senior) annotator for resolving disagreements; scenes are summarized using GPT-4 and then calibrated by two skilled annotators. Test responses: candidate responses generated by ChatGPT/GPT-4 and then selected/revised by three annotators with a holdout annotator integrating annotations; manual double-check and revision performed.

## üî¨ Methodology

**Methods**:
- Reference-based automatic evaluation (reference-based metrics)
- GPT-4-based ranking evaluation
- Human evaluation (annotator revision of GPT-4 rankings)
- Retrieval evaluation for retrieval-based tasks

**Metrics**:
- Bleu-1
- Rough-L
- Distinct-1
- Mean Average Precision (MAP)
- Mean Reciprocal Rank (MRR)
- Precision at 1 (P@1)
- R10@k (Recall among top-k candidates)
- GPT-4 ranking on Relevance with the Scene (Relv.Sce.), Relevance with the Attributes (Relv.Att.), Relevance with the Relations (Relv.Re.)
- Human evaluation (annotator-revised rankings)

**Calculation**: Reference-based metrics (Bleu-1, Rough-L, Distinct-1) computed against annotated positive responses. GPT-4 is instructed to rank generated responses based on Relv.Sce., Relv.Att., and Relv.Re.; human annotators are then allowed to revise GPT-4's rankings and the modified results are adopted (averaged if multiple annotators revise). Retrieval metrics (MAP, MRR, P@1, R10@k) computed for retrieval experiments.

**Interpretation**: Higher scores in reference-based metrics indicate greater relevance/diversity; higher proportions in GPT-4 and human ranking metrics for Relv.Sce./Relv.Att./Relv.Re. indicate stronger persona (character) consistency. Table 3 reports percentage of generated responses ranked as best (top-1) in GPT-4 and human evaluation; Table 4 reports win/tie/lose proportions comparing Per-ChatGPT to human experts.

**Baseline Results**: Generation baselines: fine-tuned Alpaca and ChatGLM-6B; in-context learning: GPT-3 (text-davinci-002), ChatGPT (gpt3.5-turbo), ChatGLM variants. Authors report that rich-persona prompts (Per-Model) outperform base prompts across GPT-4 and human-based metrics. Per-ChatGPT shows notable improvements: Relv.Att. increased by 11.4% and Relv.Re. increased by 16.1% compared to ChatGPT. Retrieval baseline BERT-FP: MAP=0.468, MRR=0.468, P@1=0.259, R10@1=0.259, R10@5=0.788.

**Validation**: Quality control via multiple annotators: three annotators label attributes/relations with a holdout annotator resolving disagreements; manual double-check and revision. Scene summaries produced by GPT-4 are calibrated by two skilled annotators. For test responses, three annotators select positive responses from model candidates and a holdout annotator integrates annotations; final human evaluation revises GPT-4 rankings where annotators intervene.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Intellectual Property
- Data usage restrictions

**Atlas Risks**:
- **Data Laws**: Data usage restrictions
- **Intellectual Property**: Data usage rights restrictions, Copyright infringement

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: The authors provide only line number and page number of each collected dialogue rather than the detailed content of each dialogue session; they supply a script to extract raw dialogue data from the novels according to the provided line and page numbers.

**Data Licensing**: Dataset annotated material is promised to be released for research communities and the annotated character attributes are copyrighted by the authors; the dataset is developed for non-commercial use. No standard public license (e.g., CC BY) is specified in the paper.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
