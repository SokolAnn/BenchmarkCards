# DataSciBench

## ğŸ“Š Benchmark Details

**Name**: DataSciBench

**Overview**: DataSciBench is a comprehensive benchmark for evaluating Large Language Model (LLM) capabilities in data science, constructed based on a curated collection of complex prompts and featuring a semi-automated pipeline for generating ground truth and validating evaluation metrics.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Data Science

**Languages**:
- English

**Similar Benchmarks**:
- MLAgentBench
- Text2Analysis
- DAEval

**Resources**:
- [GitHub Repository](https://github.com/THUDM/DataSciBench/)

## ğŸ¯ Purpose and Intended Users

**Goal**: To provide a comprehensive and rigorous evaluation of LLMs in data science, revealing their strengths and weaknesses across various tasks.

**Target Audience**:
- ML Researchers
- Data Scientists
- Industry Practitioners

**Tasks**:
- Data Cleaning and Preprocessing
- Data Exploration and Statistics Understanding
- Data Visualization
- Predictive Modeling
- Data Mining and Pattern Recognition
- Interpretability and Report Generation

**Limitations**: N/A

## ğŸ’¾ Data

**Source**: Curated prompts and generated ground truth based on existing data science benchmarks and literature.

**Size**: 222 examples

**Format**: Text

**Annotation**: Semi-automated pipelines with human verification.

## ğŸ”¬ Methodology

**Methods**:
- Automated metrics
- Human evaluation
- Code execution evaluation

**Metrics**:
- Success Rate
- Completion Rate
- Model Accuracy
- Data Quality Score
- Visualization Completeness

**Calculation**: Defined through aggregate metrics based on performance evaluations of different models.

**Interpretation**: Models are evaluated based on their ability to successfully complete data science tasks and adhere to detailed instructions.

**Validation**: Validation involved cross-references with established benchmarks and expert reviews.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Privacy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias
- **Privacy**: Personal information in data

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
