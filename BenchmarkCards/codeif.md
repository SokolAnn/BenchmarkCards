# CodeIF

## üìä Benchmark Details

**Name**: CodeIF

**Overview**: CodeIF is the first benchmark specifically designed to assess the abilities of large language models (LLMs) to adhere to task-oriented instructions within diverse code generation scenarios. It encompasses a broad range of tasks, including function synthesis, error debugging, algorithmic refactoring, and code explanation, providing a comprehensive suite to evaluate model performance.

**Data Type**: code generation tasks

**Domains**:
- Computer Science

**Languages**:
- Java
- Python
- Go
- C++

**Similar Benchmarks**:
- McEval
- FullStackBench

**Resources**:
- [GitHub Repository](https://github.com/lin-rany/codeIFcute)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the instruction-following capabilities of LLMs in code generation across various programming languages and tasks.

**Target Audience**:
- ML Researchers
- Software Developers
- Model Developers

**Tasks**:
- Code Generation
- Error Debugging
- Function Synthesis
- Algorithmic Refactoring
- Code Explanation

**Limitations**: Limited Language Support; Static Evaluation Focus; Uniform Metric Weighting.

## üíæ Data

**Source**: Constructed from real code generation tasks through collecting constraints and LLM outputs.

**Size**: 1,200 tasks

**Format**: N/A

**Annotation**: Human-reviewed and generated by advanced LLMs.

## üî¨ Methodology

**Methods**:
- Automated evaluation
- Human evaluation

**Metrics**:
- Completely Satisfaction Rate (CSR)
- Soft Satisfaction Rate (SSR)
- Rigorous Satisfaction Rate (RSR)
- Consistent Continuity Satisfaction Rate (CCSR)

**Calculation**: Metrics are computed as the average satisfaction of constraints by the models.

**Interpretation**: Higher scores indicate better adherence to the constraints and instructions.

**Baseline Results**: Evaluated across 35 state-of-the-art LLMs including both open-source and commercial models.

**Validation**: Statistical analysis showed strong agreements in human evaluations.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy
- Robustness

**Atlas Risks**:
- **Fairness**
- **Accuracy**: Poor model accuracy
- **Robustness**

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
