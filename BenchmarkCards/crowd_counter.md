# CROWD COUNTER

## ğŸ“Š Benchmark Details

**Name**: CROWD COUNTER

**Overview**: CROWD COUNTER introduces a dataset containing 3,425 hate speech-counterspeech pairs spanning six different types of counterspeech for evaluating type-specific counterspeech generation.

**Data Type**: counterspeech pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- Gab
- Reddit

**Resources**:
- [GitHub Repository](https://github.com/hate-alert/CrowdCounter)

## ğŸ¯ Purpose and Intended Users

**Goal**: To provide a diverse and high-quality dataset for training and evaluating systems generating type-specific counterspeech in response to hate speech.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Tasks**:
- Counterspeech Generation
- Type Classification

**Limitations**: The dataset is only based on the English language and focuses solely on abusive content from the Gab platform.

## ğŸ’¾ Data

**Source**: HateXplain dataset and crowd-sourced annotations.

**Size**: 3,425 examples

**Format**: JSON

**Annotation**: Crowd-sourced via Amazon Mechanical Turk with guidelines to avoid redundancy and ensure quality.

## ğŸ”¬ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Meteor
- BLEU Score
- Argument quality
- Counter-argument quality
- Toxicity

**Calculation**: Metrics are calculated based on the responses generated by models compared to existing hate speech.

**Interpretation**: Higher scores in metrics indicate better performance in relevance, variety, and quality of responses.

**Baseline Results**: Flan-T5 scores highest in terms of relevance metrics compared to competing models.

**Validation**: The dataset was validated through checks for diversity and quality against released hateful messages.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Bias
- Privacy
- Safety

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Fairness**: Data bias
- **Privacy**: Personal information in data

**Demographic Analysis**: The dataset includes various demographic representations based on the targets of the hate speech.

**Potential Harm**: ['Increased risk of reinforcing stereotypes through biased counterspeech.']

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: The data is anonymized to protect annotator identities.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
