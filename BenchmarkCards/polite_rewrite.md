# POLITE REWRITE

## üìä Benchmark Details

**Name**: POLITE REWRITE

**Overview**: POLITE REWRITE ‚Äì a dataset for polite language rewrite. The released dataset has 10K polite sentence rewrites annotated collaboratively by GPT-3.5 and human, which can be used as gold standard for training, validation and test; and 100K high-quality polite sentence rewrites by GPT-3.5 without human review.

**Data Type**: text (source sentence, polite rewrite sentence pairs)

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- GYAFC

**Resources**:
- [Resource](N/A)

## üéØ Purpose and Intended Users

**Goal**: To provide a novel dataset for polite language rewrite, a challenging sentence rewrite task to guide a generation model against verbal abuse and offensive expression.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Sentence Rewrite
- Style Transfer

**Limitations**: N/A

## üíæ Data

**Source**: Impolite sentences selected from web using a sentiment analyzer (a fine-tuned UNILM on SST-2). Candidate sentences are screened with GPT-3.5 (8-shot in-context learning). Rewrites are generated by GPT-3.5 and then reviewed/edited by human annotators in a multi-stage human-in-the-loop procedure (Stage 0: GPT-3.5 8-shot seed; Stage 1: human accept/modify; Stage 2: GPT-3.5 fine-tuning (davinci-002) on human edits; Stage 3: GPT-3.5 generation). The released dataset contains 10K gold-standard sentence pairs (human+GPT-3.5 collaborative annotation) and 100K silver-standard pairs (GPT-3.5 without human review).

**Size**: 10,000 sentence pairs (gold); 100,000 sentence pairs (silver)

**Format**: N/A

**Annotation**: Human-GPT-3.5 collaborative annotation: GPT-3.5 generates rewrites (8-shot and fine-tuned davinci-002); human annotators accept, modify, or rewrite GPT-3.5 outputs. Gold: 10K reviewed by humans; Silver: 100K generated by GPT-3.5 without human review.

## üî¨ Methodology

**Methods**:
- Human-GPT-3.5 collaborative annotation
- Automated metric evaluation (BLEU)
- Human evaluation (English native speakers scoring outputs 1-5)
- Neural model baselines (Transformer, BART) trained/fine-tuned on dataset

**Metrics**:
- BLEU
- Human evaluation score (1-5)
- Pearson Correlation

**Calculation**: BLEU reported (sentence-level BLEU as referenced by 'Human-(sentence-level)BLEU'). Human judges assign scores from 1 to 5 (5 best, 1 worst). Pearson correlation computed between human-human judges and between human scores and sentence-level BLEU.

**Interpretation**: Higher BLEU indicates closer match to reference polite rewrites. Human judge score: 5 is best polite rewrite, 1 is worst. Pearson correlation is used to assess agreement between judges and between human judgments and BLEU.

**Baseline Results**: Transformer (Gold): BLEU 6.2, Human Eval 1.8; Transformer (Silver+Gold): BLEU 23.9, Human Eval 2.8; BART (Gold): BLEU 34.9, Human Eval 3.2; BART (Silver+Gold): BLEU 37.5, Human Eval 3.9.

**Validation**: 10K gold data randomly split into 5K train / 3K development / 2K test. Silver data (100K) used as additional training data. Quality validation: 500 impolite sentences from the 10K were annotated by an additional human and another English native speaker attempted to distinguish purely-human vs collaborative annotations; over 90% of cases were indistinguishable. Human evaluation on 100 sampled test sentences by two native speakers reported correlations (human-human 0.84, human-BLEU 0.68).

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Safety

**Atlas Risks**:
- **Value Alignment**: Toxic output

**Potential Harm**: ['Verbal abuse', 'Offensive expression']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
