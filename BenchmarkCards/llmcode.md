# LLMCode

## 📊 Benchmark Details

**Name**: LLMCode

**Overview**: LLMCode is an open-source tool that evaluates and enhances researcher-AI alignment in qualitative analysis through two metrics—Intersection over Union (IoU) and Modified Hausdorff Distance (MHD).

**Data Type**: text

**Domains**:
- Human-Computer Interaction

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/username/repo)

## 🎯 Purpose and Intended Users

**Goal**: To improve the trustworthiness of LLM-driven qualitative coding by measuring and enhancing alignment between human and AI insights.

**Target Audience**:
- Qualitative Researchers
- Designers
- AI Tool Developers

**Tasks**:
- Qualitative Coding
- Human-AI Collaboration

**Limitations**: N/A

## 💾 Data

**Source**: Empirical studies conducted with designers using LLMCode.

**Size**: 26 participants across two studies

**Format**: N/A

**Annotation**: Manual coding by human researchers.

## 🔬 Methodology

**Methods**:
- Human evaluation
- Iterative coding process
- Quantitative metrics evaluation

**Metrics**:
- Intersection over Union (IoU)
- Modified Hausdorff Distance (MHD)

**Calculation**: Metrics are calculated based on the alignment between human-coded segments and AI-generated annotations.

**Interpretation**: Higher IoU indicates better alignment with human annotations; lower MHD indicates closer semantic alignment.

**Baseline Results**: N/A

**Validation**: Evaluation performed through user studies measuring interaction and qualitative metrics.

## ⚠️ Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
