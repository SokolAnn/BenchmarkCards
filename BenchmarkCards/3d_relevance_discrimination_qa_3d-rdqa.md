# 3D Relevance Discrimination QA (3D-RDQA)

## 📊 Benchmark Details

**Name**: 3D Relevance Discrimination QA (3D-RDQA)

**Overview**: The 3D-RDQA dataset is designed to disrupt shortcut learning and improve 3D understanding by encouraging genuine 3D scene comprehension rather than superficial language cues.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Similar Benchmarks**:
- ScanQA

**Resources**:
- [GitHub Repository](https://github.com/Li-Hao-yuan/3DRDQA)

## 🎯 Purpose and Intended Users

**Goal**: To facilitate rigorous evaluation and improve 3D understanding in vision-language models.

**Target Audience**:
- ML Researchers
- Domain Experts

**Tasks**:
- 3D Question Answering

**Limitations**: While the 3D-RDQA dataset effectively evaluates the 3D understanding of models, its multiple-choice format requires further investigation of its adaptability to other tasks.

## 💾 Data

**Source**: Created as a novel dataset by manipulating 3D tokens from existing datasets.

**Size**: N/A

**Format**: N/A

**Annotation**: Automatically generated with a focus on disrupting reliance on language.

## 🔬 Methodology

**Methods**:
- Human evaluation
- Performance analysis

**Metrics**:
- Accuracy

**Calculation**: Metrics calculated based on model responses in 3D question answering tasks.

**Interpretation**: Results are interpreted to understand the model's reliance on 3D versus language cues.

**Baseline Results**: N/A

**Validation**: Validation involves comparing model performance on the 3D-RDQA dataset against existing approaches.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Fairness**: Data bias

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
