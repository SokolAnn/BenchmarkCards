# ElecBench (a Power Dispatch Evaluation Benchmark for Large Language Models)

## üìä Benchmark Details

**Name**: ElecBench (a Power Dispatch Evaluation Benchmark for Large Language Models)

**Overview**: ElecBench introduces an evaluation benchmark for large language models (LLMs) within the power sector, addressing the lack of performance benchmarks for LLMs in this domain. The benchmark encompasses sector-specific scenarios and metrics to enhance decision-making precision in power dispatch.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Electrical Engineering
- Power System Operation

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/xiyuan-zhou/ElecBench-a-Power-Dispatch-Evaluation-Benchmark-for-Large-Language-Models)

## üéØ Purpose and Intended Users

**Goal**: To provide a comprehensive evaluation framework for large language models in the context of power system operations.

**Target Audience**:
- ML Researchers
- Power System Engineers
- Industry Practitioners

**Tasks**:
- Power Dispatch
- Fault Diagnosis
- Performance Evaluation

**Limitations**: N/A

## üíæ Data

**Source**: Test data generated specifically for evaluating LLMs in power system operation tasks, using both public datasets (e.g., MMLU, C-Eval) and proprietary data.

**Size**: N/A

**Format**: N/A

**Annotation**: The data generation includes automated and manual question formulation based on professional literature and simulation scenarios.

## üî¨ Methodology

**Methods**:
- Dual LLM scoring
- Human evaluation
- Simulation-based evaluation

**Metrics**:
- Factuality
- Logicality
- Stability
- Security
- Fairness
- Expressiveness

**Calculation**: Metrics calculated based on performance outcomes from empirical tests and simulations.

**Interpretation**: Performance is interpreted based on how well LLMs manage to adhere to defined metrics across various scenarios.

**Baseline Results**: N/A

**Validation**: Test results validated through public release and multiple evaluation rounds involving both AI and human evaluators.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Privacy
- Robustness
- Security

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Fairness**: Output bias
- **Privacy**: Personal information in data
- **Robustness**: Evasion attack
- **Misuse**: Improper usage

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
