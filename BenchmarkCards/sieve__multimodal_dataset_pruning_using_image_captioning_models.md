# Sieve: Multimodal Dataset Pruning Using Image Captioning Models

## üìä Benchmark Details

**Name**: Sieve: Multimodal Dataset Pruning Using Image Captioning Models

**Overview**: The paper introduces Sieve, a pruning method that utilizes synthetic captions from image-captioning models to improve dataset quality for Vision-Language Models by reducing false positives and negatives in image-text pair alignment.

**Data Type**: image-text pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Similar Benchmarks**:
- DataComp

**Resources**:
- [GitHub Repository](https://github.com/{repository_url})

## üéØ Purpose and Intended Users

**Goal**: To improve dataset quality for Vision-Language Models through effective pruning of noisy image-text datasets.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Image Retrieval
- Multimodal Learning

**Limitations**: N/A

## üíæ Data

**Source**: DataComp benchmark and web-crawled image-text datasets

**Size**: 128 million image-text pairs

**Format**: N/A

**Annotation**: Synthetic captions generated by image-captioning models

## üî¨ Methodology

**Methods**:
- Model-based evaluation
- Fused scoring from Sieve and CLIPScore

**Metrics**:
- Accuracy
- Retrieval performance

**Calculation**: Uses cosine similarity between embeddings of generated captions and alt-text.

**Interpretation**: Performance is interpreted based on improvements in classification and retrieval tasks.

**Baseline Results**: Surpasses CLIPScore by 2.6% on medium scale and 1.7% on large scale.

**Validation**: Evaluated across 38 downstream tasks.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Accuracy**: Data contamination, Unrepresentative data

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
