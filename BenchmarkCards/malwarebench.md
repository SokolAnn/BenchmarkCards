# MalwareBench

## ğŸ“Š Benchmark Details

**Name**: MalwareBench

**Overview**: MalwareBench is a benchmark dataset containing 3,520 jailbreaking prompts for malicious code generation, designed to evaluate LLM robustness against such threats. It encompasses 320 manually crafted malicious code generation requirements across 6 domains and 29 categories.

**Data Type**: jailbreaking prompts

**Domains**:
- Software Security

**Languages**:
- English

**Similar Benchmarks**:
- RMCBench

**Resources**:
- [GitHub Repository](https://github.com/MAIL-Tele-AI/MalwareBench)

## ğŸ¯ Purpose and Intended Users

**Goal**: To evaluate the security capabilities of large language models in generating malicious code and their vulnerability to jailbreak attacks.

**Target Audience**:
- ML Researchers
- Security Practitioners

**Tasks**:
- Malicious Code Generation

**Limitations**: Only Qwen - Turbo used for generating jailbreaking questions; limited scope of 320 requirements.

## ğŸ’¾ Data

**Source**: 320 manually crafted malicious requirements covering multiple programming languages and operating systems.

**Size**: 3,520 prompts

**Format**: N/A

**Annotation**: Manually crafted by experts in the field.

## ğŸ”¬ Methodology

**Methods**:
- Direct input evaluation
- Jailbreak prompt mutation

**Metrics**:
- Refusal rate
- Quality metric score ranging from 1 to 4

**Calculation**: Evaluation involves scoring based on whether models refuse to answer and the quality of their responses.

**Interpretation**: Scores indicate the models' ability to reject malicious inputs and quality of responses from irrelevant to well-developed harmful code.

**Baseline Results**: Average rejection rate of malicious content is 60.93%, dropping to 39.92% under jailbreak methods.

**Validation**: Evaluated against 29 models using LLMs, including mainstream and open-source.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Safety
- Robustness
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias
- **Robustness**: Evasion attack

**Demographic Analysis**: N/A

**Potential Harm**: Aims to understand the vulnerabilities of LLMs in generating harmful content.

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Conducted in compliance with ethical standards and relevant regulations.
