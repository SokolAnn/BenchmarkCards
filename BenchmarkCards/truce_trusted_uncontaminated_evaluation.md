# TRUCE (TRusted UnContaminated Evaluation)

## üìä Benchmark Details

**Name**: TRUCE (TRusted UnContaminated Evaluation)

**Overview**: TRUCE introduces the concept of Private Benchmarking, ensuring that benchmark datasets are kept private from the model to prevent contamination, while allowing for effective evaluation of LLMs. It builds solutions based on various trust models and demonstrates practical feasibility with experimental evaluation.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/microsoft/private-benchmarking)

## üéØ Purpose and Intended Users

**Goal**: The primary objective of TRUCE is to provide a solution for private benchmarking of LLMs to prevent data contamination during model evaluation.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Limitations**: N/A

## üíæ Data

**Source**: N/A

**Size**: N/A

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Trusted model owner evaluation
- Trusted dataset owner evaluation
- Trusted third party evaluation
- Confidential computation
- Secure multi-party computation

**Calculation**: The evaluation computes metrics based on the outputs of the LLM against the private benchmark data.

**Interpretation**: N/A

**Baseline Results**: N/A

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Privacy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Privacy**: Data privacy rights alignment

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: MIT

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
