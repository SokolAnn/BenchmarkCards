# N/A - Not a benchmark paper

## 📊 Benchmark Details

**Name**: N/A - Not a benchmark paper

**Overview**: The paper introduces two datasets of university-level probability and statistics questions to evaluate program synthesis capabilities of OpenAI's Codex.

**Data Type**: text

**Domains**:
- Natural Language Processing
- Mathematics

**Languages**:
- English

**Similar Benchmarks**:
- MATH
- MAWPS
- MathQA
- Math23k
- GSM8K

**Resources**:
- [Resource](N/A)

## 🎯 Purpose and Intended Users

**Goal**: To evaluate the efficacy of program synthesis in solving probability and statistics problems through dataset creation.

**Target Audience**:
- ML Researchers
- Educators
- Students

**Tasks**:
- Problem Solving

**Limitations**: N/A

## 💾 Data

**Source**: Curated questions from MIT's 18.05 Introduction to Probability and Statistics and Harvard's STAT110 Probability.

**Size**: 40 questions

**Format**: Text-based questions

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Program synthesis

**Metrics**:
- Accuracy

**Calculation**: Code execution accuracy is evaluated by comparing generated program output to correct solutions.

**Interpretation**: Outputs are considered correct if they are within 1% of the ground truth solutions.

**Validation**: Approach validated by comparing generated results against ground truth across structured datasets.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
