# Enhancing Video Captions Using Large Language Models

## üìä Benchmark Details

**Name**: Enhancing Video Captions Using Large Language Models

**Overview**: This research investigates the integration of Large Language Models (LLMs) to enhance the accuracy and context-awareness of captions generated by automatic speech recognition (ASR) systems for the Deaf and Hard of Hearing (DHH) community. A dataset is curated to evaluate the proposed pipeline's effectiveness in correcting ASR-generated captions.

**Data Type**: text

**Domains**:
- Natural Language Processing
- Accessibility

**Languages**:
- English

**Similar Benchmarks**:
- LibriSpeech
- TED-LIUM
- Common Voice

**Resources**:
- [GitHub Repository](https://github.com/monikabhole001/Improving-the-Quality-of-Video-Captions-for-the-DHH-Community-Using-LLM)

## üéØ Purpose and Intended Users

**Goal**: To improve the quality of video captions for the Deaf and Hard of Hearing community by leveraging Large Language Models.

**Target Audience**:
- ML Researchers
- Accessibility Practitioners
- AI Developers

**Tasks**:
- Caption Correction
- Speech Recognition

**Limitations**: LLMs might miss or misinterpret voice intonations, cultural references, and idioms that manual captioning can understand and convey accurately.

## üíæ Data

**Source**: Dataset of 52 videos collected from YouTube representing diverse domains.

**Size**: 52 videos

**Format**: Text

**Annotation**: Manually generated ground truth captions for comparison with ASR-generated captions.

## üî¨ Methodology

**Methods**:
- Quantitative Metrics Evaluation
- Model Performance Assessment

**Metrics**:
- Word Error Rate (WER)
- BLEU Score
- ROUGE Score

**Calculation**: Metrics calculated based on the comparison between LLM-generated captions and ground truth captions.

**Interpretation**: A lower WER indicates better accuracy; BLEU and ROUGE assess precision and recall of generated captions.

**Validation**: The performance of LLMs was evaluated against ground truth captions.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: Potential misinterpretation of cultural references by LLMs.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
