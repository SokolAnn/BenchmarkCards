# Linguistic Benchmark

## 📊 Benchmark Details

**Name**: Linguistic Benchmark

**Overview**: We introduce a comprehensive Linguistic Benchmark designed to evaluate the limitations of Large Language Models (LLMs) in domains such as logical reasoning, spatial intelligence, and linguistic understanding, among others. Through a series of straightforward questions, it uncovers the significant limitations of well-regarded models to perform tasks that humans manage with ease.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- MMLU
- GSM8K
- BIG-Bench

**Resources**:
- [GitHub Repository](https://github.com/autogenai/linguistic-benchmark)

## 🎯 Purpose and Intended Users

**Goal**: To provide a benchmark that evaluates LLMs on their reasoning capabilities and identify their limitations.

**Target Audience**:
- ML Researchers
- AI Practitioners
- Model Developers

**Tasks**:
- Logical Reasoning
- Spatial Intelligence
- Linguistic Understanding

**Limitations**: N/A

## 💾 Data

**Source**: 30 crafted questions focusing on various reasoning tasks, developed by the authors.

**Size**: 30 questions

**Format**: Text

**Annotation**: Judged by authors based on model responses.

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated scoring

**Metrics**:
- Accuracy

**Calculation**: Scores are calculated based on the precision of answers and adherence to logical principles.

**Interpretation**: Higher scores denote better performance in logical reasoning and task understanding.

**Validation**: Evaluated against popular LLMs and human responses.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
