# A BENCHMARK FOR VERICODING

## üìä Benchmark Details

**Name**: A BENCHMARK FOR VERICODING

**Overview**: This paper presents and tests the largest benchmark for vericoding, LLM-generation of formally verified code from formal specifications, containing 12,504 formal specifications.

**Data Type**: formal specifications

**Domains**:
- Software Engineering
- Artificial Intelligence

**Languages**:
- English

**Similar Benchmarks**:
- VerifyThisBench
- VeriBench

**Resources**:
- [GitHub Repository](https://github.com/username/repository)

## üéØ Purpose and Intended Users

**Goal**: To provide a benchmark expansion for formal specifications to support automation of formal verification and vericoding.

**Target Audience**:
- ML Researchers
- Software Engineers
- Formal Verification Practitioners

**Tasks**:
- Formal Verification
- Program Synthesis

**Limitations**: N/A

## üíæ Data

**Source**: Curated from various formal verification benchmarks and vibe coding datasets.

**Size**: 12,504 specifications

**Format**: JSONL

**Annotation**: Tasks are curated and quality-checked based on algorithm specifications.

## üî¨ Methodology

**Methods**:
- Automated metrics
- Verification against formal specifications

**Metrics**:
- Success rate

**Calculation**: Success rates are calculated based on the proportion of tasks completed successfully using LLMs.

**Interpretation**: A high success rate indicates the effectiveness of the benchmark and task difficulty.

**Baseline Results**: N/A

**Validation**: Manual inspection of a sample of outputs for verification success.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Robustness

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: All data is anonymized and does not contain personal information.

**Data Licensing**: MIT License

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
