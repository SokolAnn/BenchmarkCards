# GPT4Graph

## 📊 Benchmark Details

**Name**: GPT4Graph

**Overview**: We establish a benchmark across ten common scenarios to assess language models’ capability in handling graph-related tasks.

**Data Type**: graph-structured data

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [Resource](https://anonymous.4open.science/r/GPT4Graph)

## 🎯 Purpose and Intended Users

**Goal**: To setup a comprehensive comparison to show the ability of LLM in understanding graph structured data.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Node Classification
- Graph Classification
- Knowledge Graph Question Answering
- Graph Query Language Generation

**Limitations**: N/A

## 💾 Data

**Source**: OGBN-ARXIV citation network and other datasets.

**Size**: 100 nodes sampled from graph datasets

**Format**: GraphML, Adjacency List, Edge List

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Empirical evaluation
- Prompt techniques

**Metrics**:
- Accuracy

**Calculation**: Metrics calculated based on task outcomes in graph understanding.

**Interpretation**: Higher accuracy indicates better understanding of graph-structured data.

**Baseline Results**: N/A

**Validation**: Tested on multiple graph mining tasks.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Robustness

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: CDLAPermissive-2.0 license for synthesized labels; MIT license for code.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
