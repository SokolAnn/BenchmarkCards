# CIRCLE (Code-Interpreter Resilience Check for LLM Exploits)

## üìä Benchmark Details

**Name**: CIRCLE (Code-Interpreter Resilience Check for LLM Exploits)

**Overview**: The CIRCLE benchmark evaluates and quantifies interpreter-specific vulnerabilities across major LLM platforms, targeting system-level cybersecurity risks through a structured testing framework that assesses CPU, memory, and disk resource exhaustion.

**Data Type**: text

**Domains**:
- Natural Language Processing
- Cybersecurity

**Languages**:
- English

**Similar Benchmarks**:
- CyberSecEval
- CVE-Bench
- RedCode
- SandboxEval

**Resources**:
- [Resource](https://huggingface.co/datasets/govtech/CIRCLE)
- [GitHub Repository](https://github.com/govtech-responsibleai/CIRCLE)

## üéØ Purpose and Intended Users

**Goal**: Systematically evaluate interpreter-specific vulnerabilities in LLMs and guide safe and responsible deployment of LLM interpreter integrations.

**Target Audience**:
- Cybersecurity Researchers
- ML Researchers
- Industry Practitioners

**Tasks**:
- Vulnerability Assessment
- Resource Exhaustion Testing

**Limitations**: The benchmark comprises predetermined prompt sets, restricting responsiveness to emerging threats and novel exploitation techniques.

## üíæ Data

**Source**: Automated generation of 1,260 prompts focusing on resource exhaustion vulnerabilities.

**Size**: 1,260 prompts

**Format**: JSON

**Annotation**: Prompts are manually reviewed and classified into distinct risk categories.

## üî¨ Methodology

**Methods**:
- Automated evaluation
- Systematic testing across model providers

**Metrics**:
- Refusal Rate
- Execution Success Rate
- Timeout Rate

**Calculation**: Metrics are calculated based on model responses categorized into outcomes during evaluation.

**Interpretation**: Higher refusal rates indicate better model robustness against risky prompts.

**Validation**: Automated assessments are performed by a judge LLM, ensuring consistent evaluation.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Safety
- Accuracy

**Atlas Risks**:
- **Robustness**: Data poisoning
- **Fairness**: Output bias

**Demographic Analysis**: N/A

**Potential Harm**: ['Denial of Service (DoS) attacks']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: All prompts adhere to established resource constraints typical of native interpreter environments.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
