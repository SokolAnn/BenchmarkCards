# Embedded Lies Dataset

## üìä Benchmark Details

**Name**: Embedded Lies Dataset

**Overview**: This paper presents a novel dataset of 2,088 truthful and deceptive statements with annotated embedded lies, designed to enhance research in embedded lies within verbal deception detection.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [Resource](https://osf.io/jzrvh/?view_only=0195bd62f6974482b02fbc3c2912dbf4)

## üéØ Purpose and Intended Users

**Goal**: To foster research on embedded lies in verbal deception detection by providing a dataset collected through a within-subjects experimental design.

**Target Audience**:
- Researchers in Psychology
- NLP Researchers
- Data Scientists

**Tasks**:
- Text Classification

**Limitations**: N/A

## üíæ Data

**Source**: Collected through an experiment with participants providing autobiographical accounts written in both truthful and deceptive manners.

**Size**: 2,088 examples

**Format**: N/A

**Annotation**: Automated and manual annotations of embedded lies by participants.

## üî¨ Methodology

**Methods**:
- Supervised machine learning
- Natural Language Processing techniques

**Metrics**:
- Accuracy
- Precision
- Recall
- F1 Score

**Calculation**: Metrics were calculated using cross-validation to ensure robustness.

**Interpretation**: The interpretation of results relates to the ability to differentiate between truthful and deceptive statements based on the number of embedded lies.

**Baseline Results**: Performed multiple machine learning and language model evaluations, with the best model achieving 64% accuracy.

**Validation**: Validation procedures included nested cross-validation for model training.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Privacy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Output bias
- **Privacy**: Personal information in data

**Demographic Analysis**: The study includes analyses of individual differences based on demographic factors.

**Potential Harm**: ['Potential for misclassification affecting reputational impacts on participants.']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Participants provided informed consent, and data handling is compliant with ethical standards.

**Data Licensing**: Not Applicable

**Consent Procedures**: Informed consent was obtained from all participants.

**Compliance With Regulations**: Not Applicable
