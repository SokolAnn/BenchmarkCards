# A Survey on Hallucination in Large Vision-Language Models

## üìä Benchmark Details

**Name**: A Survey on Hallucination in Large Vision-Language Models

**Overview**: This survey investigates hallucination phenomena in Large Vision-Language Models (LVLMs), focusing on their effects, causes, evaluation methods, and mitigation strategies.

**Data Type**: Survey

**Domains**:
- Artificial Intelligence
- Vision-Language Models

**Languages**:
- English

**Similar Benchmarks**:
- CHAIR
- CCEval
- FAITHSCORE
- M-HalDetect
- POPE
- NOPE
- CIEM

**Resources**:
- [GitHub Repository](https://github.com/lhanchao777/LVLM-Hallucinations-Survey)

## üéØ Purpose and Intended Users

**Goal**: To provide insights for the development of LVLMs and explore the opportunities and challenges related to hallucinations in these models.

**Target Audience**:
- Researchers
- Developers
- Academics

**Tasks**:
- Understanding hallucination in LVLMs
- Evaluating and mitigating hallucination effects
- Developing more effective LVLMs

**Limitations**: N/A

**Out of Scope Uses**:
- Applications outside of LVLMs
- General language models without visual inputs

## üíæ Data

**Source**: N/A

**Size**: N/A

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Literature review
- Thematic analysis of hallucination examples
- Evaluation of existing benchmarks

**Metrics**:
- Accuracy
- Relevancy
- FAITHScore
- Reward Model Score

**Calculation**: N/A

**Interpretation**: N/A

**Baseline Results**: N/A

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Hallucination in visual outputs
- Misalignment of visual and textual information

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias
- **Explainability**: Unexplainable output
- **Robustness**: Prompt injection attack

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
