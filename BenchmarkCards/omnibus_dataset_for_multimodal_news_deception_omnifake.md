# Omnibus Dataset for Multimodal News Deception (OmniFake)

## 📊 Benchmark Details

**Name**: Omnibus Dataset for Multimodal News Deception (OmniFake)

**Overview**: The Omnibus Dataset for Multimodal News Deception (OmniFake) is a comprehensive benchmark of 127K samples that integrates human-curated misinformation from existing resources with newly synthesized AI-generated examples. It supports the unified detection of both human-written and AI-generated fake content.

**Data Type**: image-text pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Resources**:
- [Resource](https://arxiv.org/abs/2509.25991)

## 🎯 Purpose and Intended Users

**Goal**: To detect both human-crafted and AI-generated multimodal misinformation on social media.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Fake News Detection

**Limitations**: N/A

## 💾 Data

**Source**: Fakeddit dataset and newly synthesized AI-generated content.

**Size**: 127,283 samples

**Format**: N/A

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Automated metrics

**Metrics**:
- Accuracy
- Precision
- Recall
- F1 Score

**Calculation**: Metrics are calculated based on classification results from the detection framework.

**Interpretation**: Higher scores indicate better performance in identifying misinformation.

**Validation**: Dataset split into training, validation, and testing.

## ⚠️ Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
