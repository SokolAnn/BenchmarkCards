# MESH (Mise-En-Sc√®ne-Hallucinator)

## üìä Benchmark Details

**Name**: MESH (Mise-En-Sc√®ne-Hallucinator)

**Overview**: MESH is a benchmark designed to evaluate hallucinations in Large Video Models (LVMs) systematically using a Question-Answering framework. The benchmark incorporates binary and multi-choice formats with target and trap instances, aligning with human video understanding.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/username/repo)

## üéØ Purpose and Intended Users

**Goal**: To assess the ability of Large Video Models to avoid hallucination results and replicate aspects of human understanding of video.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Video Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: TVQA+ dataset

**Size**: N/A

**Format**: N/A

**Annotation**: Using a Question-Answering framework with binary and multi-choice questions.

## üî¨ Methodology

**Methods**:
- Automated metrics
- A/B testing

**Metrics**:
- Accuracy

**Calculation**: Accuracy measures the proportion of correct answers in both binary and multi-choice formats.

**Interpretation**: An accuracy score closer to 1 indicates better performance in recognizing elements and actions within videos.

**Baseline Results**: N/A

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Output bias

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
