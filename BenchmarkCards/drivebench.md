# DriveBench

## üìä Benchmark Details

**Name**: DriveBench

**Overview**: DriveBench is a benchmark dataset designed to evaluate the reliability of Vision-Language Models (VLMs) across various driving tasks including perception, prediction, planning, and explanation under different input conditions (clean, corrupted, and text-only). It includes 19,200 frames, 20,498 QA pairs, and 17 settings to assess VLM performance in real-world autonomous driving scenarios.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Similar Benchmarks**:
- DriveLM

**Resources**:
- [Resource](https://huggingface.co/datasets/drive-bench/arena)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the reliability and visual grounding of Vision-Language Models (VLMs) in autonomous driving across various tasks and conditions, revealing limitations and promoting safer driving decisions.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Tasks**:
- Perception
- Prediction
- Planning
- Behavior

**Limitations**: The benchmark may not generalize to all driving scenarios due to its specific focus on visual-language integration under particular conditions.

## üíæ Data

**Source**: DriveBench dataset curated from driving scenarios and augmented with question-answer pairs for evaluating VLMs.

**Size**: 19,200 frames and 20,498 QA pairs

**Format**: Graph and language

**Annotation**: Manually annotated and selected to ensure balance and representativeness for various driving tasks.

## üî¨ Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Accuracy
- BLEU Score
- ROUGE-L
- GPT Score

**Calculation**: Metrics are computed based on the quality of responses generated by VLMs for driving-related questions, assessing both correctness and reasoning quality using GPT-based rubrics.

**Interpretation**: Scores indicate the precision of answers as well as reasoning clarity, with higher scores reflecting better performance in terms of contextual understanding and reliability.

**Baseline Results**: N/A

**Validation**: Extensive experiments and benchmarking against existing models.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Safety
- Reliability
- Robustness
- Accuracy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data, Poor model accuracy
- **Robustness**: Prompt injection attack, Evasion attack
- **Fairness**: Data bias
- **Societal Impact**: Impact on affected communities

**Demographic Analysis**: N/A

**Potential Harm**: ['Potential collisions due to unreliable model predictions.']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
