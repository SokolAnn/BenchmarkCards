# Ethical Decision Support Assessment Checklist (EDSAC)

## üìä Benchmark Details

**Name**: Ethical Decision Support Assessment Checklist (EDSAC)

**Overview**: The study introduces the EDSAC framework to evaluate the ethical reasoning capabilities of Large Language Models (LLMs) in construction project management contexts, assessing performance against real-world ethical scenarios.

**Data Type**: text

**Domains**:
- Construction Project Management
- Artificial Intelligence

**Languages**:
- English

**Resources**:
- [Resource](N/A)

## üéØ Purpose and Intended Users

**Goal**: To empirically assess the ethical reasoning capacities of LLMs and establish a framework for their evaluation in the context of construction project management.

**Target Audience**:
- Researchers
- Construction Professionals
- Ethics Consultants

**Tasks**:
- Ethical Decision Making
- Performance Evaluation

**Limitations**: The scenarios used were static and the pool of interviewees and tested LLMs was finite.

## üíæ Data

**Source**: Test responses from three LLMs (ChatGPT, Gemini, LLaMA) evaluated against twelve ethical scenarios designed for construction decision-making.

**Size**: 72 responses

**Format**: N/A

**Annotation**: Responses were scored using a purpose-built checklist that evaluates ethical soundness, legal compliance, fairness, transparency, contextual relevance, actionable recommendations, and bias sensitivity.

## üî¨ Methodology

**Methods**:
- Quantitative performance testing
- Qualitative interviews

**Metrics**:
- Mean Score
- 5-point Likert Scale

**Calculation**: Performance scores were calculated based on the EDSAC framework, which evaluates responses on various ethical dimensions.

**Interpretation**: Scores indicate the level of ethical reasoning capacity of LLM responses, influencing their appropriateness for ethical decision-making.

**Baseline Results**: ChatGPT scored 4.35, Gemini scored 4.21, and LLaMA scored 3.92 out of 5 across ethical criteria.

**Validation**: Inter-rater reliability was ensured by having two researchers independently score the responses, with discrepancies resolved through discussion.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Privacy
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Consent was obtained for the interview process.

**Compliance With Regulations**: Not Applicable
