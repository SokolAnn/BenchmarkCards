# DrafterBench

## 📊 Benchmark Details

**Name**: DrafterBench

**Overview**: DrafterBench provides a comprehensive evaluation of LLM agents in the context of technical drawing revision, containing twelve types of tasks, 46 customized functions/tools, and 1920 tasks in total to assess AI agents' proficiency.

**Data Type**: structured data tasks

**Domains**:
- Civil Engineering

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/DrafterBench/DrafterBench)
- [Resource](https://huggingface.co/datasets/DrafterBench)

## 🎯 Purpose and Intended Users

**Goal**: To offer a systematic and comprehensive evaluation of the capabilities of LLMs to automate monotonous, low-tech, and high-labor-intensity tasks from industry.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers
- Domain Experts

**Tasks**:
- Drawing Revision

**Limitations**: N/A

## 💾 Data

**Source**: Real-world drawing revision files collected from design firms and construction companies.

**Size**: 1920 tasks

**Format**: N/A

**Annotation**: Verified by humans to simulate real scenarios.

## 🔬 Methodology

**Methods**:
- Automated metrics
- Dual functions record operation paths

**Metrics**:
- Task Accuracy
- Error Statistics

**Calculation**: Scores are graded based on code executability and target completeness.

**Interpretation**: The higher the score, the better the task execution and adherence to instructions.

**Baseline Results**: N/A

**Validation**: Tasks were filtered and verified for solvability.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Robustness

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Robustness**: Evasion attack

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
