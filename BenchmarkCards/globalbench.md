# GlobalBench

## üìä Benchmark Details

**Name**: GlobalBench

**Overview**: GlobalBench is an ever-expanding benchmark designed to track progress in NLP across all languages and tasks, incentivizing equitable language technology development by providing multifaceted evaluations including accuracy, utility, and equity across languages.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- XTREME
- XGLUE

**Resources**:
- [Resource](https://explainaboard.inspiredco.ai/benchmark?parent_id=globalbench&show_featured=false)
- [GitHub Repository](https://github.com/ExpressAI/DataLab)

## üéØ Purpose and Intended Users

**Goal**: To incentivize the global development of equitable language technologies that serve speakers of all languages by measuring and tracking NLP progress across a wide range of datasets and tasks.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Text Classification
- Named Entity Recognition
- Question Answering
- Machine Translation
- Text Pair Classification
- KG Prediction
- Language Modeling
- Grammatical Error Correction
- Summarization
- Code Generation

**Limitations**: GlobalBench may lose comparability due to its inclusivity, as it evaluates datasets of varying difficulties across languages.

## üíæ Data

**Source**: GlobalBench integrates datasets from various multilingual resources, totaling 966 datasets across 190 languages.

**Size**: 966 datasets

**Format**: N/A

**Annotation**: Datasets are collected from various sources and may include manual annotations depending on the source.

## üî¨ Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Accuracy
- F1 Score
- BLEU Score

**Calculation**: Metrics are calculated based on the best performances of submitted systems for each language and task.

**Interpretation**: Higher scores in metrics indicate better performance of language technologies across tasks and languages.

**Baseline Results**: N/A

**Validation**: GlobalBench continuously updates its leaderboard to reflect system performance across languages and tasks, thus validating contributions dynamically.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias, Output bias
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: GlobalBench analyzes system performances across demographic distributions to evaluate inclusion and equity in language technologies.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
