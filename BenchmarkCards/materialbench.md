# MaterialBENCH

## üìä Benchmark Details

**Name**: MaterialBENCH

**Overview**: MaterialBENCH is a college-level benchmark dataset for large language models (LLMs) in the field of materials science, consisting of problem-answer pairs derived from university textbooks, including free-response and multiple-choice questions.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- MMLU
- SciBench
- ChemBench

**Resources**:
- [Resource](https://huggingface.co/omron-sinicx)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the capabilities and limitations of existing large language models (LLMs) in solving materials science problems.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers
- Domain Experts

**Tasks**:
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Problems selected from university-level textbooks on materials science.

**Size**: 164 problems

**Format**: CSV

**Annotation**: Problems manually collected and verified by experts.

## üî¨ Methodology

**Methods**:
- Human evaluation

**Metrics**:
- Accuracy

**Calculation**: Accuracy calculated based on the number of correct answers from the models.

**Interpretation**: Higher accuracy indicates better performance in solving the problems.

**Baseline Results**: N/A

**Validation**: Manually verifying the correctness of the model responses by experts.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
