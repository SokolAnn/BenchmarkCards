# Hanfu-Bench

## ğŸ“Š Benchmark Details

**Name**: Hanfu-Bench

**Overview**: Hanfu-Bench is a manually curated multimodal dataset composed of traditional Chinese Hanfu designs spanning various dynasties, designed to evaluate cultural visual understanding and cultural image transcreation capabilities of Vision-Language Models (VLMs).

**Data Type**: multimodal

**Domains**:
- Natural Language Processing

**Languages**:
- Chinese
- English

**Resources**:
- [GitHub Repository](https://github.com/lizhou21/Hanfu-Bench)

## ğŸ¯ Purpose and Intended Users

**Goal**: To evaluate models' ability to understand and apply temporal-cultural features related to traditional Chinese Hanfu through visual question answering and image transcreation tasks.

**Target Audience**:
- ML Researchers
- Cultural Scholars
- AI Practitioners

**Tasks**:
- Cultural Visual Understanding
- Cultural Image Transcreation

**Limitations**: Current models struggle to accurately capture and adapt traditional cultural elements into modern designs.

## ğŸ’¾ Data

**Source**: Curated images collected from online retailers and television series related to historical Chinese attire.

**Size**: 1,192 images

**Format**: N/A

**Annotation**: Manual annotation by experts

## ğŸ”¬ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- Cultural Inheritance
- Modern Adaptability
- Semantic Equivalence
- Visual Change
- Naturalness

**Calculation**: Metrics are calculated based on human evaluations and comparisons of generated images against input images.

**Interpretation**: High scores indicate strong performance in retaining cultural elements and adapting them for modern contexts.

**Baseline Results**: Current VLMs show limited success with the best-performing model achieving only 42% in cultural image transcreation tasks.

**Validation**: Evaluated through multiple rounds of expert and non-expert assessments.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Bias
- Accuracy
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: Evaluation included diverse cultural representations.

**Potential Harm**: ['Inaccurate cultural representation']

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: The dataset uses publicly available images without commercial intent.

**Data Licensing**: CC BY-NC-SA 4.0 license, restricting to academic and non-commercial use.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
