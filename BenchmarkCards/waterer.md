# WaterER

## 📊 Benchmark Details

**Name**: WaterER

**Overview**: WaterER is a domain-specific benchmark suite established to evaluate the contributions of large language models (LLMs) in water engineering and research tasks.

**Data Type**: multiple-choice questions and titles for research papers

**Domains**:
- Natural Language Processing
- Water Engineering
- Water Research

**Languages**:
- English
- Chinese

**Resources**:
- [Resource](N/A)

## 🎯 Purpose and Intended Users

**Goal**: To evaluate the capabilities of large language models in understanding and responding to technical water-related tasks.

**Target Audience**:
- Researchers
- Water Engineers
- AI Developers

**Tasks**:
- Question Answering
- Research Gap Identification

**Limitations**: N/A

## 💾 Data

**Source**: Various reputable publications and technical resources pertaining to water engineering and research.

**Size**: 983 tasks

**Format**: N/A

**Annotation**: Manual validation by water experts

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- ROUGE-L

**Calculation**: Accuracy of the models' performances on zero-shot and five-shot settings.

**Interpretation**: Higher scores indicate better performance in handling domain-specific tasks.

**Baseline Results**: N/A

**Validation**: Dataset divided into a 10% validation set and a 90% test set.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Fairness**: Data bias

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
