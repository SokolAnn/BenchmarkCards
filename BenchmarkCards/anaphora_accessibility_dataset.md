# Anaphora Accessibility Dataset

## 📊 Benchmark Details

**Name**: Anaphora Accessibility Dataset

**Overview**: The dataset focuses on assessing discourse-level understanding in models through the task of anaphora accessibility, evaluating the ability to accurately reference entities introduced in discourse based on various linguistic constructions.

**Data Type**: anaphora pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/XiaomengZhu/AnaphoraAccessibilityDataset)

## 🎯 Purpose and Intended Users

**Goal**: To evaluate and improve discourse understanding abilities of language models through the lens of anaphora accessibility.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Discourse Understanding
- Anaphora Accessibility

**Limitations**: N/A

## 💾 Data

**Source**: Generated and manually inspected sentences based on theoretical constructions related to discourse and quantifier scope.

**Size**: 9,816 sentences

**Format**: N/A

**Annotation**: Manually verified by linguistics experts

## 🔬 Methodology

**Methods**:
- Surprisal-based evaluation
- Human comparison trials

**Metrics**:
- Accuracy

**Calculation**: Metrics calculated based on the probability assigned by models to specific continuations based on the context given.

**Interpretation**: Higher scores on relevant comparisons indicate better discourse understanding capabilities.

**Baseline Results**: N/A

**Validation**: Tests were validated through human participant comparisons on comprehension tasks.

## ⚠️ Targeted Risks

**Risk Categories**:
- Fairness
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Informed consent was obtained from participants for data collection.

**Compliance With Regulations**: Not Applicable
