# LebEval (Lebanese Evaluation Dataset)

## 📊 Benchmark Details

**Name**: LebEval (Lebanese Evaluation Dataset)

**Overview**: LebEval is a new benchmark derived from native Lebanese content, aiming to address the limitations of existing benchmarks that rely on translated materials, specifically focused on the translation of the low-resource Lebanese dialect.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- Arabic
- English

**Similar Benchmarks**:
- FLoRes

**Resources**:
- [GitHub Repository](https://github.com/username/repo)

## 🎯 Purpose and Intended Users

**Goal**: To establish a more reliable evaluation framework for dialectal translation using culturally-aware datasets that better reflect the linguistic and cultural nuances of the Lebanese dialect.

**Target Audience**:
- ML Researchers
- Language Technologists
- NLP Practitioners

**Tasks**:
- Machine Translation

**Limitations**: N/A

## 💾 Data

**Source**: The dataset includes authentic Lebanese content sourced from podcasts.

**Size**: Approximately 3,000 sentences

**Format**: N/A

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- xCOMET

**Calculation**: N/A

**Interpretation**: Higher xCOMET scores indicate better translation quality correlating with human judgment.

**Baseline Results**: N/A

**Validation**: This benchmark was validated using human evaluations and its performance was compared against the FLoRes benchmark.

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
