# DS Critique Bank

## üìä Benchmark Details

**Name**: DS Critique Bank

**Overview**: DS Critique Bank is a sizeable, human-verified dataset created for the task of explanation critiquing, which involves identifying flaws in model-generated explanations and providing suggestions to improve them. It includes critiques of reasoning chains generated by LLMs to enhance the understanding of their reasoning capabilities.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- MMLU (Massive Multitask Language Understanding)
- HellaSwag

**Resources**:
- [Resource](https://allenai.org/data/digital-socrates)

## üéØ Purpose and Intended Users

**Goal**: To provide a nuanced, interpretable evaluation tool that can automatically critique explanations generated by LLMs, enhancing their interpretability and understanding.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers
- Domain Experts

**Tasks**:
- Explanation Critique
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Data is sourced from existing question-answering datasets such as ARC and RAINBOW, where each instance comprises a question, model-generated explanation, and critiques along with human annotations.

**Size**: 26,478 critiques

**Format**: JSON

**Annotation**: Critiques are generated via expert annotation and crowd-sourced contributions, ensuring quality through vetted processes.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Explanation Score (ESC) from 0 to 5
- Critique Quality Score from 0 to 3

**Calculation**: Metrics are calculated based on the critiques' alignment with human-annotated explanation quality and flaw dimensions.

**Interpretation**: An explanation with a score of 0 is completely wrong, while a score of 5 indicates a fully correct explanation.

**Baseline Results**: Critiques generated by GPT-4 and validated against human evaluations, with a high correlation on explanation quality metrics.

**Validation**: The methodology employs a combination of human evaluations and automated assessments to ensure critique reliability.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Fairness
- Robustness
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Robustness**: Hallucination
- **Accuracy**: Unrepresentative data, Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: The dataset aims to reveal specific weaknesses in reasoning capabilities across LLMs which can help inform training and mitigate overarching issues.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: All annotators are anonymized, ensuring no personal identifiable information is included in the dataset.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
