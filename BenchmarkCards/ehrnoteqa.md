# EHRNoteQA

## üìä Benchmark Details

**Name**: EHRNoteQA

**Overview**: EHRNoteQA is a novel benchmark designed to evaluate Large Language Models (LLMs) in real-world clinical scenarios for answering clinicians‚Äô questions regarding patient discharge summaries, comprising 962 different QA pairs each linked to distinct patients‚Äô discharge summaries.

**Data Type**: question-answering pairs

**Domains**:
- Healthcare

**Languages**:
- English

**Similar Benchmarks**:
- MedQA
- PubMedQA
- MMLU
- MedMCQA

**Resources**:
- [Resource](https://doi.org/10.13026/acga-ht95)
- [GitHub Repository](https://github.com/ji-youn-kim/EHRNoteQA)

## üéØ Purpose and Intended Users

**Goal**: To provide a realistic evaluation standard for LLMs in clinical contexts, focusing on the analysis of discharge summaries.

**Target Audience**:
- ML Researchers
- Healthcare Professionals
- Model Developers

**Tasks**:
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: MIMIC-IV EHR database

**Size**: 962 question-answering pairs

**Format**: N/A

**Annotation**: Generated by GPT-4 and manually reviewed by clinicians.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Spearman correlation
- Kendall tau

**Calculation**: Scores are calculated using correlations between LLM performance on EHRNoteQA and clinician evaluations.

**Interpretation**: Higher scores indicate better performance in aligning with clinician evaluations.

**Validation**: EHRNoteQA results show high correlation with manual evaluations by clinicians.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Fairness
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Unrepresentative data, Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: MIT License

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
