# Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes

## üìä Benchmark Details

**Name**: Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes

**Overview**: The paper develops a framework to demonstrate how the temporal dynamics of word embeddings can be leveraged to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the U.S. over the 20th and 21st centuries.

**Data Type**: Text data from historical documents and U.S. Census data

**Domains**:
- Natural Language Processing
- Sociology
- Machine Learning

**Languages**:
- English

**Resources**:
- [Resource](Dataset of word embeddings trained on historical texts)
- [Resource](U.S. Census data)
- [GitHub Repository](Code and embeddings available at https://github.com/nikhgarg/EmbeddingDynamicStereotypes)

## üéØ Purpose and Intended Users

**Goal**: To quantify historical shifts in gender and ethnic stereotypes using word embeddings.

**Target Audience**:
- Researchers in linguistics
- Sociologists
- Data scientists
- Practitioners in NLP

**Tasks**:
- Analyze changes in language and stereotypes over time
- Validate findings against external data such as census
- Develop methods for quantifying stereotypes

**Limitations**: None

## üíæ Data

**Source**: Google News dataset, Google Books, and U.S. Census data

**Size**: Datasets include 100 years of text data

**Format**: Historical text corpora and vectors

**Annotation**: Word vectors trained to represent words and their semantic relationships

## üî¨ Methodology

**Methods**:
- Word embeddings
- Statistical analysis
- Regression
- Temporal analysis

**Metrics**:
- Relative norm distance
- Cosine similarity

**Calculation**: Calculating the relative strength of association between groups and neutral words.

**Interpretation**: The changes in embeddings reflect social shifts and trends in demographics.

**Validation**: Validated against historical census data and crowd-sourced stereotype scores

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias in word embeddings
- Temporal changes in language representation

**Atlas Risks**:
No specific atlas risks defined

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Data provided under appropriate usage rights consistent with the sources.

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
