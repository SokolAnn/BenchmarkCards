# MEQA (Meta-Evaluation Framework for Question & Answer LLM Benchmarks)

## üìä Benchmark Details

**Name**: MEQA (Meta-Evaluation Framework for Question & Answer LLM Benchmarks)

**Overview**: MEQA is a framework for the meta-evaluation of question and answer (QA) benchmarks, providing standardized assessments, quantifiable scores, and enabling meaningful intra-benchmark comparisons.

**Data Type**: quantitative scores

**Domains**:
- Natural Language Processing
- Cybersecurity

**Languages**:
- English

**Similar Benchmarks**:
- HarmBench-Cyber
- WMDP-Cyber
- CyberSecEval 1
- CyberSecEval 2
- SecEval
- SEvenLLM-Bench
- CyberMetric
- SECURE
- SecQA

**Resources**:
- [Resource](N/A)

## üéØ Purpose and Intended Users

**Goal**: To provide a framework for the meta-evaluation of QA benchmarks in order to assess their quality and effectiveness.

**Target Audience**:
- Benchmark Developers
- AI Researchers
- Evaluators

**Tasks**:
- Meta-evaluation

**Limitations**: N/A

## üíæ Data

**Source**: Evaluated benchmark datasets in cybersecurity

**Size**: N/A

**Format**: N/A

**Annotation**: Scores given by human and LLM evaluators based on defined criteria.

## üî¨ Methodology

**Methods**:
- Human evaluation
- LLM-based evaluation

**Metrics**:
- Mean score
- Standard deviation

**Calculation**: Scores are calculated on a scale from 1 to 5 for each sub-criterion.

**Interpretation**: Scores reflect the effectiveness of benchmarks in various meta-evaluation criteria.

**Baseline Results**: Scores from evaluated benchmarks as listed in Table 2.

**Validation**: Evaluation agreed upon by multiple human evaluators.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data, Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
