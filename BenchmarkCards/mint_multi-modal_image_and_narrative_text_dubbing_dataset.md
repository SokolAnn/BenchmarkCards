# MINT (Multi-modal Image and Narrative Text Dubbing Dataset)

## üìä Benchmark Details

**Name**: MINT (Multi-modal Image and Narrative Text Dubbing Dataset)

**Overview**: The MINT dataset was constructed to enhance the foley audio dubbing tasks involving narrative texts and images, addressing the limitations of existing datasets related to text-to-audio technology.

**Data Type**: audio-caption pairs

**Domains**:
- Natural Language Processing
- Computer Vision

**Languages**:
- English

**Similar Benchmarks**:
- AudioSet
- AudioCaps
- Clotho
- Sound-of-Story
- WavCaps

**Resources**:
- [GitHub Repository](https://github.com/borisfrb/MINT)

## üéØ Purpose and Intended Users

**Goal**: To provide a robust dataset for foley audio dubbing tasks incorporating multi-modal inputs such as image and narrative text.

**Target Audience**:
- ML Researchers
- Audio Researchers
- Model Developers

**Tasks**:
- Foley Audio Dubbing

**Limitations**: N/A

## üíæ Data

**Source**: Constructed using images from YouTube videos aligned with audio descriptions from AudioCaps, enhanced with narrative text generated by large language models.

**Size**: 35,363 training samples, 2,532 validation samples, 2,121 test samples

**Format**: JSON

**Annotation**: Manually annotated and expanded using language models based on detailed instructions.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Frechet Distance (FD)
- Kullback-Leibler (KL) divergence
- Overall audio quality (OVL)
- Relevance to the text caption (REL)

**Calculation**: FD and KL divergence calculated based on generated audio samples compared to target samples.

**Interpretation**: Higher FD indicates generated audio is closer to target audio; higher OVL and REL indicate better alignment with narrative text.

**Baseline Results**: Existing models like AudioGen and Tandem structures were tested against the proposed methods, showing significant performance improvements.

**Validation**: Tests were conducted with random samples and comprehensive evaluation metrics to ensure model reliability.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Robustness
- Safety

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: The dataset is for academic and research purposes only, adhering to fair use policies.

**Data Licensing**: CC BY-NC-SA-4.0 license for MINT dataset; AudioCaps dataset is under MIT License.

**Consent Procedures**: Involved subjects were aligned with terms ensuring academic use.

**Compliance With Regulations**: Dataset development aimed at following guidelines for copyright and privacy.
