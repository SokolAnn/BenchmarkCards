# Hallucination Elimination and Semantic Enhancement Framework for Vision-Language Models in Traffic Scenarios

## üìä Benchmark Details

**Name**: Hallucination Elimination and Semantic Enhancement Framework for Vision-Language Models in Traffic Scenarios

**Overview**: This paper proposes HCOENet, a method to eliminate hallucinations and enhance the description of critical objects overlooked in the initial response by large vision-language models.

**Data Type**: Image

**Domains**:
- Traffic Scenarios

**Resources**:
- [GitHub Repository](https://github.com/fjq-tongji/HCOENet)

## üéØ Purpose and Intended Users

**Goal**: To mitigate hallucinations in vision-language models and enhance the semantic understanding of traffic scenarios.

**Target Audience**:
- Researchers
- Developers in AI and autonomous driving

**Tasks**:
- Image description
- Hallucination detection and elimination
- Dataset creation

**Limitations**: Requires specific training to fine-tune existing models for optimal performance.

## üíæ Data

**Source**: Novel datasets created include CODA desc and nuScenes desc.

**Size**: 16952 image-text pairs total (9695 for CODA desc and 40157 for nuScenes desc)

**Format**: N/A

**Annotation**: Automatic semantic annotation generated by the framework.

## üî¨ Methodology

**Methods**:
- HCOENet
- Cross-checking mechanism
- Entity filtering
- Critical-object enhancement

**Metrics**:
- F1-score
- Precision
- Recall
- Accuracy

**Calculation**: Improvements in F1-scores were calculated comparing performances before and after applying HCOENet.

**Interpretation**: Based on the comparative results achieving higher scores using different models with HCOENet.

**Validation**: Experimental results validated on the POPE benchmark.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Hallucinations in generated text
- Safety risks in autonomous driving
- Misinterpretation of visual data

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Explainability**: Unexplainable output
- **Transparency**: Lack of training data transparency

**Demographic Analysis**: Not specified.

**Potential Harm**: Potential safety risks due to hallucinations affecting driving decisions.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
