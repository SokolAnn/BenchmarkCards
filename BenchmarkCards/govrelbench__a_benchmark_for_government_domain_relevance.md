# GovRelBench: A Benchmark for Government Domain Relevance

## üìä Benchmark Details

**Name**: GovRelBench: A Benchmark for Government Domain Relevance

**Overview**: GovRelBench is a benchmark specifically designed for evaluating the core capabilities of LLMs in the government domain. It consists of government domain prompts and a dedicated evaluation tool, GovRelBERT.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/pan-xi/GovRelBench)

## üéØ Purpose and Intended Users

**Goal**: To enhance the capability evaluation framework for large models in the government domain, providing an effective tool for relevant research and practice.

**Target Audience**:
- ML Researchers
- Policy Analysts
- Model Developers

**Tasks**:
- Text Classification

**Limitations**: N/A

## üíæ Data

**Source**: A combination of self-crawled data and specific domain data filtered from open-source datasets.

**Size**: 78,200 samples

**Format**: N/A

**Annotation**: Data annotated using SoftGovScore method to convert hard labels to soft scores.

## üî¨ Methodology

**Methods**:
- Automated metrics

**Metrics**:
- Accuracy
- F1 Score

**Calculation**: Accuracy and F1 Score are computed based on the relevance scores assigned to the model outputs.

**Interpretation**: Higher scores indicate better relevance of the generated text to the government domain.

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
