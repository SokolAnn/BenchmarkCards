# F-Eval (Fundamental Abilities Evaluation Benchmark)

## üìä Benchmark Details

**Name**: F-Eval (Fundamental Abilities Evaluation Benchmark)

**Overview**: F-Eval is a bilingual evaluation benchmark designed to assess the fundamental abilities of large language models (LLMs) including expression, commonsense, and logic. It consists of 15 sub-datasets with a total of 2211 instances, incorporating various task formats such as multi-choice and subjective tasks. The benchmark aims to facilitate the study of LLMs' fundamental abilities across different model sizes and dimensions.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English
- Chinese

**Resources**:
- [GitHub Repository](https://github.com/OpenLMLab/F-Eval)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the fundamental capabilities of large language models in terms of expression, commonsense reasoning, and logic abilities using a comprehensive and diverse set of tasks and evaluation methods.

**Target Audience**:
- ML Researchers
- Model Developers
- NLP Practitioners

**Tasks**:
- Text Classification
- Commonsense Reasoning
- Logic Reasoning

**Limitations**: The benchmark primarily focuses on expression, commonsense, and logic capabilities, which may not cover all fundamental capabilities LLMs should possess.

## üíæ Data

**Source**: Curated from online sources and adaptations of existing datasets, including original K12 texts and commonsense knowledge graphs.

**Size**: 2211 instances

**Format**: JSON

**Annotation**: Annotated by a mixture of expert and ordinary human annotators, with review processes in place for data quality.

## üî¨ Methodology

**Methods**:
- Rule-based Evaluation
- API Evaluation
- Probability Evaluation
- Assistant-Tool Evaluation

**Metrics**:
- Accuracy
- Correlation with human judgements

**Calculation**: Evaluation methods corresponding to each sub-dataset are specified, with scores obtained for each instance based on the designed metrics.

**Interpretation**: Scores reflect the ability of LLMs to perform on tasks measuring fundamental abilities, with higher scores indicating better performance.

**Baseline Results**: Comparison was made against 13 advanced LLMs, including GPT-4 and various open-source models, highlighting gaps in performance.

**Validation**: Rigorous evaluation against human judgments and existing benchmarks ensured reliability.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Fairness
- Safety
- Robustness
- Privacy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias
- **Privacy**: Personal information in data

**Demographic Analysis**: N/A

**Potential Harm**: ['Perpetuating commonsense errors in LLM outputs', 'Generating harmful content under specific conditions']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: User data was collected from publicly available sources; all information was anonymized post-processing.

**Data Licensing**: The data will be released under the CC BY-NC-ND 4.0 license for academic use only.

**Consent Procedures**: N/A - Not applicable as the data is sourced from publicly available resources.

**Compliance With Regulations**: Data sourced complies with relevant academic use regulations, including respect for personal data privacy.
