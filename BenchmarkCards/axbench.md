# AXBENCH

## üìä Benchmark Details

**Name**: AXBENCH

**Overview**: AXBENCH is a benchmark for evaluating language model control methods at scale using synthetic data. It assesses various steering methods and concept detection with labeled data generated from an LLM.

**Data Type**: labelled pairs of instructions and responses

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/stanfordnlp/axbench)

## üéØ Purpose and Intended Users

**Goal**: The primary objective of AXBENCH is to provide a comprehensive means for evaluating steering and concept detection methods in language models.

**Target Audience**:
- ML Researchers
- Model Developers

**Tasks**:
- Concept Detection
- Model Steering

**Limitations**: N/A

## üíæ Data

**Source**: Synthetic data generated from language model prompts

**Size**: 500 concepts

**Format**: N/A

**Annotation**: Labelled pairs of instructions and responses generated by LLM

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- F1 Score
- Area Under ROC Curve (AUC-ROC)

**Calculation**: Metrics are calculated based on model performance in concept detection and steering tasks using labeled data.

**Interpretation**: Higher scores indicate better performance in accurately detecting concepts and steering the language model behavior.

**Baseline Results**: N/A

**Validation**: The benchmark was validated using a diverse set of prompts and evaluations against established models.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
