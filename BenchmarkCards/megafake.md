# MegaFake

## üìä Benchmark Details

**Name**: MegaFake

**Overview**: The MegaFake dataset is a comprehensive dataset of fake news generated by large language models, developed using a novel theoretical framework known as LLM-Fake Theory. It comprises 46,096 instances of fake news and 17,871 instances of legitimate news, providing valuable resources for research in the detection and governance of fake news generated by LLMs.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- FakeNewsNet

**Resources**:
- [Resource](https://arxiv.org/abs/2408.11871)

## üéØ Purpose and Intended Users

**Goal**: To advance research in the detection of LLM-generated fake news and understand the mechanisms behind its creation.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers
- Domain Experts

**Tasks**:
- Fake News Detection
- Text Classification

**Limitations**: The dataset is constrained as it solely relies on the GossipCop dataset and currently supports only binary classification for fake or legitimate news.

## üíæ Data

**Source**: The MegaFake dataset was built upon the GossipCop dataset from FakeNewsNet, which includes human-generated fake and legitimate news articles as a foundation for generating LLM-generated content.

**Size**: 63,967 instances

**Format**: JSON

**Annotation**: Automatically generated by large language models using a novel generation pipeline informed by social psychology theory.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy
- F1 Score
- Precision
- Recall

**Calculation**: Metrics are calculated based on the performance of various NLG and NLU models tasked with classifying the categories of news in the dataset.

**Interpretation**: Higher scores indicate better model performance at identifying the true nature of news articles as legitimate or fake.

**Validation**: Cross-experiments were conducted to assess the robustness of the dataset against existing benchmarks.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: The dataset does not include demographic breakdowns or fairness across groups, as it focuses on LLM-generated content.

**Potential Harm**: The dataset involves the generation of potentially harmful misinformation, necessitating careful consideration of its use.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
