# CA4P-483

## üìä Benchmark Details

**Name**: CA4P-483

**Overview**: We construct the first Chinese privacy policy dataset, namely CA4P-483, to facilitate the sequence labeling tasks and regulation compliance identification between privacy policies and software. Our dataset includes 483 Chinese Android application privacy policies, over 11K sentences, and 52K fine-grained annotations.

**Data Type**: text (privacy policy documents; sentence- and character-level sequence labeling)

**Domains**:
- Natural Language Processing
- Software Engineering
- Cyber Security

**Languages**:
- Chinese

**Similar Benchmarks**:
- OPP-115
- APP-350
- MSRA
- OntoNotes
- PeopleDairy
- Weibo
- Resume
- CLUENER2020
- CNERTA
- Twitter-2015
- Twitter-2017

**Resources**:
- [GitHub Repository](https://github.com/zacharykzhao/CA4P-483)
- [Resource](https://arxiv.org/abs/2212.04357v1)

## üéØ Purpose and Intended Users

**Goal**: To construct a fine-grained Chinese Android application privacy policy dataset (CA4P-483) with annotations based on privacy-related laws to facilitate sequence labeling tasks and regulation compliance identification between privacy policies and software.

**Target Audience**:
- Natural Language Processing Researchers
- Software Engineering Researchers
- Cyber Security Researchers

**Tasks**:
- Sequence Labeling
- Regulation Compliance Identification
- App Behavior Consistency Identification

**Limitations**: Depends on locating data access-related sentences using a data collection and sharing word list (limited when information is given in enumeration format). The dataset is time-limited to the timestamp of collection (January 2021).

## üíæ Data

**Source**: Manually collected from Android application markets including Google Play and AppGallery; Chinese privacy policy websites downloaded when available; collection performed around January 2021; text extraction via html2text and annotation via tagtog.

**Size**: 483 documents; 11,565 sentences; 52,577 fine-grained annotations

**Format**: N/A

**Annotation**: Two-phase annotation: coarse-grained paragraph-level annotation followed by fine-grained character-level annotation of seven components (controller, data entity, collection, sharing, condition, purpose, receiver). Annotation was performed by trained annotators (30 undergraduates for coarse phase with three instructors supervising; fine-grained annotation by selected undergraduates with instructor inspection). Each privacy policy was allocated to at least four annotators in the coarse phase. Inter-annotator agreement measured by Fleiss' Kappa with average 77.20% (substantial agreement).

## üî¨ Methodology

**Methods**:
- Hidden Markov Model (HMM)
- Conditional Random Field (CRF)
- BiLSTM
- BiLSTM-CRF
- BERT-BiLSTM-CRF
- Lattice-LSTM

**Metrics**:
- Precision
- Recall
- F1 Score

**Calculation**: Precision, Recall, and F1-score are applied to evaluate baselines following previous research (Wilson et al., 2016; Sui et al., 2021).

**Interpretation**: Higher Precision/Recall/F1 indicate better sequence labeling performance on CA4P-483. The paper reports BiLSTM-CRF as achieving the highest overall F1 (86.84%), while BERT-BiLSTM-CRF had lower overall performance (F1 51.18%), indicating varying effectiveness of model families on this dataset.

**Baseline Results**: Overall performance on CA4P-483 (Precision / Recall / F1): HMM 77.47% / 66.11% / 69.63%; CRF 85.52% / 86.28% / 85.63%; BiLSTM 85.13% / 85.99% / 85.05%; BiLSTM-CRF 86.94% / 86.90% / 86.84%; BERT-BiLSTM-CRF 46.22% / 57.35% / 51.18%; Lattice-LSTM 78.63% / 80.75% / 79.67%.

**Validation**: Dataset split into training, development, and test sets (detailed in Table 2). Annotation quality validated via Fleiss' Kappa (average 77.20%). Baselines evaluated on train/dev/test splits and reported per-component and overall Precision/Recall/F1.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Privacy
- Legal Compliance
- Accuracy

**Atlas Risks**:
- **Data Laws**: Data usage restrictions, Data acquisition restrictions
- **Privacy**: Personal information in data
- **Accuracy**: Poor model accuracy

**Potential Harm**: ['Identify whether privacy policies violate regulation requirements', 'Detect privacy violations', 'Identify inconsistency between app behavior and privacy policy statements']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Dataset constructed from publicly available privacy policy websites; authors state they do not collect any personal/private information.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
