# Anno-lexical

## üìä Benchmark Details

**Name**: Anno-lexical

**Overview**: This study introduces Anno-lexical, the first large-scale dataset for media bias classification with over 48,000 synthetically annotated examples, created to investigate the viability of using Large Language Models for annotations.

**Data Type**: synthetically annotated text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- BABE
- BASIL

**Resources**:
- [Resource](https://anonymous.4open.science/llm-annotations-annomatic)

## üéØ Purpose and Intended Users

**Goal**: To create a cost-effective, high-quality dataset for training classifiers in media bias detection using LLMs.

**Target Audience**:
- ML Researchers
- Domain Experts

**Tasks**:
- Media Bias Detection

**Limitations**: N/A

## üíæ Data

**Source**: Synthetic annotations generated by LLMs based on carefully selected prompts and human-labeled examples.

**Size**: 48,330 sentences

**Format**: N/A

**Annotation**: Synthesized by Large Language Models using majority vote among multiple LLM annotators.

## üî¨ Methodology

**Methods**:
- Labeling by Large Language Models
- Majority voting for annotation

**Metrics**:
- Matthew's Correlation Coefficient (MCC)

**Calculation**: MCC is calculated based on the confusion matrix for binary classification tasks.

**Interpretation**: Higher MCC values indicate better performance in correctly classifying lexical bias.

**Validation**: Comparative testing against human-annotated models and evaluation on established bias benchmark datasets.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Apache-2.0 license

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
