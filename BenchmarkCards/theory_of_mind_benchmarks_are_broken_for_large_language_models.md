# Theory of Mind Benchmarks are Broken for Large Language Models

## üìä Benchmark Details

**Name**: Theory of Mind Benchmarks are Broken for Large Language Models

**Overview**: This paper critiques existing theory of mind benchmarks for large language models (LLMs), arguing that they measure only literal theory of mind rather than functional theory of mind, and introduces functional theory of mind as a critical aspect to evaluate LLMs effectively.

**Data Type**: multimodal

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [Resource](https://arxiv.org/abs/2412.19726)

## üéØ Purpose and Intended Users

**Goal**: To highlight the limitations of current theory of mind benchmarks and advocate for a new interactive methodology to evaluate functional theory of mind in LLMs.

**Target Audience**:
- ML Researchers
- AI Practitioners

**Tasks**:
- Theory of Mind Evaluation
- Reinforcement Learning
- Multi-Agent Interaction

**Limitations**: N/A

## üíæ Data

**Source**: Empirical evaluations through simulations and experiments with large language models

**Size**: N/A

**Format**: N/A

**Annotation**: N/A

## üî¨ Methodology

**Methods**:
- Empirical evaluation
- Simulations
- Multimodal analysis

**Metrics**:
- Accuracy
- Regret

**Calculation**: Calculated metrics focus on comparing literal and functional theory of mind performances based on predefined games and policies.

**Interpretation**: Higher regret signifies poorer functional adaptation capabilities in LLMs.

**Baseline Results**: N/A

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Robustness

**Atlas Risks**:
- **Fairness**: Data bias
- **Robustness**: Prompt injection attack
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
