# AIRTBench

## 📊 Benchmark Details

**Name**: AIRTBench

**Overview**: AIRTBench is an AI red teaming benchmark for evaluating language models’ ability to autonomously discover and exploit AI/ML security vulnerabilities through CTF challenges.

**Data Type**: AI/ML security challenges

**Domains**:
- Cybersecurity

**Languages**:
- English

**Resources**:
- [GitHub Repository](https://github.com/dreadnode/AIRTBench-Code)

## 🎯 Purpose and Intended Users

**Goal**: To measure and track progress in autonomous AI red teaming capabilities.

**Target Audience**:
- Cybersecurity Researchers
- Security Operations Center (SOC) Teams
- Red Teams
- Penetration Testers
- AI/ML Security Engineers

**Tasks**:
- Adversarial Attack Testing
- Model Security Evaluation
- Vulnerability Detection

**Limitations**: N/A

## 💾 Data

**Source**: 70 unique challenges from the Crucible challenge environment hosted on the Dreadnode platform.

**Size**: 70 challenges

**Format**: N/A

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Success Rate
- Challenge Completion Time

**Calculation**: Success is calculated as the percentage of challenges solved by the models.

**Interpretation**: A higher success rate indicates better autonomous red teaming capabilities.

**Baseline Results**: N/A

**Validation**: N/A

## ⚠️ Targeted Risks

**Risk Categories**:
- Security Risks
- Operational Risks

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Apache 2.0

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
