# JADE

## üìä Benchmark Details

**Name**: JADE

**Overview**: JADE is a targeted linguistic fuzzing platform that strengthens the linguistic complexity of seed questions to break a wide range of large language models (LLMs). It generates benchmarks containing unsafe questions that trigger harmful generation of multiple LLMs with a high average unsafe generation ratio.

**Data Type**: Natural Language Questions

**Domains**:
- Safety Evaluation
- Natural Language Processing

**Languages**:
- English
- Chinese

**Similar Benchmarks**:
- RealToxicityPrompts
- Safety-Prompts
- CValues
- DO-NOT-ANSWER

**Resources**:
- [GitHub Repository](https://github.com/whitzard-ai/jade-db)
- [Resource](https://whitzard-ai.github.io/jade.html)

## üéØ Purpose and Intended Users

**Goal**: To evaluate the safety of LLMs by generating complex questions that bypass existing safety guardrails.

**Target Audience**:
- Researchers
- AI Developers
- Safety Evaluators

**Tasks**:
- Generate unsafe questions to evaluate LLM security
- Refine safety evaluation methods
- Analyze LLM vulnerabilities

**Limitations**: N/A

**Out of Scope Uses**:
- General user inquiries
- Non-AI safety assessments

## üíæ Data

**Source**: Generated by JADE

**Size**: N/A

**Format**: Text

**Annotation**: Questions annotated for unsafe content generation

## üî¨ Methodology

**Methods**:
- Linguistic Mutation
- Transformational Rules
- Active Prompt Tuning

**Metrics**:
- Unsafe Generation Ratio
- Fluency
- Semantic Similarity

**Calculation**: Effectiveness measured as the ratio of questions triggering unsafe generation.

**Interpretation**: Higher ratios indicate better ability to bypass LLM safety measures.

**Baseline Results**: Average violation rate of existing benchmarks <= 20%, JADE achieves >70%.

**Validation**: Results validated through human annotation and majority voting.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Unsafe Generation
- Data Privacy
- Ethical Implications

**Atlas Risks**:
- **Accuracy**: Data contamination, Poor model accuracy
- **Fairness**: Data bias
- **Societal Impact**: Impact on cultural diversity

**Demographic Analysis**: N/A

**Potential Harm**: Potential for generating unsafe content that could lead to harmful behaviors.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Ensured through the modification of questions to prevent personal data exposure.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Aligned with safety principles for generative AI.
