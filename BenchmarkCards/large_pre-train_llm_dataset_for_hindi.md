# Large Pre-Train LLM Dataset for Hindi

## ğŸ“Š Benchmark Details

**Name**: Large Pre-Train LLM Dataset for Hindi

**Overview**: The paper proposes a large pre-training dataset in Hindi useful for the Indic language, containing 1.28 billion Hindi tokens collected from various domains, aimed at building foundation LLMs.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- Hindi

**Resources**:
- [Resource](https://huggingface.co/datasets/Hindi-data-hub/odaigen_hindi_pre_trained_sp)

## ğŸ¯ Purpose and Intended Users

**Goal**: To facilitate the development of pre-trained language models specifically for Hindi to enhance NLP capabilities.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Tasks**:
- Text Classification
- Machine Translation
- Sentiment Analysis
- Named Entity Recognition

**Limitations**: The dataset may still have flaws or biases affecting the efficacy of trained models.

## ğŸ’¾ Data

**Source**: Datasets were compiled from various sources including Wikipedia, AI4Bharat IndicParaphrase, Miracl Corpus, Oscar dataset, and others.

**Size**: 1.28 billion tokens

**Format**: N/A

**Annotation**: N/A

## ğŸ”¬ Methodology

**Methods**:
- Data Collection
- Preprocessing
- Dataset Compilation

**Calculation**: Data was systematically collected from multiple sources and preprocessed to ensure quality.

**Interpretation**: The dataset's quality ensures robust training of language models, which should improve various NLP tasks.

**Validation**: N/A

## âš ï¸ Targeted Risks

**Risk Categories**:
- Bias
- Accuracy
- Ethical Concerns

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
