# FaithBench

## 📊 Benchmark Details

**Name**: FaithBench

**Overview**: A diverse hallucination benchmark for summarization tasks performed by modern LLMs, featuring challenging hallucinations generated by 10 modern LLMs from 8 different families with human-annotated ground truth.

**Data Type**: Summarization hallucination detection

**Similar Benchmarks**:
- Vectara's Hallucination Leaderboard
- Galileo's Hallucination Index

**Resources**:
- [GitHub Repository](https://github.com/vectara/FaithBench)

## 🎯 Purpose and Intended Users

**Goal**: To evaluate hallucination rates of large language models and the effectiveness of hallucination detection models.

**Target Audience**:
- Researchers in NLP
- AI developers
- Machine learning practitioners

**Tasks**:
- Detect and evaluate hallucinations in summaries generated by LLMs

**Limitations**: None

## 💾 Data

**Source**: Vectara’s Hallucination Leaderboard

**Size**: 660 samples

**Format**: N/A

**Annotation**: Ground truth annotations made by 11 human experts

## 🔬 Methodology

**Methods**:
- Human annotation for challenging samples
- Automated hallucination detection models

**Metrics**:
- Hallucination rates
- Inter-annotator agreement (IAA)

**Calculation**: Percentage of hallucinations per model computed based on label assignments

**Interpretation**: Evaluated correlation between LLM outputs and human-annotated ground truth

**Validation**: Pilot runs to ensure annotator agreement on definitions and categorization

## ⚠️ Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness
- Privacy

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias, Output bias
- **Privacy**: Personal information in data, Data privacy rights alignment

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Data created will be made open source to the public.

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
