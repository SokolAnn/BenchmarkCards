# PLANET: A Collection of Benchmarks for Evaluating LLMs’ Planning Capabilities

## 📊 Benchmark Details

**Name**: PLANET: A Collection of Benchmarks for Evaluating LLMs’ Planning Capabilities

**Overview**: This paper surveys and categorizes existing benchmarks for evaluating the planning capabilities of large language models (LLMs) in various tasks such as embodied environments, web navigation, scheduling, and more. It identifies common testbeds for algorithm development while highlighting gaps that require further attention in benchmark creation.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Similar Benchmarks**:
- ALFWorld
- PlanBench
- ALFRED
- TravelPlanner

**Resources**:
- [Resource](https://arxiv.org/abs/2504.14773)

## 🎯 Purpose and Intended Users

**Goal**: To provide a comprehensive overview of benchmarks available for evaluating LLMs' planning abilities and identify gaps in existing benchmarks to guide future development.

**Target Audience**:
- ML Researchers
- Domain Experts

**Tasks**:
- Planning
- Web Navigation
- Task Automation

**Limitations**: N/A

## 💾 Data

**Source**: Survey of existing planning benchmarks; aggregation of information from various sources

**Size**: N/A

**Format**: N/A

**Annotation**: N/A

## 🔬 Methodology

**Methods**:
- Benchmark survey

**Metrics**:
- N/A

**Calculation**: N/A

**Interpretation**: N/A

**Baseline Results**: N/A

**Validation**: N/A

## ⚠️ Targeted Risks

**Risk Categories**:
- Safety
- Robustness
- Accuracy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data
- **Robustness**: Evasion attack
- **Societal Impact**: Impact on affected communities

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
