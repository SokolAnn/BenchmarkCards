# Multimodal Stance Generation Dataset (Stance-Gen2024)

## üìä Benchmark Details

**Name**: Multimodal Stance Generation Dataset (Stance-Gen2024)

**Overview**: StanceGen2024 is the first multimodal dataset explicitly designed for stance-controlled generation in political discourse. It pairs multimodal posts (text, images, videos) from the 2024 U.S. presidential election with stance-annotated user responses, enabling systematic exploration of how multimodal context shapes ideological expression.

**Data Type**: multimodal

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [Resource](https://anonymous.4open.science/r/StanceGen-BE9D)

## üéØ Purpose and Intended Users

**Goal**: The primary objective of this benchmark is to explore how multimodal political content interacts across different media and influences users' stance expression, thereby providing a real and diverse foundation for future multimodal stance generation tasks.

**Target Audience**:
- ML Researchers
- Industry Practitioners

**Tasks**:
- Stance Detection
- Multimodal Content Generation

**Limitations**: The StanceGen2024 dataset focuses on the 2024 U.S. presidential election, limiting its generalizability to other political contexts or topics.

## üíæ Data

**Source**: Posts from the official Twitter profiles of Kamala Harris and Donald Trump along with user comments.

**Size**: 1,039 posts and 25,025 comments

**Format**: N/A

**Annotation**: Both tweets and their associated user comments are annotated with political stances (e.g., against or favor) and with topic categories that capture broad themes such as voter mobilization, political ideology, and candidate image projection.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Controllability
- Perplexity
- Relevance
- Cross-modal Semantic Similarity (CMSS)

**Calculation**: Metrics are calculated based on outputs generated by models applied to the StanceGen2024 dataset.

**Interpretation**: A higher controllability score indicates a better ability of the model to maintain the predetermined stance in the generated responses, while lower perplexity denotes more fluent responses.

**Baseline Results**: LLaV A-SDMG achieves higher controllability in multimodal tasks compared to other models.

**Validation**: Cohen‚Äôs Kappa Statistic was used to evaluate inter-annotator agreement, with an average score of 0.719.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: ['Political discourse is inherently biased']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
