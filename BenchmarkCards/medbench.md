# MedBench

## üìä Benchmark Details

**Name**: MedBench

**Overview**: A comprehensive benchmark for the Chinese medical domain, comprising 40,041 questions sourced from authentic examination exercises and medical reports of diverse branches of medicine.

**Data Type**: question-answering pairs

**Domains**:
- Healthcare

**Languages**:
- Chinese

**Similar Benchmarks**:
- MedQA
- MedMCQA
- MLEC-QA
- CMExam

**Resources**:
- [GitHub Repository](https://github.com/michael-wzhu/ChatMed)

## üéØ Purpose and Intended Users

**Goal**: To provide a standardized medical benchmark capable of offering reliable and authoritative evaluations for Chinese medical large language models.

**Target Audience**:
- ML Researchers
- Medical Researchers
- Practitioners

**Tasks**:
- Question Answering

**Limitations**: N/A

## üíæ Data

**Source**: Authentic medical examinations and real-world clinical cases from Chinese medical licensing and training.

**Size**: 40,041 questions

**Format**: N/A

**Annotation**: Expert annotated

## üî¨ Methodology

**Methods**:
- Automated metrics
- Human evaluation

**Metrics**:
- Accuracy
- BLEU
- ROUGE

**Calculation**: Accuracy is calculated based on examination performances; BLEU and ROUGE used for real-world cases.

**Interpretation**: Higher accuracy indicates better performance in responding correctly to medical examination questions.

**Validation**: Extensive experiments conducted and detailed analyses performed.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Fairness
- Safety
- Privacy

**Atlas Risks**:
No specific atlas risks defined

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
