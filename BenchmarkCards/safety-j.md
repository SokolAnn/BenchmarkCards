# SAFETY-J

## ğŸ“Š Benchmark Details

**Name**: SAFETY-J

**Overview**: SAFETY-J is a bilingual generative safety evaluator designed for English and Chinese languages, providing critique-based judgments to enhance content safety evaluation and facilitate model improvements.

**Data Type**: dialogues and augmented query-response pairs

**Domains**:
- Natural Language Processing

**Languages**:
- English
- Chinese

**Similar Benchmarks**:
- ShieldLM

**Resources**:
- [GitHub Repository](https://github.com/GAIR-NLP/Safety-J)

## ğŸ¯ Purpose and Intended Users

**Goal**: To provide a comprehensive safety evaluation for outputs generated by large language models and improve the transparency and interpretability of content assessments.

**Target Audience**:
- ML Researchers
- AI Developers
- Industry Practitioners

**Tasks**:
- Safety Evaluation

**Limitations**: SAFETY-J may not cover all safety domains, particularly those requiring professional knowledge.

## ğŸ’¾ Data

**Source**: Data collected from existing datasets like BeaverTails, Alpaca, and augmented with LLM-generated content.

**Size**: 19,030 query-response pairs

**Format**: N/A

**Annotation**: Annotated by human experts and LLM-generated critiques.

## ğŸ”¬ Methodology

**Methods**:
- Automated meta-evaluation
- Iterative preference learning

**Metrics**:
- Accuracy
- F1 Score
- Precision
- Recall

**Calculation**: Metrics calculated based on the performance of critiques generated by SAFETY-J using standard evaluation methods.

**Interpretation**: Interpret scores to assess the effectiveness of safety evaluations and critique quality.

**Validation**: The benchmark evaluates models against established test datasets.

## âš ï¸ Targeted Risks

**Risk Categories**:
- Safety
- Bias

**Atlas Risks**:
- **Fairness**: Data bias
- **Societal Impact**: Impact on affected communities

**Potential Harm**: ['Potential misuse of criticism techniques']

## ğŸ”’ Ethical and Legal Considerations

**Privacy And Anonymity**: Data privacy procedures included measures to avoid using private data.

**Data Licensing**: Not Applicable

**Consent Procedures**: Ensure participants are aware of potential offensive content during annotation.

**Compliance With Regulations**: Adheres to local and international data protection standards.
