# VERIFYBENCH: BENCHMARKING REFERENCE-BASED REWARD SYSTEMS FOR LARGE LANGUAGE MODELS

## üìä Benchmark Details

**Name**: VERIFYBENCH: BENCHMARKING REFERENCE-BASED REWARD SYSTEMS FOR LARGE LANGUAGE MODELS

**Overview**: VerifyBench is introduced as a benchmark specifically designed to evaluate the accuracy of reference-based reward systems, focusing on absolute correctness judgments rather than relative preference assessments.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing
- Mathematical Reasoning

**Languages**:
- English

**Similar Benchmarks**:
- VerifierBench

**Resources**:
- [Resource](https://huggingface.co/datasets/ZJU-REAL/VerifyBench)
- [Resource](https://zju-real.github.io/VerifyBench)
- [GitHub Repository](https://github.com/ZJU-REAL/VerifyBench)

## üéØ Purpose and Intended Users

**Goal**: To provide a standardized framework for assessing reference-based reward systems and improving verification accuracy in reasoning models trained via reinforcement learning.

**Target Audience**:
- ML Researchers
- Industry Practitioners
- Model Developers

**Tasks**:
- Verification of responses
- Performance evaluation of reward systems

**Limitations**: Limited to general reasoning, logical reasoning, and mathematical reasoning domains.

## üíæ Data

**Source**: Curated from existing open datasets and responses generated by multiple open-source and proprietary LLMs.

**Size**: 2,000 well-balanced question-answer-completion-correctness tuples

**Format**: JSON

**Annotation**: Human annotation with multiple annotators to ensure label consistency and reliability.

## üî¨ Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy is defined based on the proportion of correctly assigned scores by reward models on labeled instances.

**Interpretation**: High accuracy indicates effective verification by reward models, while low accuracy signifies areas needing improvement.

**Baseline Results**: State-of-the-art LLMs demonstrate up to 95.8% accuracy on VerifyBench.

**Validation**: Thorough human annotation and analysis for reliability of performance assessments.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Accuracy
- Fairness

**Atlas Risks**:
- **Accuracy**: Poor model accuracy
- **Fairness**: Data bias

**Demographic Analysis**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
