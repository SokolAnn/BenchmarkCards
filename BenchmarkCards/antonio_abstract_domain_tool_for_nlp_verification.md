# ANTONIO (Abstract domaiN Tool fOr Nlp verIficatiOn)

## üìä Benchmark Details

**Name**: ANTONIO (Abstract domaiN Tool fOr Nlp verIficatiOn)

**Overview**: Proposes practical methods and heuristics for preparing NLP datasets and models to make them amenable to state-of-the-art neural network verification methods; implements these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou, and demonstrates the tool on the R-U-A-Robot dataset to generate verification benchmarks and queries.

**Data Type**: text (sentence classification examples and sentence embeddings)

**Domains**:
- Natural Language Processing
- Formal Verification

**Similar Benchmarks**:
- R-U-A-Robot

**Resources**:
- [GitHub Repository](https://github.com/ANTONIONLP/ANTONIO)
- [Resource](https://vnnlib.org/)
- [GitHub Repository](https://github.com/onnx/onnx)

## üéØ Purpose and Intended Users

**Goal**: Provide practical methods and heuristics to prepare NLP datasets and models to be amenable to neural network verification methods; implement these as the Python library ANTONIO linking to ERAN and Marabou; enable inclusion of NLP problems into neural network verification competitions.

**Target Audience**:
- Neural network verification community
- Natural Language Processing researchers

**Tasks**:
- Text Classification
- Verification of neural networks
- Adversarial robustness testing

**Limitations**: Evaluation in this tool paper is performed on the R-U-A-Robot dataset only. State-of-the-art transformers are beyond the reach of state-of-the-art verifiers and verification efforts focus on classifiers on top of embeddings rather than verifying large pre-trained transformers end-to-end.

## üíæ Data

**Source**: R-U-A-Robot dataset (used in experiments); augmented via character-level, word-level, and sentence-level perturbations generated by ANTONIO; embeddings produced via Sentence-BERT.

**Size**: 6,800 examples

**Format**: Sentence embeddings (384-dimensional vectors) for geometric processing; generated neural networks exported in ONNX format and verification queries in VNNLIB format.

**Annotation**: R-U-A-Robot labels: positive (question demands identification), negative (question about something else), ambiguous.

## üî¨ Methodology

**Methods**:
- Automated metrics (accuracy, robustness metrics)
- Model-based evaluation using neural network verifiers (ERAN, Marabou)
- Adversarial testing and attack-based dataset augmentation
- Translation of networks to ONNX and verification queries to VNNLIB

**Metrics**:
- Accuracy
- Robustness to attack (accuracy on adversarial test samples)
- Percentage of verified hyper-rectangles (verification success rate)

**Calculation**: Accuracy: standard classification accuracy on test set. Robustness to attack: generate perturbations of the test set and compute accuracy on perturbed samples. Percentage of verified hyper-rectangles: run verifiers (ERAN, Marabou) on generated VNNLIB queries corresponding to hyper-rectangles and compute percentage of hyper-rectangles for which the verifier proves the desired property.

**Interpretation**: It is important to avoid significant drops in standard accuracy when training for robustness; robustness metric measures classifier accuracy under generated perturbations; higher percentage of verified hyper-rectangles indicates greater success of verifiers on the defined input regions.

**Baseline Results**: Table 4 (excerpt): Marabou - Nbase: H*_{œµ=0.05}=1.79, H*_{char}=4.88, H*_{word}=11.69; N_{œµ=0.05}: 18.46, 21.99, 41.93; N_{char-adv}: 7.37, 30.41, 41.93; N_{word-adv}: 12.17, 25.82, 45.12. ERAN - Nbase: 0.00, 0.87, 1.80; N_{œµ=0.05}: 0.12, 4.18, 10.16; N_{char-adv}: 0.00, 4.43, 8.97; N_{word-adv}: 0.04, 4.05, 10.75.

**Validation**: Validated by generating ONNX neural networks and VNNLIB verification queries and running them on two state-of-the-art verifiers (ERAN and Marabou); results reported (Table 4). Conforms to VNN-COMP standards (ONNX for networks and VNNLIB for verification queries).

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Safety
- Robustness
- Accuracy

**Atlas Risks**:
- **Legal Compliance**: Legal accountability
- **Robustness**: Evasion attack
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: N/A

**Potential Harm**: ['User discomfort or deception (preventing chatbot deception)', 'Legal implications for chatbot designers']

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Mentions proposed legislation and regulatory context, e.g., the EU Artificial Intelligence Act and California Senate Bill No. 1001 regarding chatbot identification requirements.
