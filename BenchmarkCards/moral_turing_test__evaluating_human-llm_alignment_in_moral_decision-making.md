# Moral Turing Test: Evaluating Human-LLM Alignment in Moral Decision-Making

## üìä Benchmark Details

**Name**: Moral Turing Test: Evaluating Human-LLM Alignment in Moral Decision-Making

**Overview**: The study investigates human alignment with large language model (LLM) moral judgments through a corpus of human- and LLM-generated responses to various moral scenarios, highlighting misalignment and human preferences in moral decision-making.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- English

**Resources**:
- [Resource](https://arxiv.org/abs/2410.07304)

## üéØ Purpose and Intended Users

**Goal**: To examine the alignment between human moral judgments and those of LLMs, particularly focusing on detection and agreement in moral decision-making.

**Target Audience**:
- ML Researchers
- Ethicists
- AI Practitioners

**Tasks**:
- Moral Decision-Making
- Human-AI Interaction Analysis

**Limitations**: Findings may be model-specific, particularly to the GPT-3.5 architecture.

## üíæ Data

**Source**: Responses generated through structured moral scenarios presented to human participants and LLM (GPT-3.5) models.

**Size**: 3,420 responses

**Format**: JSON

**Annotation**: Responses were manually collected from human participants and generated by LLMs.

## üî¨ Methodology

**Methods**:
- User study with human evaluators
- Statistical analysis
- Linguistic analysis
- Predictive modeling

**Metrics**:
- Accuracy
- F1 Score

**Calculation**: Metrics calculated through evaluation of participant responses to judgment detection and agreement.

**Interpretation**: Higher agreement rates indicated stronger alignment and preference for LLM-generated judgments in morally complex scenarios.

**Baseline Results**: Models achieved detection accuracy of approximately 64% on corpus 1 and 71% on corpus 2.

**Validation**: Statistical tests including t-tests and ANOVAs were conducted to validate findings.

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Accuracy

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Poor model accuracy

**Demographic Analysis**: Demographic breakdown of participants was collected, revealing no significant differences in results based on gender.

**Potential Harm**: Potential risk of misalignment in moral decision-making leading to harmful outcomes.

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Informed consent was obtained from all participants before the experiments.

**Data Licensing**: Not Applicable

**Consent Procedures**: Participants received clear instructions regarding their involvement and data usage.

**Compliance With Regulations**: Research was conducted in accordance with the Declaration of Helsinki.
