# ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large Language Models

## üìä Benchmark Details

**Name**: ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large Language Models

**Overview**: The ZhuJiu benchmark is designed to comprehensively evaluate Large Language Models (LLMs) across 7 ability dimensions covering 51 tasks, including a focus on knowledge ability. It employs multiple evaluation methods to ensure authoritative evaluation results, specifically targeting Chinese LLM assessment while also allowing for robust evaluation in English.

**Data Type**: text

**Domains**:
- Natural Language Processing

**Languages**:
- Chinese
- English

**Similar Benchmarks**:
- GLUE
- SuperGLUE
- CUGE

**Resources**:
- [Resource](http://www.zhujiu-benchmark.com/)

## üéØ Purpose and Intended Users

**Goal**: To provide a comprehensive benchmark for evaluating the performance of Large Language Models in both Chinese and English across multiple dimensions and tasks.

**Target Audience**:
- ML Researchers
- Model Developers
- Industry Practitioners

**Tasks**:
- Knowledge Evaluation
- Language Understanding
- Language Generation
- Reasoning Ability
- Refusal Ability
- Safety Assessment
- Robustness Evaluation

**Limitations**: N/A

## üíæ Data

**Source**: The ZhuJiu benchmark includes evaluation data constructed for 37 specific tasks alongside 14 publicly available datasets.

**Size**: N/A

**Format**: N/A

**Annotation**: Manually constructed using seed data reviewed and confirmed for each specific task.

## üî¨ Methodology

**Methods**:
- Metrics Evaluation
- Scoring Evaluation
- Comparative Evaluation

**Metrics**:
- Accuracy
- Robustness
- Completeness
- Timeliness

**Calculation**: Scores are calculated based on user-defined metrics and evaluation frameworks comparative results.

**Interpretation**: The evaluation determines the performance of LLMs based on their responses to various tasks, comparing results from different models.

**Baseline Results**: Evaluated 10 LLMs including ChatGLM, BELLE, ChatGPT, etc.

**Validation**: N/A

## ‚ö†Ô∏è Targeted Risks

**Risk Categories**:
- Bias
- Safety
- Privacy
- Robustness
- Fairness
- Accuracy

**Atlas Risks**:
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: N/A

**Potential Harm**: N/A

## üîí Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
