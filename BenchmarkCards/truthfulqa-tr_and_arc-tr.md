# TruthfulQA-TR and ARC-TR

## 📊 Benchmark Details

**Name**: TruthfulQA-TR and ARC-TR

**Overview**: This work introduces two Turkish evaluation datasets, TruthfulQA-TR for assessing common falsehoods, and ARC-TR, a set of grade-school science questions, to evaluate the capabilities of Turkish LLMs.

**Data Type**: question-answering pairs

**Domains**:
- Natural Language Processing

**Languages**:
- Turkish

**Resources**:
- [Resource](https://emrecanacikgoz.github.io/Bridging-the-Bosphorus/)

## 🎯 Purpose and Intended Users

**Goal**: To advance the development of Turkish LLMs and provide standard benchmarks for assessing their performance.

**Target Audience**:
- Researchers in Natural Language Processing
- Model Developers

**Tasks**:
- Question Answering

**Limitations**: N/A

## 💾 Data

**Source**: TruthfulQA dataset adapted for Turkish and ARC dataset translated into Turkish.

**Size**: N/A

**Format**: N/A

**Annotation**: Translated by using state-of-the-art tools and validated with multiple annotators.

## 🔬 Methodology

**Methods**:
- Human evaluation
- Automated metrics

**Metrics**:
- Accuracy

**Calculation**: Accuracy is calculated based on the performance of models on the newly established benchmarks.

**Interpretation**: Higher accuracy indicates better performance in generating truthful and accurate responses.

**Baseline Results**: N/A

**Validation**: Evaluated through a leaderboard that catalogs model performances on the new tasks.

## ⚠️ Targeted Risks

**Risk Categories**:
- Bias
- Fairness

**Atlas Risks**:
- **Fairness**: Data bias
- **Accuracy**: Unrepresentative data

**Demographic Analysis**: N/A

## 🔒 Ethical and Legal Considerations

**Privacy And Anonymity**: Not Applicable

**Data Licensing**: Not Applicable

**Consent Procedures**: Not Applicable

**Compliance With Regulations**: Not Applicable
